{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimTooLongException(Exception):\n",
    "\n",
    "    def __init__(self, max_n_steps):\n",
    "        self.max_n_steps = max_n_steps\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Simulation exceeded the maximum of {} steps.'.format(self.max_n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_sample(p, n_samples=1):\n",
    "    \"\"\"\n",
    "    Samples from a discrete distribution.\n",
    "    :param p: a distribution with N elements\n",
    "    :param n_samples: number of samples\n",
    "    :return: vector of samples\n",
    "    \"\"\"\n",
    "\n",
    "    # check distribution\n",
    "    #assert isdistribution(p), 'Probabilities must be non-negative and sum to one.'\n",
    "\n",
    "    # cumulative distribution\n",
    "    c = np.cumsum(p[:-1])[np.newaxis, :]\n",
    "\n",
    "    # get the samples\n",
    "    r = rng.rand(n_samples, 1)\n",
    "    return np.sum((r > c).astype(int), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovJumpProcess:\n",
    "    \"\"\"Implements a generic markov jump process and algorithms for simulating it.\n",
    "    It is an abstract class, it needs to be inherited by a concrete implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, init, params):\n",
    "\n",
    "        self.state = np.asarray(init)\n",
    "        self.params = np.asarray(params)\n",
    "        self.time = 0.0\n",
    "\n",
    "    def _calc_propensities(self):\n",
    "        raise NotImplementedError('This is an abstract method and should be implemented in a subclass.')\n",
    "\n",
    "    def _do_reaction(self, reaction):\n",
    "        raise NotImplementedError('This is an abstract method and should be implemented in a subclass.')\n",
    "\n",
    "    def sim_steps(self, num_steps):\n",
    "        \"\"\"Simulates the process with the gillespie algorithm for a specified number of steps.\"\"\"\n",
    "\n",
    "        times = [self.time]\n",
    "        states = [self.state.copy()]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "\n",
    "            rates = self.params * self._calc_propensities()\n",
    "            total_rate = rates.sum()\n",
    "\n",
    "            if total_rate == 0:\n",
    "                self.time = float('inf')\n",
    "                break\n",
    "\n",
    "            self.time += rng.exponential(scale=1/total_rate)\n",
    "\n",
    "            reaction = discrete_sample(rates / total_rate)[0]\n",
    "            self._do_reaction(reaction)\n",
    "\n",
    "            times.append(self.time)\n",
    "            states.append(self.state.copy())\n",
    "\n",
    "        return times, np.array(states)\n",
    "\n",
    "    def sim_time(self, dt, duration, max_n_steps=float('inf')):\n",
    "        \"\"\"Simulates the process with the gillespie algorithm for a specified time duration.\"\"\"\n",
    "\n",
    "        num_rec = int(duration / dt) + 1\n",
    "        states = np.zeros([num_rec, self.state.size])\n",
    "        cur_time = self.time\n",
    "        n_steps = 0\n",
    "\n",
    "        for i in range(num_rec):\n",
    "\n",
    "            while cur_time > self.time:\n",
    "\n",
    "                rates = self.params * self._calc_propensities()\n",
    "                total_rate = rates.sum()\n",
    "\n",
    "                if total_rate == 0:\n",
    "                    self.time = float('inf')\n",
    "                    break\n",
    "\n",
    "                self.time += rng.exponential(scale=1/total_rate)\n",
    "\n",
    "                reaction = discrete_sample(rates / total_rate)[0]\n",
    "                self._do_reaction(reaction)\n",
    "\n",
    "                n_steps += 1\n",
    "                if n_steps > max_n_steps:\n",
    "                    raise SimTooLongException(max_n_steps)\n",
    "\n",
    "            states[i] = self.state.copy()\n",
    "            cur_time += dt\n",
    "\n",
    "        return np.array(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LotkaVolterra(MarkovJumpProcess):\n",
    "    \"\"\"Implements the lotka-volterra population model.\"\"\"\n",
    "\n",
    "    def _calc_propensities(self):\n",
    "\n",
    "        x, y = self.state\n",
    "        xy = x * y\n",
    "        return np.array([xy, x, y, xy])\n",
    "\n",
    "    def _do_reaction(self, reaction):\n",
    "\n",
    "        if reaction == 0:\n",
    "            self.state[0] += 1\n",
    "        elif reaction == 1:\n",
    "            self.state[0] -= 1\n",
    "        elif reaction == 2:\n",
    "            self.state[1] += 1\n",
    "        elif reaction == 3:\n",
    "            self.state[1] -= 1\n",
    "        else:\n",
    "            raise ValueError('Unknown reaction.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/mauro/Documents/University/MCMCPlayground/data/lotka-volterra/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_smc_abc():\n",
    "    \"\"\"Runs sequential monte carlo abc and saves results.\"\"\"\n",
    "\n",
    "    # set parameters\n",
    "    n_particles = 100\n",
    "    eps_init = 10.0\n",
    "    eps_last = 0.1\n",
    "    eps_decay = 0.9\n",
    "    ess_min = 0.5\n",
    "\n",
    "    # load pilot results and observed statistics\n",
    "    pilot_means, pilot_stds = pd.read_pickle(datadir + 'pilot_run_results.pkl')  #load(datadir + 'pilot_run_results.pkl')\n",
    "\n",
    "    obs_stats = pd.read_pickle(datadir + 'obs_stats.pkl') #load(datadir + 'obs_stats.pkl')\n",
    "    obs_stats -= pilot_means\n",
    "    obs_stats /= pilot_stds\n",
    "\n",
    "    all_params = []\n",
    "    all_logweights = []\n",
    "    all_eps = []\n",
    "    all_nsims = []\n",
    "    n_dim = len(true_params)\n",
    "\n",
    "    # sample initial population\n",
    "    params = np.empty([n_particles, n_dim])\n",
    "    weights = np.ones(n_particles, dtype=float) / n_particles\n",
    "    logweights = np.log(weights)\n",
    "    eps = eps_init\n",
    "    iter = 0\n",
    "    nsims = 0\n",
    "\n",
    "    for i in range(n_particles):\n",
    "\n",
    "        dist = float('inf')\n",
    "\n",
    "        while dist > eps:\n",
    "            params[i] = sim_prior_params()\n",
    "\n",
    "            lv = LotkaVolterra(init, params[i])\n",
    "            try:\n",
    "                nsims += 1\n",
    "                states = lv.sim_time(dt, duration, max_n_steps=max_n_steps)\n",
    "            except SimTooLongException:\n",
    "                continue\n",
    "\n",
    "            stats = calc_summary_stats(states)\n",
    "            stats -= pilot_means\n",
    "            stats /= pilot_stds\n",
    "\n",
    "            dist = calc_dist(stats, obs_stats)\n",
    "\n",
    "        print('particle = {0}'.format(i))\n",
    "\n",
    "    all_params.append(params)\n",
    "    all_logweights.append(logweights)\n",
    "    all_eps.append(eps)\n",
    "    all_nsims.append(nsims)\n",
    "\n",
    "    print('iteration = {0}, eps = {1:.2}, ess = {2:.2%}'.format(iter, eps, 1.0))\n",
    "\n",
    "    while eps > eps_last:\n",
    "\n",
    "        iter += 1\n",
    "        eps *= eps_decay\n",
    "\n",
    "        # calculate population covariance\n",
    "        logparams = np.log(params)\n",
    "        mean = np.mean(logparams, axis=0)\n",
    "        cov = 2.0 * (np.dot(logparams.T, logparams) / n_particles - np.outer(mean, mean))\n",
    "        std = np.linalg.cholesky(cov)\n",
    "\n",
    "        # perturb particles\n",
    "        new_params = np.empty_like(params)\n",
    "        new_logweights = np.empty_like(logweights)\n",
    "\n",
    "        for i in range(n_particles):\n",
    "\n",
    "            dist = float('inf')\n",
    "\n",
    "            while dist > eps:\n",
    "                idx = discrete_sample(weights)[0]\n",
    "                new_params[i] = params[idx] * np.exp(np.dot(std, rng.randn(n_dim)))\n",
    "\n",
    "                lv = LotkaVolterra(init, new_params[i])\n",
    "                try:\n",
    "                    nsims += 1\n",
    "                    states = lv.sim_time(dt, duration, max_n_steps=max_n_steps)\n",
    "                except SimTooLongException:\n",
    "                    continue\n",
    "\n",
    "                stats = calc_summary_stats(states)\n",
    "                stats -= pilot_means\n",
    "                stats /= pilot_stds\n",
    "\n",
    "                dist = calc_dist(stats, obs_stats)\n",
    "\n",
    "            new_logparams_i = np.log(new_params[i])\n",
    "            logkernel = -0.5 * np.sum(np.linalg.solve(std, (new_logparams_i - logparams).T) ** 2, axis=0)\n",
    "            new_logweights[i] = -float('inf') if np.any(new_logparams_i > log_prior_max) or np.any(new_logparams_i < log_prior_min) else -scipy.misc.logsumexp(logweights + logkernel)\n",
    "\n",
    "            print('particle = {0}'.format(i))\n",
    "\n",
    "        params = new_params\n",
    "        logweights = new_logweights - scipy.misc.logsumexp(new_logweights)\n",
    "        weights = np.exp(logweights)\n",
    "\n",
    "        # calculate effective sample size\n",
    "        ess = 1.0 / (np.sum(weights ** 2) * n_particles)\n",
    "        print('iteration = {0}, eps = {1:.2}, ess = {2:.2%}'.format(iter, eps, ess))\n",
    "\n",
    "        if ess < ess_min:\n",
    "\n",
    "            # resample particles\n",
    "            new_params = np.empty_like(params)\n",
    "\n",
    "            for i in range(n_particles):\n",
    "                idx = discrete_sample(weights)[0]\n",
    "                new_params[i] = params[idx]\n",
    "\n",
    "            params = new_params\n",
    "            weights = np.ones(n_particles, dtype=float) / n_particles\n",
    "            logweights = np.log(weights)\n",
    "\n",
    "        all_params.append(params)\n",
    "        all_logweights.append(logweights)\n",
    "        all_eps.append(eps)\n",
    "        all_nsims.append(nsims)\n",
    "\n",
    "        # save results\n",
    "        filename = datadir + 'smc_abc_results.pkl'\n",
    "        save((all_params, all_logweights, all_eps, all_nsims), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_smc_abc_results():\n",
    "    \"\"\"\n",
    "    Loads and shows the results from smc abc.\n",
    "    \"\"\"\n",
    "\n",
    "    # read data\n",
    "    all_params, all_logweights, all_eps, _ = pd.read_pickle(datadir + 'smc_abc_results.pkl') #load(datadir + 'smc_abc_results.pkl')\n",
    "    n_dim = len(true_params)\n",
    "\n",
    "    for params, logweights, eps in izip(all_params, all_logweights, all_eps):\n",
    "\n",
    "        weights = np.exp(logweights)\n",
    "        logparams = np.log(params)\n",
    "\n",
    "        # print estimates with error bars\n",
    "        means = np.dot(weights, logparams)\n",
    "        stds = np.sqrt(np.dot(weights, logparams ** 2) - means ** 2)\n",
    "        print('eps = {0:.2}'.format(eps))\n",
    "        for i in range(n_dim):\n",
    "            print('log theta {0}: true = {1:.2} \\t estimate = {2:.2} +/- {3:.2}'.format(i+1, np.log(true_params[i]), means[i], 2.0 * stds[i]))\n",
    "        print('')\n",
    "\n",
    "        # plot histograms and scatter plots\n",
    "        plot_hist_marginals(logparams, lims=[log_prior_min, log_prior_max], gt=np.log(true_params))\n",
    "        plt.gcf().suptitle('tolerance = {0:.2}'.format(eps))\n",
    "\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file):\n",
    "    \"\"\"Loads data from file.\"\"\"\n",
    "\n",
    "    f = open(file, 'r')\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data, file):\n",
    "    \"\"\"Saves data to a file.\"\"\"\n",
    "\n",
    "    f = open(file, 'w')\n",
    "    pickle.dump(data, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_marginals(data, lims=None, gt=None):\n",
    "    # Plots marginal histograms and pairwise scatter plots of a dataset.\n",
    "\n",
    "    n_bins = int(np.sqrt(data.shape[0]))\n",
    "\n",
    "    if data.ndim == 1:\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.hist(data, n_bins, normed=True)\n",
    "        ax.set_ylim([0, ax.get_ylim()[1]])\n",
    "        if lims is not None: ax.set_xlim(lims)\n",
    "        if gt is not None: ax.vlines(gt, 0, ax.get_ylim()[1], color='r')\n",
    "\n",
    "    else:\n",
    "\n",
    "        n_dim = data.shape[1]\n",
    "        fig, ax = plt.subplots(n_dim, n_dim)\n",
    "        ax = np.array([[ax]]) if n_dim == 1 else ax\n",
    "\n",
    "        if lims is not None:\n",
    "            lims = np.asarray(lims)\n",
    "            lims = np.tile(lims, [n_dim, 1]) if lims.ndim == 1 else lims\n",
    "\n",
    "        for i in range(n_dim):\n",
    "            for j in range(n_dim):\n",
    "\n",
    "                if i == j:\n",
    "                    ax[i, j].hist(data[:, i], n_bins, normed=True)\n",
    "                    ax[i, j].set_ylim([0, ax[i, j].get_ylim()[1]])\n",
    "                    if lims is not None: ax[i, j].set_xlim(lims[i])\n",
    "                    if gt is not None: ax[i, j].vlines(gt[i], 0, ax[i, j].get_ylim()[1], color='r')\n",
    "\n",
    "                else:\n",
    "                    ax[i, j].plot(data[:, i], data[:, j], 'k.', ms=2)\n",
    "                    if lims is not None:\n",
    "                        ax[i, j].set_xlim(lims[i])\n",
    "                        ax[i, j].set_ylim(lims[j])\n",
    "                    if gt is not None: ax[i, j].plot(gt[i], gt[j], 'r.', ms=8)\n",
    "\n",
    "    plt.show(block=False)\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = [50, 100]\n",
    "dt = 0.2\n",
    "duration = 30\n",
    "true_params = [0.01, 0.5, 1.0, 0.01]\n",
    "log_prior_min = -5\n",
    "log_prior_max = 2\n",
    "max_n_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_prior_params(num_sims=1):\n",
    "    \"\"\"\n",
    "    Simulates parameters from the prior. Assumes a uniform prior in the log domain.\n",
    "    \"\"\"\n",
    "\n",
    "    z = rng.rand(4) if num_sims == 1 else rng.rand(num_sims, 4)\n",
    "    return np.exp((log_prior_max - log_prior_min) * z + log_prior_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_summary_stats(states):\n",
    "    \"\"\"\n",
    "    Given a sequence of states produced by a simulation, calculates and returns a vector of summary statistics.\n",
    "    Assumes that the sequence of states is uniformly sampled in time.\n",
    "    \"\"\"\n",
    "\n",
    "    N = states.shape[0]\n",
    "    x, y = states[:, 0].copy(), states[:, 1].copy()\n",
    "\n",
    "    # means\n",
    "    mx = np.mean(x)\n",
    "    my = np.mean(y)\n",
    "\n",
    "    # variances\n",
    "    s2x = np.var(x, ddof=1)\n",
    "    s2y = np.var(y, ddof=1)\n",
    "\n",
    "    # standardize\n",
    "    x = (x - mx) / np.sqrt(s2x)\n",
    "    y = (y - my) / np.sqrt(s2y)\n",
    "\n",
    "    # auto correlation coefficient\n",
    "    acx = []\n",
    "    acy = []\n",
    "    for lag in [1, 2]:\n",
    "        acx.append(np.dot(x[:-lag], x[lag:]) / (N-1))\n",
    "        acy.append(np.dot(y[:-lag], y[lag:]) / (N-1))\n",
    "\n",
    "    # cross correlation coefficient\n",
    "    ccxy = np.dot(x, y) / (N-1)\n",
    "\n",
    "    return np.array([mx, my, np.log(s2x + 1), np.log(s2y + 1)] + acx + acy + [ccxy])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist(stats_1, stats_2):\n",
    "    \"\"\"\n",
    "    Calculates the distance between two vectors of summary statistics. Here the euclidean distance is used.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(np.sum((stats_1 - stats_2) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-081640605363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_smc_abc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-133-b27a89f9ed7e>\u001b[0m in \u001b[0;36mrun_smc_abc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mnsims\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_n_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSimTooLongException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-f20e789de211>\u001b[0m in \u001b[0;36msim_time\u001b[0;34m(self, dt, duration, max_n_steps)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexponential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mreaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscrete_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrates\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_reaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreaction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-f9b3878d968d>\u001b[0m in \u001b[0;36mdiscrete_sample\u001b[0;34m(p, n_samples)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# get the samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_smc_abc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
