{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bebbec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd.numpy import exp\n",
    "from autograd.numpy.linalg import norm \n",
    "from autograd import grad\n",
    "\n",
    "from numpy.random import randn, rand\n",
    "from numpy import log, zeros, eye, vstack\n",
    "from scipy.stats import norm as ndist\n",
    "from scipy.stats import multivariate_normal as MVN\n",
    "from scipy.optimize import fsolve\n",
    "from statsmodels.tsa.stattools import acf \n",
    "\n",
    "from utils import ESS_univariate, ESS, n_unique\n",
    "from tangential_hug_functions import HugTangentialStepEJSD_Deterministic\n",
    "from tangential_hug_functions import Hop_Deterministic\n",
    "from tangential_hug_functions import HugStepEJSD_Deterministic\n",
    "\n",
    "\n",
    "transform = lambda a, b, g, k, z: a + b*(1 + 0.8 * (1 - exp(-g * z)) / (1 + exp(-g * z))) * ((1 + z**2)**k) * z\n",
    "\n",
    "def f(thetau):\n",
    "    \"\"\"Deterministic function for distance manifold. f:R^5 -> R \"\"\"\n",
    "    a_param, b_param, k_param, *z = thetau  # Latents are standard normal variables\n",
    "    z = np.array(z)\n",
    "    out = transform(a_param, b_param, g_true, k_param, z)\n",
    "    return norm(out - y_star)\n",
    "\n",
    "\n",
    "def experiment(x00, T1, T2, N, alphas, nlags):\n",
    "    \"\"\"Runs Hug+Hop and THUG+HOP using the same velocities and the same random seeds.\"\"\"\n",
    "    ### COMMON VARIABLES\n",
    "    v = q.rvs(N)\n",
    "    log_uniforms1 = log(rand(N))     # Log uniforms for the HUG kernels\n",
    "    log_uniforms2 = log(rand(N))     # Log uniforms for the HOP kernel\n",
    "    u = MVN(zeros(5), eye(5)).rvs(N) # Original velocities for HOP kernel\n",
    "    ### STORAGE (HUG + HOP)\n",
    "    hh = x00              # Initial sample\n",
    "    ahh1 = 0.0            # Acceptance probability for HUG kernel\n",
    "    ahh2 = 0.0            # Acceptance probability for HOP kernel (when used with HUG)\n",
    "    ehh = 0.0             # EJSD\n",
    "    eghh = 0.0            # EJSD in Gradient direction\n",
    "    ethh = 0.0            # EJSD in Tangent direction\n",
    "    ### STORAGE (THUG + HOP) I MUST STORE FOR ALL ALPHAS\n",
    "    ath1 = zeros(n_alphas)\n",
    "    ath2 = zeros(n_alphas)\n",
    "    eth  = zeros(n_alphas)\n",
    "    egth = zeros(n_alphas)\n",
    "    etth = zeros(n_alphas)\n",
    "    ### ADDITIONAL STORAGE FOR THUG\n",
    "    th_esst = zeros(n_alphas)\n",
    "    th_essu = zeros(n_alphas)\n",
    "    th_essj = zeros(n_alphas)\n",
    "    th_uniq = zeros(n_alphas)\n",
    "    th_act  = zeros((n_alphas, nlags))\n",
    "    th_acu  = zeros((n_alphas, nlags))\n",
    "    ### HUG + HOP\n",
    "    x = x00\n",
    "    for i in range(N):\n",
    "        y, a1, e, eg, et = HugStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T1, B, q, log_abc_posterior, grad_function)\n",
    "        x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, log_abc_posterior, grad_function)\n",
    "        hh = vstack((hh, y, x))\n",
    "        ahh1 += a1 * 100 / N\n",
    "        ahh2 += a2 * 100 / N\n",
    "        ehh += e / N\n",
    "        eghh += eg / N \n",
    "        ethh += et / N \n",
    "    # COMPUTE ESS AND OTHER METRICS FOR HUG\n",
    "    hh = hh[1:]\n",
    "    hh_esst = ESS_univariate(hh[::2, 0])     # ESS for theta\n",
    "    hh_essu = ESS_univariate(hh[::2, 1])     # ESS for u\n",
    "    hh_essj = ESS(hh[::2])                   # ESS joint\n",
    "    hh_uniq = n_unique(hh)                             # Number of unique samples\n",
    "    hh_act  = acf(hh[::2, 0], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for theta (remove the first 1.0)\n",
    "    hh_acu  = acf(hh[::2, 1], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for u\n",
    "    ### THUG + HOP\n",
    "    for k, alpha in enumerate(alphas):\n",
    "        x = x00\n",
    "        th = x00      # RESTART THE SAMPLES FROM SCRATCH\n",
    "        for i in range(N):\n",
    "            y, a1, e, eg, et = HugTangentialStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T2, B, alpha, q, log_abc_posterior, grad_function)\n",
    "            x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, log_abc_posterior, grad_function)\n",
    "            th = vstack((th, y, x))\n",
    "            ath1[k] += a1 * 100 / N\n",
    "            ath2[k] += a2 * 100 / N\n",
    "            eth[k]  += e / N\n",
    "            egth[k] += eg / N \n",
    "            etth[k] += et / N \n",
    "        ### COMPUTE ESS AND OTHER METRISC FOR THUG\n",
    "        th = th[1:]\n",
    "        th_esst[k] = ESS_univariate(th[::2, 0])     # ESS for theta\n",
    "        th_essu[k] = ESS_univariate(th[::2, 1])     # ESS for u\n",
    "        th_essj[k] = ESS(th[::2])                   # ESS joint\n",
    "        th_uniq[k] = n_unique(th)                             # Number of unique samples\n",
    "        th_act[k] = acf(th[::2, 0], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for theta\n",
    "        th_acu[k] = acf(th[::2, 1], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for u\n",
    "    # RETURN EVERYTHING\n",
    "    out = {\n",
    "        'HH': {\n",
    "            'A1': ahh1,\n",
    "            'A2': ahh2,\n",
    "            'E': ehh,\n",
    "            'EG': eghh, \n",
    "            'ET': ethh,\n",
    "            'ESS_T': hh_esst,\n",
    "            'ESS_U': hh_essu,\n",
    "            'ESS_J': hh_essj,\n",
    "            'UNIQUE': hh_uniq,\n",
    "            'AC_T': hh_act,\n",
    "            'AC_U': hh_acu,\n",
    "            'T': T1,\n",
    "            'SAMPLES': hh\n",
    "        },\n",
    "        'TH': {\n",
    "            'A1': ath1,\n",
    "            'A2': ath2,\n",
    "            'E': eth,\n",
    "            'EG': egth, \n",
    "            'ET': etth, \n",
    "            'ESS_T': th_esst,\n",
    "            'ESS_U': th_essu,\n",
    "            'ESS_J': th_essj,\n",
    "            'UNIQUE': th_uniq,\n",
    "            'AC_T': th_act,\n",
    "            'AC_U': th_acu,\n",
    "            'T': T2,\n",
    "            'SAMPLES': th\n",
    "        }\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "# Prior, Kernel and Posterior\n",
    "def logprior(thetau):\n",
    "    \"\"\"Log prior distribution.\"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return log((abs(thetau[:3]) <= 10).all().astype('float32')) + ndist.logpdf(thetau[-2:]).sum()\n",
    "    \n",
    "def log_uniform_kernel(xi, epsilon):\n",
    "    \"\"\"Log density of uniform kernel. \"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return log(f(xi) <= epsilon)\n",
    "    \n",
    "def log_abc_posterior(xi):\n",
    "    \"\"\"Log density of ABC posterior. Product of (param-latent) prior and uniform kernel.\"\"\"\n",
    "    return logprior(xi) + log_uniform_kernel(xi, epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3a52b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings\n",
    "m = 2                    # Number of latents/observations\n",
    "alphas = [0.95]\n",
    "n_alphas = len(alphas)\n",
    "epsilon = 0.1\n",
    "lam = epsilon / 4\n",
    "kappa = 0.25\n",
    "T1 = T2 = 0.1\n",
    "B = 5\n",
    "N = 5000\n",
    "nlags = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1822ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Parameter Value\n",
    "a_true, b_true, g_true, k_true = 3.0, 1.0, 2.0, 0.5\n",
    "theta0 = np.array([a_true, b_true, k_true])          \n",
    "\n",
    "# Generate Initial Data\n",
    "y_star = transform(*theta0, *randn(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0206bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient function\n",
    "grad_function = grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5fd1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposal for HUG/THUG\n",
    "q = MVN(zeros(5), eye(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdee1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Guess\n",
    "guess = np.array([1.0, 1.0, 1.0, 0.0, 0.0]) \n",
    "func = lambda xi: np.r_[f(xi), 0.0, 0.0, 0.0, 0.0]  # Append 0, 0 to make fsolve work.\n",
    "xi0 = fsolve(func, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e23a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMON VARIABLES\n",
    "x00 = xi0\n",
    "v = q.rvs(N)\n",
    "log_uniforms1 = log(rand(N))     # Log uniforms for the HUG kernels\n",
    "log_uniforms2 = log(rand(N))     # Log uniforms for the HOP kernel\n",
    "u = MVN(zeros(5), eye(5)).rvs(N) # Original velocities for HOP kernel\n",
    "### STORAGE (HUG + HOP)\n",
    "hh = x00              # Initial sample\n",
    "ahh1 = 0.0            # Acceptance probability for HUG kernel\n",
    "ahh2 = 0.0            # Acceptance probability for HOP kernel (when used with HUG)\n",
    "ehh = 0.0             # EJSD\n",
    "eghh = 0.0            # EJSD in Gradient direction\n",
    "ethh = 0.0            # EJSD in Tangent direction\n",
    "### STORAGE (THUG + HOP) I MUST STORE FOR ALL ALPHAS\n",
    "ath1 = zeros(n_alphas)\n",
    "ath2 = zeros(n_alphas)\n",
    "eth  = zeros(n_alphas)\n",
    "egth = zeros(n_alphas)\n",
    "etth = zeros(n_alphas)\n",
    "### ADDITIONAL STORAGE FOR THUG\n",
    "th_esst = zeros(n_alphas)\n",
    "th_essu = zeros(n_alphas)\n",
    "th_essj = zeros(n_alphas)\n",
    "th_uniq = zeros(n_alphas)\n",
    "th_act  = zeros((n_alphas, nlags))\n",
    "th_acu  = zeros((n_alphas, nlags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d99ce00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurocamara/miniforge3/envs/tf_env/lib/python3.8/site-packages/autograd/numpy/linalg.py:89: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return expand(g / ans) * x\n",
      "/Users/maurocamara/miniforge3/envs/tf_env/lib/python3.8/site-packages/autograd/numpy/linalg.py:89: RuntimeWarning: invalid value encountered in multiply\n",
      "  return expand(g / ans) * x\n"
     ]
    }
   ],
   "source": [
    "### HUG + HOP\n",
    "x = x00\n",
    "for i in range(N):\n",
    "    y, a1, e, eg, et = HugStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T1, B, q, log_abc_posterior, grad_function)\n",
    "    x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, log_abc_posterior, grad_function)\n",
    "    hh = vstack((hh, y, x))\n",
    "    ahh1 += a1 * 100 / N\n",
    "    ahh2 += a2 * 100 / N\n",
    "    ehh += e / N\n",
    "    eghh += eg / N \n",
    "    ethh += et / N \n",
    "# COMPUTE ESS AND OTHER METRICS FOR HUG\n",
    "hh = hh[1:]\n",
    "hh_esst = ESS_univariate(hh[::2, 0])     # ESS for theta\n",
    "hh_essu = ESS_univariate(hh[::2, 1])     # ESS for u\n",
    "hh_essj = ESS(hh[::2])                   # ESS joint\n",
    "hh_uniq = n_unique(hh)                             # Number of unique samples\n",
    "hh_act  = acf(hh[::2, 0], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for theta (remove the first 1.0)\n",
    "hh_acu  = acf(hh[::2, 1], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52b3e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THUG + HOP\n",
    "for k, alpha in enumerate(alphas):\n",
    "    x = x00\n",
    "    th = x00      # RESTART THE SAMPLES FROM SCRATCH\n",
    "    for i in range(N):\n",
    "        y, a1, e, eg, et = HugTangentialStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T2, B, alpha, q, log_abc_posterior, grad_function)\n",
    "        x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, log_abc_posterior, grad_function)\n",
    "        th = vstack((th, y, x))\n",
    "        ath1[k] += a1 * 100 / N\n",
    "        ath2[k] += a2 * 100 / N\n",
    "        eth[k]  += e / N\n",
    "        egth[k] += eg / N \n",
    "        etth[k] += et / N \n",
    "    ### COMPUTE ESS AND OTHER METRISC FOR THUG\n",
    "    th = th[1:]\n",
    "    th_esst[k] = ESS_univariate(th[::2, 0])     # ESS for theta\n",
    "    th_essu[k] = ESS_univariate(th[::2, 1])     # ESS for u\n",
    "    th_essj[k] = ESS(th[::2])                   # ESS joint\n",
    "    th_uniq[k] = n_unique(th)                             # Number of unique samples\n",
    "    th_act[k] = acf(th[::2, 0], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for theta\n",
    "    th_acu[k] = acf(th[::2, 1], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a2843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {\n",
    "    'HH': {\n",
    "        'A1': ahh1,\n",
    "        'A2': ahh2,\n",
    "        'E': ehh,\n",
    "        'EG': eghh, \n",
    "        'ET': ethh,\n",
    "        'ESS_T': hh_esst,\n",
    "        'ESS_U': hh_essu,\n",
    "        'ESS_J': hh_essj,\n",
    "        'UNIQUE': hh_uniq,\n",
    "        'AC_T': hh_act,\n",
    "        'AC_U': hh_acu,\n",
    "        'T': T1,\n",
    "        'SAMPLES': hh\n",
    "    },\n",
    "    'TH': {\n",
    "        'A1': ath1,\n",
    "        'A2': ath2,\n",
    "        'E': eth,\n",
    "        'EG': egth, \n",
    "        'ET': etth, \n",
    "        'ESS_T': th_esst,\n",
    "        'ESS_U': th_essu,\n",
    "        'ESS_J': th_essj,\n",
    "        'UNIQUE': th_uniq,\n",
    "        'AC_T': th_act,\n",
    "        'AC_U': th_acu,\n",
    "        'T': T2,\n",
    "        'SAMPLES': th\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41d2b9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94.6599999999983, 49.800000000002186, 0.033701944047393885, 79.82333371420188)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['HH']['A1'], out['HH']['A2'], out['HH']['E'], out['HH']['ESS_J']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b4e3478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.]), array([100.]), array([nan]), array([nan]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['TH']['A1'], out['TH']['A2'], out['TH']['E'], out['TH']['ESS_J']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5c9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
