{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25cb1496",
   "metadata": {},
   "source": [
    "The aim of this experiment is to see how Markov-Snippets THUG behaves compared to SMC-THUG on the G and K problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a20cd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand, randn\n",
    "from numpy import ones, exp, log, diag, vstack, pi, array, r_, isfinite, logspace, zeros, eye\n",
    "from numpy.linalg import norm, solve\n",
    "from numpy.random import default_rng, choice\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.stats import multivariate_normal as MVN\n",
    "from scipy.special import ndtri, ndtr\n",
    "from scipy.stats import uniform as udist\n",
    "from scipy.stats import norm as ndist\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from ipywidgets.widgets import interact\n",
    "import math\n",
    "from warnings import catch_warnings, filterwarnings\n",
    "import time\n",
    "\n",
    "from RWM import RWM\n",
    "from Manifolds.Manifold import Manifold\n",
    "from tangential_hug_functions import HugTangentialMultivariate\n",
    "import arviz\n",
    "from utils import ESS_univariate\n",
    "from seaborn import kdeplot\n",
    "\n",
    "from copy import deepcopy\n",
    "from matplotlib import rc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060bf03",
   "metadata": {},
   "source": [
    "# G and K functions and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e35db5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GKManifold(Manifold):\n",
    "    def __init__(self, ystar):\n",
    "        self.m = len(ystar)            # Number constraints = dimensionality of the data\n",
    "        self.d = 4                     # Manifold has dimension 4 (like the parameter θ)\n",
    "        self.n = self.d + self.m       # Dimension of ambient space is m + 4\n",
    "        self.ystar = ystar\n",
    "        # N(0, 1) ---> U(0, 10).\n",
    "        self.G    = lambda θ: 10*ndtr(θ)\n",
    "        # U(0, 10) ---> N(0, 1)\n",
    "        self.Ginv = lambda θ: ndtri(θ/10)\n",
    "\n",
    "    def q(self, ξ):\n",
    "        \"\"\"Constraint for G and K.\"\"\"\n",
    "        ξ = r_[self.G(ξ[:4]), ξ[4:]]   # expecting theta part to be N(0, 1)\n",
    "        with catch_warnings():\n",
    "            filterwarnings('error')\n",
    "            try:\n",
    "                return (ξ[0] + ξ[1]*(1 + 0.8*(1 - exp(-ξ[2]*ξ[4:]))/(1 + exp(-ξ[2]*ξ[4:]))) * ((1 + ξ[4:]**2)**ξ[3])*ξ[4:]) - self.ystar\n",
    "            except RuntimeWarning:\n",
    "                raise ValueError(\"Constraint found Overflow warning.\")\n",
    "                \n",
    "    def _q_raw_uniform(self, ξ):\n",
    "        \"\"\"Constraint function expecting ξ[:4] ~ U(0, 10). It doesn't do any warning check.\"\"\"\n",
    "        return (ξ[0] + ξ[1]*(1 + 0.8*(1 - exp(-ξ[2]*ξ[4:]))/(1 + exp(-ξ[2]*ξ[4:]))) * ((1 + ξ[4:]**2)**ξ[3])*ξ[4:]) - self.ystar\n",
    "    def _q_raw_normal(self, ξ):\n",
    "        \"\"\"Same as `_q_raw_uniform` except expects ξ[:4]~N(0,1).\"\"\"\n",
    "        ξ = r_[self.G(ξ[:4]), ξ[4:]] \n",
    "        return self._q_raw_uniform(ξ)\n",
    "\n",
    "    def Q(self, ξ):\n",
    "        \"\"\"Transpose of Jacobian for G and K. \"\"\"\n",
    "        ξ = r_[self.G(ξ[:4]), ξ[4:]]\n",
    "        return vstack((\n",
    "        ones(len(ξ[4:])),\n",
    "        (1 + 0.8 * (1 - exp(-ξ[2] * ξ[4:])) / (1 + exp(-ξ[2] * ξ[4:]))) * ((1 + ξ[4:]**2)**ξ[3]) * ξ[4:],\n",
    "        8 * ξ[1] * (ξ[4:]**2) * ((1 + ξ[4:]**2)**ξ[3]) * exp(ξ[2]*ξ[4:]) / (5 * (1 + exp(ξ[2]*ξ[4:]))**2),\n",
    "        ξ[1]*ξ[4:]*((1+ξ[4:]**2)**ξ[3])*(1 + 9*exp(ξ[2]*ξ[4:]))*log(1 + ξ[4:]**2) / (5*(1 + exp(ξ[2]*ξ[4:]))),\n",
    "        diag(ξ[1]*((1+ξ[4:]**2)**(ξ[3]-1))*(((18*ξ[3] + 9)*(ξ[4:]**2) + 9)*exp(2*ξ[2]*ξ[4:]) + (8*ξ[2]*ξ[4:]**3 + (20*ξ[3] + 10)*ξ[4:]**2 + 8*ξ[2]*ξ[4:] + 10)*exp(ξ[2]*ξ[4:]) + (2*ξ[3] + 1)*ξ[4:]**2 + 1) / (5*(1 + exp(ξ[2]*ξ[4:]))**2))\n",
    "    ))\n",
    "    \n",
    "    def J(self, ξ):\n",
    "        \"\"\"Safely computes Jacobian.\"\"\"\n",
    "        with catch_warnings():\n",
    "            filterwarnings('error')\n",
    "            try:\n",
    "                return self.Q(ξ).T\n",
    "            except RuntimeWarning:\n",
    "                raise ValueError(\"J computation found Runtime warning.\")\n",
    "                \n",
    "    def fullJacobian(self, ξ):\n",
    "        \"\"\"J_f(G(ξ)) * J_G(ξ).\"\"\"\n",
    "        JGbar = la.block_diag(10*np.diag(ndist.pdf(ξ[:4])), eye(len(ξ[4:])))\n",
    "        return self.J(ξ) @ JGbar\n",
    "                \n",
    "    def log_parameter_prior(self, θ):\n",
    "        \"\"\"IMPORTANT: Typically the prior distribution is a U(0, 10) for all four parameters.\n",
    "        We keep the same prior but since we don't want to work on a constrained space, we \n",
    "        reparametrize the problem to an unconstrained space N(0, 1).\"\"\"\n",
    "        with catch_warnings():\n",
    "            filterwarnings('error')\n",
    "            try:\n",
    "                return udist.logpdf(self.G(θ), loc=0.0, scale=10.0).sum() + ndist.logpdf(θ).sum()\n",
    "            except RuntimeWarning:\n",
    "                return -np.inf\n",
    "            \n",
    "    def logprior(self, ξ):\n",
    "        \"\"\"Computes the prior distribution for G and K problem. Notice this is already reparametrized.\"\"\"\n",
    "        return self.log_parameter_prior(ξ[:4]) - ξ[4:]@ξ[4:]/2\n",
    "\n",
    "    def logη(self, ξ):\n",
    "        \"\"\"log posterior for c-rwm. This is on the manifold.\"\"\"\n",
    "        try:\n",
    "            J = self.J(ξ)\n",
    "            logprior = self.logprior(ξ)\n",
    "            correction_term  = - math.prod(np.linalg.slogdet(J@J.T))/2 \n",
    "            return  logprior + correction_term\n",
    "        except ValueError as e:\n",
    "            return -np.inf\n",
    "        \n",
    "    def generate_logηϵ(self, ϵ, kernel='normal'):\n",
    "        \"\"\"Returns the log abc posterior for THUG.\"\"\"\n",
    "        if kernel not in ['normal']:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            def log_abc_posterior(ξ):\n",
    "                \"\"\"Log-ABC-posterior.\"\"\"\n",
    "                u = self.q(ξ)\n",
    "                m = len(u)\n",
    "                return self.logprior(ξ) - u@u/(2*ϵ**2) - m*log(ϵ) - m*log(2*pi)/2\n",
    "            return log_abc_posterior\n",
    "            \n",
    "    def logp(self, v):\n",
    "        \"\"\"Log density for normal on the tangent space.\"\"\"\n",
    "        return MVN(mean=zeros(self.d), cov=eye(self.d)).logpdf(v)\n",
    "    \n",
    "    def is_on_manifold(self, ξ, tol=1e-8):\n",
    "        \"\"\"Checks if ξ is on the ystar manifold.\"\"\"\n",
    "        return np.max(abs(self.q(ξ))) < tol\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "OTHER FUNCTIONS\n",
    "\"\"\"    \n",
    "def generate_powers_of_ten(max_exponent, min_exponent):\n",
    "    \"\"\"E.g. generate_powers_of_ten(2, -1) will return 100, 10, 0, 0.1.\"\"\"\n",
    "    number_of_powers = max_exponent + abs(min_exponent) + 1\n",
    "    return logspace(start=max_exponent, stop=min_exponent, num=number_of_powers, endpoint=True)\n",
    "\n",
    "\n",
    "def data_generator(θ0, m, seed):\n",
    "    \"\"\"Stochastic Simulator. Generates y given θ.\"\"\"\n",
    "    rng = default_rng(seed)\n",
    "    z = rng.normal(size=m)\n",
    "    ξ = r_[θ0, z]\n",
    "    return ξ[0] + ξ[1]*(1 + 0.8*(1 - exp(-ξ[2]*ξ[4:]))/(1 + exp(-ξ[2]*ξ[4:]))) * ((1 + ξ[4:]**2)**ξ[3])*ξ[4:]\n",
    "\n",
    "def find_point_on_manifold(ystar, ϵ, max_iter=1000, tol=1.49012e-08):\n",
    "    \"\"\"Find a point on the data manifold.\"\"\"\n",
    "    i = 0\n",
    "    manifold = GKManifold(ystar=ystar)\n",
    "    log_abc_posterior = manifold.generate_logηϵ(ϵ)\n",
    "    with catch_warnings():\n",
    "        filterwarnings('error')\n",
    "        while i <= max_iter:\n",
    "            i += 1\n",
    "            try: \n",
    "                # Sample θ from U(0, 10)\n",
    "                θfixed = randn(4)\n",
    "                function = lambda z: manifold._q_raw_normal(r_[θfixed, z])\n",
    "                z_guess  = randn(manifold.m)\n",
    "                z_found  = fsolve(function, z_guess, xtol=tol)\n",
    "                ξ_found  = r_[θfixed, z_found]\n",
    "                if not isfinite([log_abc_posterior(ξ_found)]):\n",
    "                    pass\n",
    "                else:\n",
    "                    return ξ_found\n",
    "\n",
    "            except RuntimeWarning:\n",
    "                continue\n",
    "        raise ValueError(\"Couldn't find a point, try again.\") \n",
    "        \n",
    "        \n",
    "def find_point_on_manifold_from_θ(ystar, θfixed, ϵ, maxiter=2000, tol=1.49012e-08):\n",
    "    \"\"\"Same as the above but we provide the θfixed. Can be used to find a point where\n",
    "    the theta is already θ0.\"\"\"\n",
    "    i = 0\n",
    "    manifold = GKManifold(ystar=ystar)\n",
    "    log_abc_posterior = manifold.generate_logηϵ(ϵ)\n",
    "    function = lambda z: manifold._q_raw_normal(r_[θfixed, z])\n",
    "    with catch_warnings():\n",
    "        filterwarnings('error')\n",
    "        while i <= maxiter:\n",
    "            i += 1\n",
    "            try:\n",
    "                z_guess  = randn(manifold.m)\n",
    "                z_found  = fsolve(function, z_guess, xtol=tol)\n",
    "                ξ_found  = r_[θfixed, z_found]\n",
    "                if not isfinite([log_abc_posterior(ξ_found)]):\n",
    "                    raise ValueError(\"Couldn't find a point.\")\n",
    "                else:\n",
    "                    return ξ_found\n",
    "            except RuntimeWarning:\n",
    "                continue\n",
    "        raise ValueError(\"Couldn't find a point, try again.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80ce36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_setting(m, ϵs, B, δ, N, thinning=10):\n",
    "    \"\"\"Generates an object from which one can grab the settings. This allows one to run multiple scenarios.\"\"\"\n",
    "    θ0        = array([3.0, 1.0, 2.0, 0.5])      # True parameter value on U(0, 10) scale.\n",
    "    d         = 4 + m                            # Dimensionality of ξ=(θ, z)\n",
    "    ystar     = data_generator(θ0, m, seed=1234) # Observed data\n",
    "    q         = MVN(zeros(d), eye(d))            # Proposal distribution for THUG\n",
    "    ξ0        = find_point_on_manifold_from_θ(ystar=ystar, θfixed=ndtri(θ0/10), ϵ=1e-5, maxiter=5000, tol=1e-15)\n",
    "    manifold  = GKManifold(ystar)\n",
    "    return {\n",
    "        'θ0': θ0,\n",
    "        'm' : m,\n",
    "        'd' : d,\n",
    "        'ystar': ystar,\n",
    "        'q': q,\n",
    "        'ξ0': ξ0,\n",
    "        'ϵs': ϵs,\n",
    "        'B': B,\n",
    "        'δ': δ,\n",
    "        'N': N,\n",
    "        'manifold': manifold,\n",
    "        'thinning': thinning\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68e040",
   "metadata": {},
   "source": [
    "# Multivariate Markov-Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "878d8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_project(v, J):\n",
    "    \"\"\"Projects by solving linear system.\"\"\"\n",
    "    return J.T.dot(solve(J.dot(J.T), J.dot(v)))\n",
    "\n",
    "def THUGIntegratorMultivariate(z0, B, δ):\n",
    "    \"\"\"THUG Integrator for the 2D example (ie using gradients, not jacobians).\"\"\"\n",
    "    trajectory = zeros((B + 1, len(z0)))\n",
    "    x0, v0 = z0[:len(z0)//2], z0[len(z0)//2:]\n",
    "    x, v = x0, v0\n",
    "    trajectory[0, :] = z0\n",
    "    # Integrate\n",
    "    for b in range(B):\n",
    "        x = x + δ*v/2\n",
    "        v = v - 2*linear_project(v, SETTINGS100['manifold'].fullJacobian(x))\n",
    "        x = x + δ*v/2\n",
    "        trajectory[b+1, :] = np.hstack((x, v))\n",
    "    return trajectory\n",
    "\n",
    "def generate_THUGIntegratorMultivariate(B, δ):\n",
    "    \"\"\"Returns a THUG integrator for a given B and δ.\"\"\"\n",
    "    integrator = lambda z: THUGIntegratorMultivariate(z, B, δ)\n",
    "    return integrator\n",
    "\n",
    "\n",
    "#### Metropolis-Hastings version for SMC version\n",
    "def THUG_MH(z0, B, δ, logpi):\n",
    "    \"\"\"Similar to THUGIntegratoUnivariateOnlyEnd but this uses a MH step.\"\"\"\n",
    "    x0, v0 = z0[:len(z0)//2], z0[len(z0)//2:]\n",
    "    x, v = x0, v0\n",
    "    logu = np.log(np.random.rand())\n",
    "    for _ in range(B):\n",
    "        x = x + δ*v/2\n",
    "        v = v - 2*linear_project(v, SETTINGS100['manifold'].fullJacobian(x))\n",
    "        x = x + δ*v/2\n",
    "    if logu <= logpi(x) - logpi(x0):\n",
    "        # accept new point\n",
    "        return np.concatenate((x, v))\n",
    "    else:\n",
    "        # accept old point\n",
    "        return z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aad4894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateMarkovSnippetsTHUG:\n",
    "    \n",
    "    def __init__(self, SETTINGS):\n",
    "        \"\"\"Multivariate Markov Snippets SMC samplers corresponding exactly to Algorithm 1 in Christophe's notes.\n",
    "        It uses the Multivariate THUG kernel as its mutation kernel. The sequence of distributions is fixed here \n",
    "        since we provide ϵs, i.e. a list of tolerances which automatically fully specify the posterior \n",
    "        distributions used at each round.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        :param N: Number of particles\n",
    "        :type N:  int\n",
    "        \n",
    "        :param B: Number of bounces for the THUG integrator. Equivalent to `L` Leapfrog steps in HMC.\n",
    "        :type B: int\n",
    "        \n",
    "        :param δ: Step-size used at each bounce, for the THUG integrator.\n",
    "        :type δ: float\n",
    "        \n",
    "        :param d: Dimensionality of the `x` component of each particle, and equally dimensionality of \n",
    "                  `v` component of each particle. Therefore each particle has dimension `2d`.\n",
    "        \n",
    "        :param ϵs: Tolerances that fully specify the sequence of target filamentary distributions.\n",
    "        :type ϵs: iterable\n",
    "        \"\"\"\n",
    "        # Input variables\n",
    "        self.N  = SETTINGS['N']       \n",
    "        self.B  = SETTINGS['B']\n",
    "        self.δ  = SETTINGS['δ']\n",
    "        self.d  = SETTINGS['d']\n",
    "        self.ϵs = SETTINGS['ϵs']    \n",
    "        self.manifold = SETTINGS['manifold']\n",
    "        self.SETTINGS = SETTINGS\n",
    "        \n",
    "        # Variables derived from the above\n",
    "        self.P  = len(self.ϵs) - 1                                            # Number of target distributions\n",
    "        self.log_ηs = [self.manifold.generate_logηϵ(ϵ) for ϵ in self.ϵs] # List of filamentary distributions \n",
    "        self.ψ = generate_THUGIntegratorMultivariate(self.B, self.δ)\n",
    "    \n",
    "    def initialize_particles(self):\n",
    "        \"\"\"Initialize by sampling with RWM on distribution with ϵ0.\"\"\"\n",
    "        # Initialize first position on the manifold\n",
    "        x0 = self.SETTINGS['ξ0']\n",
    "        # Sample using RWM\n",
    "        burn_in = 100\n",
    "        thinning = 10\n",
    "        TO_BE_THINNED, acceptance = RWM(x0, self.δ, burn_in + thinning*self.N, self.log_ηs[0])\n",
    "        print(\"Initializing particles. Acceptance: \", np.mean(acceptance)*100)\n",
    "        # Thin the samples to obtain the particles\n",
    "        initialized_particles = TO_BE_THINNED[burn_in:][::thinning]\n",
    "        # Refresh velocities and form particles\n",
    "        v0 = np.random.normal(loc=0.0, scale=1.0, size=(self.N, self.d))\n",
    "        z0 = np.hstack((initialized_particles, v0))\n",
    "        self.starting_particles = z0\n",
    "        return z0\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Starts the Markov Snippets sampler.\"\"\"\n",
    "        starting_time = time.time() \n",
    "        N = self.N\n",
    "        B = self.B\n",
    "        ## Storage\n",
    "        #### Store z_n^{(i)}\n",
    "        self.ZN  = np.zeros((self.P+1, N, 2*self.d))\n",
    "        #### Store z_{n, k}^{(i)} so basically all the N(T+1) particles\n",
    "        self.ZNK  = np.zeros((self.P, N*(B+1), 2*self.d))\n",
    "        self.Wbar = np.zeros((self.P, N*(B+1)))\n",
    "        self.ESS  = np.zeros((self.P))\n",
    "        self.K_RESAMPLED = zeros((self.P, self.N))\n",
    "        # Initialize particles\n",
    "        z = self.initialize_particles()   # (N, 2d)\n",
    "        self.ZN[0] = z\n",
    "        # For each target distribution, run the following loop\n",
    "        for n in range(1, self.P+1):\n",
    "            print(\"### Iteration: \", n, \" ϵ = \", self.ϵs[n])\n",
    "            # Compute trajectories\n",
    "            Z = np.apply_along_axis(self.ψ, 1, z) # should have shape (N, B+1, 2d)\n",
    "            self.ZNK[n-1] = Z.reshape(N*(B+1), 2*self.d)\n",
    "            # Compute weights.\n",
    "            #### Log-Denominator: shared for each point in the same trajectory\n",
    "            log_μnm1_z  = np.apply_along_axis(self.log_ηs[n-1], 1, Z[:, 0, :self.d])  # (N, )\n",
    "            log_μnm1_z  = np.repeat(log_μnm1_z, self.B+1, axis=0).reshape(N, B+1)     # (N, B+1)\n",
    "            #### Log-Numerator: different for each point on a trajectory.\n",
    "            log_μn_ψk_z = np.apply_along_axis(self.log_ηs[n], 2, Z[:, :, :self.d])    # (N, B+1)\n",
    "            #### Put weights together\n",
    "            W = exp(log_μn_ψk_z - log_μnm1_z) #np.exp(log_μn_ψk_z - log_μnm1_z)\n",
    "            print(\"W nan: \", np.isnan(W).sum())\n",
    "            print(\"W sum: \", W.sum())\n",
    "            print(\"W min: \", W.min())\n",
    "            print(\"W med: \", np.median(W))\n",
    "            print(\"W max: \", W.max())\n",
    "            #### Normalize weights\n",
    "            W = W / W.sum()\n",
    "            # store weights (remember these are \\bar{w})\n",
    "            self.Wbar[n-1] = W.flatten()\n",
    "            # compute ESS\n",
    "            self.ESS[n-1] = 1 / np.sum(W**2)\n",
    "            print(\"ESS: \", self.ESS[n-1])\n",
    "            # Resample down to N particles\n",
    "            resampling_indeces = choice(a=np.arange(N*(B+1)), size=N, p=W.flatten())\n",
    "            print(\"Unique Indeces: \", len(np.unique(resampling_indeces)))\n",
    "            unravelled_indeces = np.unravel_index(resampling_indeces, (N, B+1))\n",
    "            self.K_RESAMPLED[n-1] = unravelled_indeces[1]\n",
    "            indeces = np.dstack(unravelled_indeces).squeeze()\n",
    "            z = np.vstack([Z[tuple(ix)] for ix in indeces])     # (N, 2d)\n",
    "            \n",
    "            # Rejuvenate velocities of N particles\n",
    "            z[:, self.d:] = np.random.normal(loc=0.0, scale=1.0, size=(N, self.d))\n",
    "            self.ZN[n] = z\n",
    "        self.total_time = time.time() - starting_time\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10841394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 21, 108)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(MSTHUG.ψ, 1, MSTHUG.starting_particles).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "131e6456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing particles. Acceptance:  65.78217821782178\n",
      "### Iteration:  1  ϵ =  5.0\n",
      "W nan:  0\n",
      "W sum:  3.45756072943243e+16\n",
      "W min:  29426.48701357718\n",
      "W med:  474678010603.9958\n",
      "W max:  158831845252365.28\n",
      "ESS:  2470.424331823293\n",
      "Unique Indeces:  862\n",
      "### Iteration:  2  ϵ =  2.0\n",
      "W nan:  0\n",
      "W sum:  137015689798825.6\n",
      "W min:  7.426448642393035e-17\n",
      "W med:  101.21397756528955\n",
      "W max:  1488040911023.8955\n",
      "ESS:  255.270732790487\n",
      "Unique Indeces:  362\n",
      "### Iteration:  3  ϵ =  1.5\n",
      "W nan:  0\n",
      "W sum:  629.5153263192589\n",
      "W min:  7.176933172726405e-07\n",
      "W med:  0.02433554191135299\n",
      "W max:  0.9105854467307908\n",
      "ESS:  6954.364949233977\n",
      "Unique Indeces:  929\n",
      "### Iteration:  4  ϵ =  1.0\n",
      "W nan:  0\n",
      "W sum:  7.497453293768899e-10\n",
      "W min:  6.801253816976773e-18\n",
      "W med:  2.961926950023106e-14\n",
      "W max:  2.753043754789736e-12\n",
      "ESS:  6183.3439564296295\n",
      "Unique Indeces:  932\n",
      "### Iteration:  5  ϵ =  0.75\n",
      "W nan:  0\n",
      "W sum:  2.7339282412411065e-21\n",
      "W min:  1.2340548756615851e-28\n",
      "W med:  1.0324824984483028e-25\n",
      "W max:  9.517393083508094e-24\n",
      "ESS:  5752.133512531586\n",
      "Unique Indeces:  916\n",
      "### Iteration:  6  ϵ =  0.5\n",
      "W nan:  0\n",
      "W sum:  1.2433172361582967e-76\n",
      "W min:  1.2268228479817378e-83\n",
      "W med:  4.924178183062619e-81\n",
      "W max:  1.8351040951215566e-79\n",
      "ESS:  8429.314889357749\n",
      "Unique Indeces:  955\n",
      "### Iteration:  7  ϵ =  0.25\n",
      "W nan:  0\n",
      "W sum:  0.0\n",
      "W min:  0.0\n",
      "W med:  0.0\n",
      "W max:  0.0\n",
      "ESS:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/dthljx8x5mldm2ll5_zz7xrr0000gn/T/ipykernel_63090/3557207091.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "  W = W / W.sum()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m MSTHUG \u001b[38;5;241m=\u001b[39m MultivariateMarkovSnippetsTHUG(SETTINGS50)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Sample\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m zP \u001b[38;5;241m=\u001b[39m \u001b[43mMSTHUG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36mMultivariateMarkovSnippetsTHUG.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mESS: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mESS[n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Resample down to N particles\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m resampling_indeces \u001b[38;5;241m=\u001b[39m \u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique Indeces: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(resampling_indeces)))\n\u001b[1;32m    103\u001b[0m unravelled_indeces \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munravel_index(resampling_indeces, (N, B\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32mmtrand.pyx:935\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "ϵs = [10.0, 5.0, 2.0, 1.5, 1.0, 0.75, 0.5, 0.25, 0.1, 0.07] #np.geomspace(start=1.0, stop=1e-6, num=20)\n",
    "SETTINGS50 = generate_setting(m=50, ϵs=ϵs, B=20, δ=0.01, N=1000, thinning=20)\n",
    "# Instantitate the algorithm\n",
    "MSTHUG = MultivariateMarkovSnippetsTHUG(SETTINGS50)\n",
    "# Sample\n",
    "zP = MSTHUG.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(n):\n",
    "    fig, ax = plt.subplots(figsize=(20, 4))\n",
    "    _, bins, _ = ax.hist(MSTHUG.K_RESAMPLED[n, :], density=True, bins=SETTINGS50['B'], edgecolor='k', color='lightsalmon')\n",
    "    ax.set_xticks(bins)\n",
    "    ax.set_xticklabels(bins.astype(int))\n",
    "    return plt.show()\n",
    "    \n",
    "interact(plot_histogram, n=(0, len(ϵs) - 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfaf436",
   "metadata": {},
   "source": [
    "# SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d59c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateMarkovSnippetsTHUGMetropolised:\n",
    "    \n",
    "    def __init__(self, SETTINGS):\n",
    "        \"\"\"Metropolised version: for each particle compute the endpoint of trajectory and its weight.\n",
    "        If the weight is positive, we accept the final point, otherwise we accept the initial point. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        :param N: Number of particles\n",
    "        :type N:  int\n",
    "        \n",
    "        :param B: Number of bounces for the THUG integrator. Equivalent to `L` Leapfrog steps in HMC.\n",
    "        :type B: int\n",
    "        \n",
    "        :param δ: Step-size used at each bounce, for the THUG integrator.\n",
    "        :type δ: float\n",
    "        \n",
    "        :param d: Dimensionality of the `x` component of each particle, and equally dimensionality of \n",
    "                  `v` component of each particle. Therefore each particle has dimension `2d`.\n",
    "        \n",
    "        :param ϵs: Tolerances that fully specify the sequence of target filamentary distributions.\n",
    "        :type ϵs: iterable\n",
    "        \"\"\"\n",
    "        # Input variables\n",
    "        self.N  = SETTINGS['N']       \n",
    "        self.δ  = SETTINGS['δ']\n",
    "        self.d  = SETTINGS['d']\n",
    "        self.ϵs = SETTINGS['ϵs']\n",
    "        self.manifold = SETTINGS['manifold']\n",
    "        self.SETTINGS = SETTINGS\n",
    "        self.B = SETTINGS['B']\n",
    "        \n",
    "        # Variables derived from the above\n",
    "        self.P  = len(self.ϵs) - 1                                       # Number of target distributions\n",
    "        self.log_ηs = [self.manifold.generate_logηϵ(ϵ) for ϵ in self.ϵs]     # List of filamentary distributions \n",
    "        \n",
    "    \n",
    "    def initialize_particles(self):\n",
    "        \"\"\"To initialize particles, we sample from a uniform on a large rectangle.\n",
    "        A rectangle of size [-100, 100] should be plenty large.\"\"\"\n",
    "        # Initialize particles by sampling from η_ϵ0 for a large ϵ0 which can be given as an argument.\n",
    "        # Sample a point from the prior\n",
    "        x0 = self.SETTINGS['ξ0']\n",
    "        # Use RWM starting from x0\n",
    "        burn_in = 100\n",
    "        TO_BE_THINNED, _ = RWM(x0, self.δ, burn_in + 10*self.N, self.log_ηs[0])\n",
    "        # Thin the samples to obtain the particles\n",
    "        initialized_particles = TO_BE_THINNED[burn_in:][::10]\n",
    "        v0 = np.random.normal(loc=0.0, scale=1.0, size=(self.N, self.d))\n",
    "        z0 = np.hstack((initialized_particles, v0))\n",
    "        self.starting_particles = z0\n",
    "        return z0\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Starts the Markov Snippets sampler.\"\"\"\n",
    "        starting_time = time.time()\n",
    "        # Initialize particles\n",
    "        z = self.initialize_particles()   # (N, 2d)\n",
    "        # Storage\n",
    "        self.PARTICLES    = zeros((self.P+1, self.N, 2*self.d))\n",
    "        self.PARTICLES[0] = z\n",
    "        self.WEIGHTS      = zeros((self.P+1, self.N))\n",
    "        self.WEIGHTS[0]   = 1 / self.N\n",
    "        self.ESS          = zeros(self.P+1)\n",
    "        self.ESS[0]       = 1 / np.sum(self.WEIGHTS[0]**2)\n",
    "        # For each target distribution, run the following loop\n",
    "        for n in range(1, self.P+1):\n",
    "            # Standard SMC sampler, we mutate the particles and then we resample\n",
    "            ### Mutation step: \n",
    "            ###### Refresh velocities\n",
    "            z[:, self.d:] = np.random.normal(loc=0.0, scale=1.0, size=(self.N, self.d))\n",
    "            ###### Mutate positions \n",
    "            M = lambda z: THUG_MH(z, self.B, self.δ, self.log_ηs[n-1])\n",
    "            Z = np.apply_along_axis(M, 1, z)\n",
    "            ### Compute weights\n",
    "            # Notice in this case the weight is different because we are not using the uniform kernel anymore\n",
    "            # Importantly: this is now the INCREMENTAL weight and so has to be multiplied by the previous one.\n",
    "            w_incremental = exp(np.apply_along_axis(self.log_ηs[n], 1, Z[:, :self.d]) - np.apply_along_axis(self.log_ηs[n-1], 1, Z[:, :self.d]))\n",
    "#             w = (abs(np.apply_along_axis(f, 1, Z[:, :p]) - level_set_value) <= self.ϵs[n]).astype(float)\n",
    "            w = self.WEIGHTS[n-1] * w_incremental\n",
    "            w = w / w.sum()\n",
    "            self.WEIGHTS[n] = w\n",
    "            self.ESS[n]     = 1 / np.sum(w**2)\n",
    "            ### Resample\n",
    "            indeces = choice(a=np.arange(self.N), size=self.N, p=w)\n",
    "            z = z[indeces, :]\n",
    "            self.PARTICLES[n] = z\n",
    "        self.total_time = time.time() - starting_time\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "296c62f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/dthljx8x5mldm2ll5_zz7xrr0000gn/T/ipykernel_63090/1779483409.py:82: RuntimeWarning: invalid value encountered in true_divide\n",
      "  w = w / w.sum()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m MSTHUG_METROP \u001b[38;5;241m=\u001b[39m MultivariateMarkovSnippetsTHUGMetropolised(SETTINGS50)\n\u001b[0;32m----> 2\u001b[0m zP_metrop \u001b[38;5;241m=\u001b[39m \u001b[43mMSTHUG_METROP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mMultivariateMarkovSnippetsTHUGMetropolised.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mESS[n]     \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(w\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m### Resample\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m indeces \u001b[38;5;241m=\u001b[39m \u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m z \u001b[38;5;241m=\u001b[39m z[indeces, :]\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPARTICLES[n] \u001b[38;5;241m=\u001b[39m z\n",
      "File \u001b[0;32mmtrand.pyx:935\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "MSTHUG_METROP = MultivariateMarkovSnippetsTHUGMetropolised(SETTINGS50)\n",
    "zP_metrop = MSTHUG_METROP.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0946c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
