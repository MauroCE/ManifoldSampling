{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b7e2df",
   "metadata": {},
   "source": [
    "The aim of this experiment is to see how Markov-Snippets THUG behaves compared to SMC-THUG on the G and K problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e46f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand, randn\n",
    "from numpy import ones, exp, log, diag, vstack, pi, array, r_, isfinite, logspace, zeros, eye\n",
    "from numpy.linalg import norm, solve\n",
    "from numpy.random import default_rng, choice\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.stats import multivariate_normal as MVN\n",
    "from scipy.special import ndtri, ndtr\n",
    "from scipy.stats import uniform as udist\n",
    "from scipy.stats import norm as ndist\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "import time\n",
    "from math import prod\n",
    "from warnings import catch_warnings, filterwarnings, resetwarnings\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from ipywidgets.widgets import interact\n",
    "\n",
    "\n",
    "from RWM import RWM\n",
    "from Manifolds.Manifold import Manifold\n",
    "from tangential_hug_functions import HugTangentialMultivariate\n",
    "from utils import ESS_univariate, prep_contour\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee73c21",
   "metadata": {},
   "source": [
    "# G and K functions and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4760afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GKManifold(Manifold):\n",
    "    def __init__(self, ystar):\n",
    "        self.m = len(ystar)            # Number constraints = dimensionality of the data\n",
    "        self.d = 4                     # Manifold has dimension 4 (like the parameter θ)\n",
    "        self.n = self.d + self.m       # Dimension of ambient space is m + 4\n",
    "        self.ystar = ystar\n",
    "        # N(0, 1) ---> U(0, 10).\n",
    "        self.G    = lambda θ: 10*ndtr(θ)\n",
    "        # U(0, 10) ---> N(0, 1)\n",
    "        self.Ginv = lambda θ: ndtri(θ/10)\n",
    "\n",
    "    def q(self, ξ):\n",
    "        \"\"\"Constraint for G and K.\"\"\"\n",
    "        ξ = r_[self.G(ξ[:4]), ξ[4:]]   # expecting theta part to be N(0, 1)\n",
    "        with catch_warnings():\n",
    "            filterwarnings('error')\n",
    "            try:\n",
    "                return (ξ[0] + ξ[1]*(1 + 0.8*(1 - exp(-ξ[2]*ξ[4:]))/(1 + exp(-ξ[2]*ξ[4:]))) * ((1 + ξ[4:]**2)**ξ[3])*ξ[4:]) - self.ystar\n",
    "            except RuntimeWarning:\n",
    "                raise ValueError(\"Constraint found Overflow warning.\")\n",
    "                \n",
    "    def _q_raw_uniform(self, ξ):\n",
    "        \"\"\"Constraint function expecting ξ[:4] ~ U(0, 10). It doesn't do any warning check.\"\"\"\n",
    "        return (ξ[0] + ξ[1]*(1 + 0.8*(1 - exp(-ξ[2]*ξ[4:]))/(1 + exp(-ξ[2]*ξ[4:]))) * ((1 + ξ[4:]**2)**ξ[3])*ξ[4:]) - self.ystar\n",
    "    def _q_raw_normal(self, ξ):\n",
    "        \"\"\"Same as `_q_raw_uniform` except expects ξ[:4]~N(0,1).\"\"\"\n",
    "        ξ = r_[self.G(ξ[:4]), ξ[4:]] \n",
    "        return self._q_raw_uniform(ξ)\n",
    "\n",
    "    def Q(self, ξ):\n",
    "        \"\"\"Transpose of Jacobian for G and K. \"\"\"\n",
    "        ξ = r_[self.G(ξ[:4]), ξ[4:]]\n",
    "        return vstack((\n",
    "        ones(len(ξ[4:])),\n",
    "        (1 + 0.8 * (1 - exp(-ξ[2] * ξ[4:])) / (1 + exp(-ξ[2] * ξ[4:]))) * ((1 + ξ[4:]**2)**ξ[3]) * ξ[4:],\n",
    "        8 * ξ[1] * (ξ[4:]**2) * ((1 + ξ[4:]**2)**ξ[3]) * exp(ξ[2]*ξ[4:]) / (5 * (1 + exp(ξ[2]*ξ[4:]))**2),\n",
    "        ξ[1]*ξ[4:]*((1+ξ[4:]**2)**ξ[3])*(1 + 9*exp(ξ[2]*ξ[4:]))*log(1 + ξ[4:]**2) / (5*(1 + exp(ξ[2]*ξ[4:]))),\n",
    "        diag(ξ[1]*((1+ξ[4:]**2)**(ξ[3]-1))*(((18*ξ[3] + 9)*(ξ[4:]**2) + 9)*exp(2*ξ[2]*ξ[4:]) + (8*ξ[2]*ξ[4:]**3 + (20*ξ[3] + 10)*ξ[4:]**2 + 8*ξ[2]*ξ[4:] + 10)*exp(ξ[2]*ξ[4:]) + (2*ξ[3] + 1)*ξ[4:]**2 + 1) / (5*(1 + exp(ξ[2]*ξ[4:]))**2))\n",
    "    ))\n",
    "    \n",
    "    def J(self, ξ):\n",
    "        \"\"\"Safely computes Jacobian.\"\"\"\n",
    "        with catch_warnings():\n",
    "            filterwarnings('error')\n",
    "            try:\n",
    "                return self.Q(ξ).T\n",
    "            except RuntimeWarning:\n",
    "                raise ValueError(\"J computation found Runtime warning.\")\n",
    "                \n",
    "    def fullJacobian(self, ξ):\n",
    "        \"\"\"J_f(G(ξ)) * J_G(ξ).\"\"\"\n",
    "        JGbar = block_diag(10*np.diag(ndist.pdf(ξ[:4])), eye(len(ξ[4:])))\n",
    "        return self.J(ξ) @ JGbar\n",
    "                \n",
    "    def log_parameter_prior(self, θ):\n",
    "        \"\"\"IMPORTANT: Typically the prior distribution is a U(0, 10) for all four parameters.\n",
    "        We keep the same prior but since we don't want to work on a constrained space, we \n",
    "        reparametrize the problem to an unconstrained space N(0, 1).\"\"\"\n",
    "        with catch_warnings():\n",
    "            filterwarnings('error')\n",
    "            try:\n",
    "                return udist.logpdf(self.G(θ), loc=0.0, scale=10.0).sum() + ndist.logpdf(θ).sum()\n",
    "            except RuntimeWarning:\n",
    "                return -np.inf\n",
    "            \n",
    "    def logprior(self, ξ):\n",
    "        \"\"\"Computes the prior distribution for G and K problem. Notice this is already reparametrized.\"\"\"\n",
    "        return self.log_parameter_prior(ξ[:4]) - ξ[4:]@ξ[4:]/2\n",
    "\n",
    "    def logη(self, ξ):\n",
    "        \"\"\"log posterior for c-rwm. This is on the manifold.\"\"\"\n",
    "        try:\n",
    "            J = self.J(ξ)\n",
    "            logprior = self.logprior(ξ)\n",
    "            correction_term  = - prod(np.linalg.slogdet(J@J.T))/2 \n",
    "            return  logprior + correction_term\n",
    "        except ValueError as e:\n",
    "            return -np.inf\n",
    "        \n",
    "    def generate_logηϵ(self, ϵ, kernel='normal'):\n",
    "        \"\"\"Returns the log abc posterior for THUG.\"\"\"\n",
    "        if kernel not in ['normal']:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            def log_abc_posterior(ξ):\n",
    "                \"\"\"Log-ABC-posterior.\"\"\"\n",
    "                u = self.q(ξ)\n",
    "                m = len(u)\n",
    "                return self.logprior(ξ) - u@u/(2*ϵ**2) - m*log(ϵ) - m*log(2*pi)/2\n",
    "            return log_abc_posterior\n",
    "            \n",
    "    def logp(self, v):\n",
    "        \"\"\"Log density for normal on the tangent space.\"\"\"\n",
    "        return MVN(mean=zeros(self.d), cov=eye(self.d)).logpdf(v)\n",
    "    \n",
    "    def is_on_manifold(self, ξ, tol=1e-8):\n",
    "        \"\"\"Checks if ξ is on the ystar manifold.\"\"\"\n",
    "        return np.max(abs(self.q(ξ))) < tol\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "OTHER FUNCTIONS\n",
    "\"\"\"    \n",
    "def generate_powers_of_ten(max_exponent, min_exponent):\n",
    "    \"\"\"E.g. generate_powers_of_ten(2, -1) will return 100, 10, 0, 0.1.\"\"\"\n",
    "    number_of_powers = max_exponent + abs(min_exponent) + 1\n",
    "    return logspace(start=max_exponent, stop=min_exponent, num=number_of_powers, endpoint=True)\n",
    "\n",
    "\n",
    "def data_generator(θ0, m, seed):\n",
    "    \"\"\"Stochastic Simulator. Generates y given θ.\"\"\"\n",
    "    rng = default_rng(seed)\n",
    "    z = rng.normal(size=m)\n",
    "    ξ = r_[θ0, z]\n",
    "    return ξ[0] + ξ[1]*(1 + 0.8*(1 - exp(-ξ[2]*ξ[4:]))/(1 + exp(-ξ[2]*ξ[4:]))) * ((1 + ξ[4:]**2)**ξ[3])*ξ[4:]\n",
    "\n",
    "def find_point_on_manifold(ystar, ϵ, max_iter=1000, tol=1.49012e-08):\n",
    "    \"\"\"Find a point on the data manifold.\"\"\"\n",
    "    i = 0\n",
    "    manifold = GKManifold(ystar=ystar)\n",
    "    log_abc_posterior = manifold.generate_logηϵ(ϵ)\n",
    "    with catch_warnings():\n",
    "        filterwarnings('error')\n",
    "        while i <= max_iter:\n",
    "            i += 1\n",
    "            try: \n",
    "                # Sample θ from U(0, 10)\n",
    "                θfixed = randn(4)\n",
    "                function = lambda z: manifold._q_raw_normal(r_[θfixed, z])\n",
    "                z_guess  = randn(manifold.m)\n",
    "                z_found  = fsolve(function, z_guess, xtol=tol)\n",
    "                ξ_found  = r_[θfixed, z_found]\n",
    "                if not isfinite([log_abc_posterior(ξ_found)]):\n",
    "                    pass\n",
    "                else:\n",
    "                    resetwarnings()\n",
    "                    return ξ_found\n",
    "\n",
    "            except RuntimeWarning:\n",
    "                continue\n",
    "        resetwarnings()\n",
    "        raise ValueError(\"Couldn't find a point, try again.\") \n",
    "        \n",
    "        \n",
    "def find_point_on_manifold_from_θ(ystar, θfixed, ϵ, maxiter=2000, tol=1.49012e-08):\n",
    "    \"\"\"Same as the above but we provide the θfixed. Can be used to find a point where\n",
    "    the theta is already θ0.\"\"\"\n",
    "    i = 0\n",
    "    manifold = GKManifold(ystar=ystar)\n",
    "    log_abc_posterior = manifold.generate_logηϵ(ϵ)\n",
    "    function = lambda z: manifold._q_raw_normal(r_[θfixed, z])\n",
    "    with catch_warnings():\n",
    "        filterwarnings('error')\n",
    "        while i <= maxiter:\n",
    "            i += 1\n",
    "            try:\n",
    "                z_guess  = randn(manifold.m)\n",
    "                z_found  = fsolve(function, z_guess, xtol=tol)\n",
    "                ξ_found  = r_[θfixed, z_found]\n",
    "                if not isfinite([log_abc_posterior(ξ_found)]):\n",
    "                    resetwarnings()\n",
    "                    raise ValueError(\"Couldn't find a point.\")\n",
    "                else:\n",
    "                    resetwarnings()\n",
    "                    return ξ_found\n",
    "            except RuntimeWarning:\n",
    "                continue\n",
    "        resetwarnings()\n",
    "        raise ValueError(\"Couldn't find a point, try again.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b20607d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_setting(m, ϵs, B, δ, N, thinning=10):\n",
    "    \"\"\"Generates an object from which one can grab the settings. This allows one to run multiple scenarios.\"\"\"\n",
    "    θ0        = array([3.0, 1.0, 2.0, 0.5])      # True parameter value on U(0, 10) scale.\n",
    "    d         = 4 + m                            # Dimensionality of ξ=(θ, z)\n",
    "    ystar     = data_generator(θ0, m, seed=1234) # Observed data\n",
    "    q         = MVN(zeros(d), eye(d))            # Proposal distribution for THUG\n",
    "    ξ0        = find_point_on_manifold_from_θ(ystar=ystar, θfixed=ndtri(θ0/10), ϵ=1e-5, maxiter=5000, tol=1e-15)\n",
    "    resetwarnings()\n",
    "    manifold  = GKManifold(ystar)\n",
    "    return {\n",
    "        'θ0': θ0,\n",
    "        'm' : m,\n",
    "        'd' : d,\n",
    "        'ystar': ystar,\n",
    "        'q': q,\n",
    "        'ξ0': ξ0,\n",
    "        'ϵs': ϵs,\n",
    "        'B': B,\n",
    "        'δ': δ,\n",
    "        'N': N,\n",
    "        'manifold': manifold,\n",
    "        'thinning': thinning\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c29ac",
   "metadata": {},
   "source": [
    "# Multivariate Markov-Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a8689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_project(v, J):\n",
    "    \"\"\"Projects by solving linear system.\"\"\"\n",
    "    return J.T.dot(solve(J.dot(J.T), J.dot(v)))\n",
    "\n",
    "def THUGIntegratorMultivariate(z0, B, δ):\n",
    "    \"\"\"THUG Integrator for the 2D example (ie using gradients, not jacobians).\"\"\"\n",
    "    trajectory = zeros((B + 1, len(z0)))\n",
    "    x0, v0 = z0[:len(z0)//2], z0[len(z0)//2:]\n",
    "    x, v = x0, v0\n",
    "    trajectory[0, :] = z0\n",
    "    # Integrate\n",
    "    for b in range(B):\n",
    "        x = x + δ*v/2\n",
    "        v = v - 2*linear_project(v, SETTINGS50['manifold'].fullJacobian(x))\n",
    "        x = x + δ*v/2\n",
    "        trajectory[b+1, :] = np.hstack((x, v))\n",
    "    return trajectory\n",
    "\n",
    "def generate_THUGIntegratorMultivariate(B, δ):\n",
    "    \"\"\"Returns a THUG integrator for a given B and δ.\"\"\"\n",
    "    integrator = lambda z: THUGIntegratorMultivariate(z, B, δ)\n",
    "    return integrator\n",
    "\n",
    "\n",
    "#### Metropolis-Hastings version for SMC version\n",
    "def THUG_MH(z0, B, δ, logpi):\n",
    "    \"\"\"Similar to THUGIntegratoUnivariateOnlyEnd but this uses a MH step.\"\"\"\n",
    "    x0, v0 = z0[:len(z0)//2], z0[len(z0)//2:]\n",
    "    x, v = x0, v0\n",
    "    logu = np.log(np.random.rand())\n",
    "    for _ in range(B):\n",
    "        x = x + δ*v/2\n",
    "        v = v - 2*linear_project(v, SETTINGS50['manifold'].fullJacobian(x))\n",
    "        x = x + δ*v/2\n",
    "    if logu <= logpi(x) - logpi(x0):\n",
    "        # accept new point\n",
    "        return np.concatenate((x, v))\n",
    "    else:\n",
    "        # accept old point\n",
    "        return z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b9f924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateMarkovSnippetsTHUG:\n",
    "    \n",
    "    def __init__(self, SETTINGS):\n",
    "        \"\"\"Multivariate Markov Snippets SMC samplers corresponding exactly to Algorithm 1 in Christophe's notes.\n",
    "        It uses the Multivariate THUG kernel as its mutation kernel. The sequence of distributions is fixed here \n",
    "        since we provide ϵs, i.e. a list of tolerances which automatically fully specify the posterior \n",
    "        distributions used at each round.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        :param N: Number of particles\n",
    "        :type N:  int\n",
    "        \n",
    "        :param B: Number of bounces for the THUG integrator. Equivalent to `L` Leapfrog steps in HMC.\n",
    "        :type B: int\n",
    "        \n",
    "        :param δ: Step-size used at each bounce, for the THUG integrator.\n",
    "        :type δ: float\n",
    "        \n",
    "        :param d: Dimensionality of the `x` component of each particle, and equally dimensionality of \n",
    "                  `v` component of each particle. Therefore each particle has dimension `2d`.\n",
    "        \n",
    "        :param ϵs: Tolerances that fully specify the sequence of target filamentary distributions.\n",
    "        :type ϵs: iterable\n",
    "        \"\"\"\n",
    "        # Input variables\n",
    "        self.N  = SETTINGS['N']       \n",
    "        self.B  = SETTINGS['B']\n",
    "        self.δ  = SETTINGS['δ']\n",
    "        self.d  = SETTINGS['d']\n",
    "        self.ϵs = SETTINGS['ϵs']    \n",
    "        self.manifold = SETTINGS['manifold']\n",
    "        self.SETTINGS = SETTINGS\n",
    "        \n",
    "        # Variables derived from the above\n",
    "        self.P  = len(self.ϵs) - 1                                            # Number of target distributions\n",
    "        self.log_ηs = [self.manifold.generate_logηϵ(ϵ) for ϵ in self.ϵs] # List of filamentary distributions \n",
    "        self.ψ = generate_THUGIntegratorMultivariate(self.B, self.δ)\n",
    "    \n",
    "    def initialize_particles(self):\n",
    "        \"\"\"Initialize by sampling with RWM on distribution with ϵ0.\"\"\"\n",
    "        # Initialize first position on the manifold\n",
    "        x0 = self.SETTINGS['ξ0']\n",
    "        # Sample using RWM\n",
    "        burn_in = 100\n",
    "        thinning = 10\n",
    "        ### try initializing using Tangential Hug as MCMC kernel?\n",
    "        #TO_BE_THINNED, acceptance = RWM(x0, self.δ, burn_in + thinning*self.N, self.log_ηs[0])\n",
    "        q = MVN(zeros(self.d), eye(self.d))\n",
    "        TO_BE_THINNED, acceptance = HugTangentialMultivariate(x0, self.B*self.δ, self.B, burn_in + thinning*self.N, 0.0, q, self.log_ηs[0], self.manifold.fullJacobian, method='linear')\n",
    "        print(\"Initializing particles. Acceptance: \", np.mean(acceptance)*100)\n",
    "        # Thin the samples to obtain the particles\n",
    "        initialized_particles = TO_BE_THINNED[burn_in:][::thinning]\n",
    "        # Refresh velocities and form particles\n",
    "        v0 = np.random.normal(loc=0.0, scale=1.0, size=(self.N, self.d))\n",
    "        z0 = np.hstack((initialized_particles, v0))\n",
    "        self.starting_particles = z0\n",
    "        return z0\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Starts the Markov Snippets sampler.\"\"\"\n",
    "        starting_time = time.time() \n",
    "        N = self.N\n",
    "        B = self.B\n",
    "        ## Storage\n",
    "        #### Store z_n^{(i)}\n",
    "        self.ZN  = np.zeros((self.P+1, N, 2*self.d))\n",
    "        #### Store z_{n, k}^{(i)} so basically all the N(T+1) particles\n",
    "        self.ZNK  = np.zeros((self.P, N*(B+1), 2*self.d))\n",
    "        self.Wbar = np.zeros((self.P, N*(B+1)))\n",
    "        self.ESS  = np.zeros((self.P))\n",
    "        self.K_RESAMPLED = zeros((self.P, self.N))\n",
    "        # Initialize particles\n",
    "        z = self.initialize_particles()   # (N, 2d)\n",
    "        self.ZN[0] = z\n",
    "        # For each target distribution, run the following loop\n",
    "        for n in range(1, self.P+1):\n",
    "            # Compute trajectories\n",
    "            Z = np.apply_along_axis(self.ψ, 1, z) # should have shape (N, B+1, 2d)\n",
    "            self.ZNK[n-1] = Z.reshape(N*(B+1), 2*self.d)\n",
    "            # Compute weights.\n",
    "            #### Log-Denominator: shared for each point in the same trajectory\n",
    "            log_μnm1_z  = np.apply_along_axis(self.log_ηs[n-1], 1, Z[:, 0, :self.d])  # (N, )\n",
    "            log_μnm1_z  = np.repeat(log_μnm1_z, self.B+1, axis=0).reshape(N, B+1)     # (N, B+1)\n",
    "            #### Log-Numerator: different for each point on a trajectory.\n",
    "            log_μn_ψk_z = np.apply_along_axis(self.log_ηs[n], 2, Z[:, :, :self.d])    # (N, B+1)\n",
    "            #### Put weights together\n",
    "            W = exp(log_μn_ψk_z - log_μnm1_z) #np.exp(log_μn_ψk_z - log_μnm1_z)\n",
    "            #### Normalize weights\n",
    "            W = W / W.sum()\n",
    "            # store weights (remember these are \\bar{w})\n",
    "            self.Wbar[n-1] = W.flatten()\n",
    "            # compute ESS\n",
    "            self.ESS[n-1] = 1 / np.sum(W**2)\n",
    "            # Resample down to N particles\n",
    "            resampling_indeces = choice(a=np.arange(N*(B+1)), size=N, p=W.flatten())\n",
    "            unravelled_indeces = np.unravel_index(resampling_indeces, (N, B+1))\n",
    "            self.K_RESAMPLED[n-1] = unravelled_indeces[1]\n",
    "            indeces = np.dstack(unravelled_indeces).squeeze()\n",
    "            z = np.vstack([Z[tuple(ix)] for ix in indeces])     # (N, 2d)\n",
    "            \n",
    "            # Rejuvenate velocities of N particles\n",
    "            z[:, self.d:] = np.random.normal(loc=0.0, scale=1.0, size=(N, self.d))\n",
    "            self.ZN[n] = z\n",
    "        self.total_time = time.time() - starting_time\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489ec1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91731f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae4466b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing particles. Acceptance:  48.119760479041915\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "#ϵs = [10.0, 5.0, 2.0, 1.5, 1.0, 0.75, 0.5, 0.25, 0.1, 0.07] #np.geomspace(start=1.0, stop=1e-6, num=20)\n",
    "#ϵs = [10.0, 1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "ϵs = [10.0, 5.0, 1.0, 0.5, 0.1, 0.05, 0.001, 0.0005, 0.0001, 0.00005]\n",
    "SETTINGS50 = generate_setting(m=50, ϵs=ϵs, B=20, δ=0.01, N=5000, thinning=20)\n",
    "# Instantitate the algorithm\n",
    "MSTHUG = MultivariateMarkovSnippetsTHUG(SETTINGS50)\n",
    "# Sample\n",
    "zP = MSTHUG.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe1855",
   "metadata": {},
   "source": [
    "# SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c128fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateMarkovSnippetsTHUGMetropolised:\n",
    "    \n",
    "    def __init__(self, SETTINGS):\n",
    "        \"\"\"Metropolised version: for each particle compute the endpoint of trajectory and its weight.\n",
    "        If the weight is positive, we accept the final point, otherwise we accept the initial point. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        :param N: Number of particles\n",
    "        :type N:  int\n",
    "        \n",
    "        :param B: Number of bounces for the THUG integrator. Equivalent to `L` Leapfrog steps in HMC.\n",
    "        :type B: int\n",
    "        \n",
    "        :param δ: Step-size used at each bounce, for the THUG integrator.\n",
    "        :type δ: float\n",
    "        \n",
    "        :param d: Dimensionality of the `x` component of each particle, and equally dimensionality of \n",
    "                  `v` component of each particle. Therefore each particle has dimension `2d`.\n",
    "        \n",
    "        :param ϵs: Tolerances that fully specify the sequence of target filamentary distributions.\n",
    "        :type ϵs: iterable\n",
    "        \"\"\"\n",
    "        # Input variables\n",
    "        self.N  = SETTINGS['N']       \n",
    "        self.δ  = SETTINGS['δ']\n",
    "        self.d  = SETTINGS['d']\n",
    "        self.ϵs = SETTINGS['ϵs']\n",
    "        self.manifold = SETTINGS['manifold']\n",
    "        self.SETTINGS = SETTINGS\n",
    "        self.B = SETTINGS['B']\n",
    "        \n",
    "        # Variables derived from the above\n",
    "        self.P  = len(self.ϵs) - 1                                       # Number of target distributions\n",
    "        self.log_ηs = [self.manifold.generate_logηϵ(ϵ) for ϵ in self.ϵs]     # List of filamentary distributions \n",
    "        \n",
    "    \n",
    "    def initialize_particles(self):\n",
    "        \"\"\"Initialize by sampling with RWM on distribution with ϵ0.\"\"\"\n",
    "        # Initialize first position on the manifold\n",
    "        x0 = self.SETTINGS['ξ0']\n",
    "        # Sample using RWM\n",
    "        burn_in = 100\n",
    "        thinning = 10\n",
    "        ### try initializing using Tangential Hug as MCMC kernel?\n",
    "        #TO_BE_THINNED, acceptance = RWM(x0, self.δ, burn_in + thinning*self.N, self.log_ηs[0])\n",
    "        q = MVN(zeros(self.d), eye(self.d))\n",
    "        TO_BE_THINNED, acceptance = HugTangentialMultivariate(x0, self.B*self.δ, self.B, burn_in + thinning*self.N, 0.0, q, self.log_ηs[0], self.manifold.fullJacobian, method='linear')\n",
    "        print(\"Initializing particles. Acceptance: \", np.mean(acceptance)*100)\n",
    "        # Thin the samples to obtain the particles\n",
    "        initialized_particles = TO_BE_THINNED[burn_in:][::thinning]\n",
    "        # Refresh velocities and form particles\n",
    "        v0 = np.random.normal(loc=0.0, scale=1.0, size=(self.N, self.d))\n",
    "        z0 = np.hstack((initialized_particles, v0))\n",
    "        self.starting_particles = z0\n",
    "        return z0\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Starts the Markov Snippets sampler.\"\"\"\n",
    "        starting_time = time.time()\n",
    "        # Initialize particles\n",
    "        z = self.initialize_particles()   # (N, 2d)\n",
    "        # Storage\n",
    "        self.PARTICLES    = zeros((self.P+1, self.N, 2*self.d))\n",
    "        self.PARTICLES[0] = z\n",
    "        self.WEIGHTS      = zeros((self.P+1, self.N))\n",
    "        self.WEIGHTS[0]   = 1 / self.N\n",
    "        self.ESS          = zeros(self.P+1)\n",
    "        self.ESS[0]       = 1 / np.sum(self.WEIGHTS[0]**2)\n",
    "        # For each target distribution, run the following loop\n",
    "        for n in range(1, self.P+1):\n",
    "            # Standard SMC sampler, we mutate the particles and then we resample\n",
    "            ### Mutation step: \n",
    "            ###### Refresh velocities\n",
    "            z[:, self.d:] = np.random.normal(loc=0.0, scale=1.0, size=(self.N, self.d))\n",
    "            ###### Mutate positions \n",
    "            M = lambda z: THUG_MH(z, self.B, self.δ, self.log_ηs[n-1])\n",
    "            Z = np.apply_along_axis(M, 1, z)\n",
    "            ### Compute weights\n",
    "            # Notice in this case the weight is different because we are not using the uniform kernel anymore\n",
    "            # Importantly: this is now the INCREMENTAL weight and so has to be multiplied by the previous one.\n",
    "            w_incremental = exp(np.apply_along_axis(self.log_ηs[n], 1, Z[:, :self.d]) - np.apply_along_axis(self.log_ηs[n-1], 1, Z[:, :self.d]))\n",
    "#             w = (abs(np.apply_along_axis(f, 1, Z[:, :p]) - level_set_value) <= self.ϵs[n]).astype(float)\n",
    "            w = w_incremental # since we resample, no need to multiply #self.WEIGHTS[n-1] * w_incremental\n",
    "            w = w / w.sum()\n",
    "            self.WEIGHTS[n] = w\n",
    "            self.ESS[n]     = 1 / np.sum(w**2)\n",
    "            ### Resample\n",
    "            indeces = choice(a=np.arange(self.N), size=self.N, p=w)\n",
    "            z = z[indeces, :]\n",
    "            self.PARTICLES[n] = z\n",
    "        self.total_time = time.time() - starting_time\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e612ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing particles. Acceptance:  48.365269461077844\n"
     ]
    }
   ],
   "source": [
    "MSTHUG_METROP = MultivariateMarkovSnippetsTHUGMetropolised(SETTINGS50)\n",
    "zP_metrop = MSTHUG_METROP.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733f7a6",
   "metadata": {},
   "source": [
    "# Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8005c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Number of particles with non-zero weight for ϵ_P) / total sampling time: \n",
      "MS  : 152.6\n",
      "SMC : 8.4\n"
     ]
    }
   ],
   "source": [
    "print(\"(Number of particles with non-zero weight for ϵ_P) / total sampling time: \")\n",
    "print(\"MS  : {:.1f}\".format(np.sum(MSTHUG.Wbar[-1] > 0) / MSTHUG.total_time))\n",
    "print(\"SMC : {:.1f}\".format(np.sum(MSTHUG_METROP.WEIGHTS[-1] > 0) / MSTHUG_METROP.total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e642c3",
   "metadata": {},
   "source": [
    "# Mean Functionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b403a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMC-THUG: Mean Functional\n",
    "def smc_mean(MS):\n",
    "    W = MS.WEIGHTS[-1][..., None]\n",
    "    Z = MS.PARTICLES[-1, :, :MS.d]\n",
    "    return np.sum(W*Z, axis=0)\n",
    "\n",
    "# Markov-Snippets: Mean functional\n",
    "def markov_snippets_mean(MS):\n",
    "    W = MS.Wbar[-1].reshape(MS.N, MS.B+1)[..., None] # (N, B+1, 1)\n",
    "    Z = MS.ZNK[-1, :, :MS.d].reshape(MS.N, MS.B+1, MS.d)   # (N, B+1, p)\n",
    "    return np.sum(np.sum(W*Z, axis=1), axis=0)    # (2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e7577b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Functional\n",
      "MS  : -5e-01 -1e+00\n",
      "SMC : -5e-01 -1e+00\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Functional\")\n",
    "print(\"MS  : {:.0e} {:.0e}\".format(*markov_snippets_mean(MSTHUG)))\n",
    "print(\"SMC : {:.0e} {:.0e}\".format(*smc_mean(MSTHUG_METROP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1821c2",
   "metadata": {},
   "source": [
    "# Resampled Indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1af0b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40adca0f42624618a9836bbdd2cc55ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='n', max=8), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_histogram(n)>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_histogram(n):\n",
    "    fig, ax = plt.subplots(figsize=(20, 4))\n",
    "    bins        = np.arange(-0.5, SETTINGS50['B']+0.5, step=1.0)\n",
    "    bins_labels = np.arange(SETTINGS50['B'])\n",
    "    _ = ax.hist(MSTHUG.K_RESAMPLED[n, :], density=True, bins=bins, edgecolor='k', color='lightsalmon')\n",
    "    ax.set_xticks(bins_labels)\n",
    "    ax.set_xticklabels(bins_labels)\n",
    "    plt.show()\n",
    "\n",
    "resetwarnings()\n",
    "interact(plot_histogram, n=(0, len(ϵs) - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "586dfb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0: 0\n",
      "k = 1: 3961\n",
      "k = 2: 0\n",
      "k = 3: 926\n",
      "k = 4: 0\n",
      "k = 5: 106\n",
      "k = 6: 0\n",
      "k = 7: 3\n",
      "k = 8: 0\n",
      "k = 9: 0\n",
      "k = 10: 0\n",
      "k = 11: 0\n",
      "k = 12: 0\n",
      "k = 13: 0\n",
      "k = 14: 0\n",
      "k = 15: 0\n",
      "k = 16: 0\n",
      "k = 17: 2\n",
      "k = 18: 0\n",
      "k = 19: 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(SETTINGS50['B']):\n",
    "    print(\"k = {}: {}\".format(i, sum(MSTHUG.K_RESAMPLED[-2, :] == i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68e1a0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.796766426658083e-15"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(MSTHUG.Wbar[-2, :], q=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cd06742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 5.735336985905676e-29, 0.7928290529279027)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(MSTHUG.Wbar[-2, :]), np.median(MSTHUG.Wbar[-2, :]), np.max(MSTHUG.Wbar[-2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "464c7a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11509, 11511])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(MSTHUG.Wbar[-2, :] > 0.1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7266077f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 548,    1],\n",
       "       [ 548,    3],\n",
       "       [ 548,    5],\n",
       "       [ 548,    7],\n",
       "       [1608,   18],\n",
       "       [3538,   17],\n",
       "       [3538,   19]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.dstack(np.unravel_index(choice(np.arange(MSTHUG.N*(MSTHUG.B+1)), size=MSTHUG.N, p=MSTHUG.Wbar[-2, :]), (MSTHUG.N, MSTHUG.B+1))).squeeze(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37aa2e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7928290529279027"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSTHUG.Wbar[-2, :].reshape(MSTHUG.N, MSTHUG.B+1)[548, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cef7c212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.841677239012335e-16"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSTHUG.Wbar[-2, :].reshape(MSTHUG.N, MSTHUG.B+1)[548, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5e094079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 21, 108)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSTHUG.ZNK[-2].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "98da82c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227.21244045, 250.41267291, 211.53813348, ..., 253.06122095,\n",
       "       127.8627568 , 218.42768995])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(MSTHUG.log_ηs[-2], 1, MSTHUG.ZNK[-2].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[:, 0, :MSTHUG.d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5e06ab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[227.21244045, 227.21244045, 227.21244045, ..., 227.21244045,\n",
       "        227.21244045, 227.21244045],\n",
       "       [250.41267291, 250.41267291, 250.41267291, ..., 250.41267291,\n",
       "        250.41267291, 250.41267291],\n",
       "       [211.53813348, 211.53813348, 211.53813348, ..., 211.53813348,\n",
       "        211.53813348, 211.53813348],\n",
       "       ...,\n",
       "       [253.06122095, 253.06122095, 253.06122095, ..., 253.06122095,\n",
       "        253.06122095, 253.06122095],\n",
       "       [127.8627568 , 127.8627568 , 127.8627568 , ..., 127.8627568 ,\n",
       "        127.8627568 , 127.8627568 ],\n",
       "       [218.42768995, 218.42768995, 218.42768995, ..., 218.42768995,\n",
       "        218.42768995, 218.42768995]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(np.apply_along_axis(MSTHUG.log_ηs[-2], 1, MSTHUG.ZNK[-2].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[:, 0, :MSTHUG.d]), MSTHUG.B+1, axis=0).reshape(MSTHUG.N, MSTHUG.B+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9f1c097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7928290529279027"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSTHUG.Wbar[7, :].reshape(MSTHUG.N, MSTHUG.B+1)[548, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "980aec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try to produce that again, but using all the calculations.\n",
    "# want to see why [548, 2] and [548, 4] are so bad but [548, 1] and [548, 3] are amazing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "57f8472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DENOMINATOR = np.repeat(np.apply_along_axis(MSTHUG.log_ηs[7], 1, MSTHUG.ZNK[7].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[:, 0, :MSTHUG.d]), MSTHUG.B+1, axis=0).reshape(MSTHUG.N, MSTHUG.B+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f68c589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERATOR = np.apply_along_axis(MSTHUG.log_ηs[8], 2, MSTHUG.ZNK[7].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[:, :, :MSTHUG.d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "084308b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNNORMALIZED_WEIGHTS = exp(NUMERATOR - DENOMINATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6db8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZED_WEIGHTS = UNNORMALIZED_WEIGHTS / UNNORMALIZED_WEIGHTS.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4f43c364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7928290529279027"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NORMALIZED_WEIGHTS[548, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7780053d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319.29068907830833, 290.1974908100208)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERATOR[548, 1], DENOMINATOR[548, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eded9d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284.9681013887259, 290.1974908100208)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERATOR[548, 2], DENOMINATOR[548, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "265fcb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE DIFFERENCE, AS EXPECTED, IS IN THE NUMERATOR. NOW, WE NEED TO FIGURE OUT WHY THE VALUE IN THE NUMERATOR\n",
    "# IS SO MUCH SMALLER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aea8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSTHUG.log_ηs[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d3d7eea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319.29068907830833"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSTHUG.log_ηs[8](MSTHUG.ZNK[7].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[548, 1, :MSTHUG.d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b4875202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284.9681013887259"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSTHUG.log_ηs[8](MSTHUG.ZNK[7].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[548, 2, :MSTHUG.d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1399f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how close the points are to the manifold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8f209904",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = SETTINGS50['manifold'].q(MSTHUG.ZNK[7].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[548, 1, :MSTHUG.d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c45aa9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2 = SETTINGS50['manifold'].q(MSTHUG.ZNK[7].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[548, 2, :MSTHUG.d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "741dbea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# they are about the same distance, so why is the density so different? \n",
    "# remember this is how the thing is calculated self.logprior(ξ) - u@u/(2*ϵ**2) - m*log(ϵ) - m*log(2*pi)/2\n",
    "# where u = self.q(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9f0b2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps the prior is different there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "276a2732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-40.19952967879184"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SETTINGS50['manifold'].logprior(MSTHUG.ZNK[7].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[548, 1, :MSTHUG.d]) #- Q1@Q1/(2*MSTHUG.ϵs[8]**2) #- SETTINGS50['m']*log(MSTHUG.ϵs[8]) - SETTINGS50['m']*log(2*pi)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "db031e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-40.10942500006716"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SETTINGS50['manifold'].logprior(MSTHUG.ZNK[7].reshape(MSTHUG.N, MSTHUG.B+1, MSTHUG.d*2)[548, 2, :MSTHUG.d]) #- Q2@Q2/(2*MSTHUG.ϵs[8]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "da79231a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-55.07987318147524"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- Q1@Q1/(2*MSTHUG.ϵs[8]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "71561623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-89.49256554978236"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- Q2@Q2/(2*MSTHUG.ϵs[8]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "228f0929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.101597463629505e-06, 1.7898513109956472e-06)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1@Q1, Q2@Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c8cf3c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.07987318147524, 89.49256554978236)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q1@Q1)/((2*MSTHUG.ϵs[8]**2)), Q2@Q2 / ((2*MSTHUG.ϵs[8]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34250e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93820dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
