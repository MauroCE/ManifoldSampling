{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a260b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autograd\n",
    "import autograd.numpy as np\n",
    "from autograd.numpy.random import seed, randn, rand\n",
    "from autograd.numpy import exp, hstack, log\n",
    "from autograd import grad, jacobian\n",
    "from autograd.numpy.linalg import norm\n",
    "from autograd.scipy.stats import norm as ag_norm\n",
    "from autograd.extend import primitive, defvjp\n",
    "from autograd.numpy.numpy_vjps import unbroadcast_f\n",
    "\n",
    "# Standard Python Imports\n",
    "from scipy.stats import norm as ndist\n",
    "from scipy.stats import uniform as udist\n",
    "from numpy import zeros, eye, vstack, sqrt\n",
    "from scipy.stats import multivariate_normal as MVN\n",
    "from numpy.random import uniform\n",
    "from scipy.optimize import fsolve\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Custom functions\n",
    "from tangential_hug_functions import HugTangentialStepEJSD_Deterministic, Hop_Deterministic, HugStepEJSD_Deterministic, HugRotatedStepEJSD_AR_Deterministic, HugRotatedStepEJSD_Deterministic\n",
    "from utils import ESS_univariate, ESS, n_unique\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a17d59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "909220eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(thetau):\n",
    "    \"\"\"Deterministic function for distance manifold. f:R^5 -> R \"\"\"\n",
    "    a_param, b_param, k_param, *z = thetau  # Latents are standard normal variables\n",
    "    z = np.array(z)\n",
    "    out = a_param + b_param*(1 + 0.8 * (1 - exp(-g_param * z)) / (1+exp(-g_param * z))) * ((1 + z**2)**k_param) * z\n",
    "    return norm(out - y_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e74fbee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(theta, N=m):\n",
    "    \"\"\"Generates initial observed data y_star.\"\"\"\n",
    "    z = randn(N)         # Get N samples from N(0, 1) for G&K simulation.\n",
    "    a_param, b_param, k_param = theta   # Grab parameters\n",
    "    return a_param + b_param*(1 + 0.8 * (1 - exp(-g_param * z)) / (1+exp(-g_param * z))) * ((1 + z**2)**k_param) * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "6fce3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = np.array([3.0, 1.0, 0.5])\n",
    "g_param = 2.0\n",
    "y_star = data_generator(theta0, N=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "cfc5b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_function = grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8df495d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3 + m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8e0cde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprior(thetau):\n",
    "    \"\"\"Log prior distribution.\"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return log((abs(thetau[:3]) <= 10).all().astype('float64')) + ndist.logpdf(thetau[3:]).sum()\n",
    "    \n",
    "def log_uniform_kernel(xi, epsilon):\n",
    "    \"\"\"Log density of uniform kernel. \"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return log((f(xi) <= epsilon).astype('float64'))\n",
    "    \n",
    "def log_abc_posterior(xi):\n",
    "    \"\"\"Log density of ABC posterior. Product of (param-latent) prior and uniform kernel.\"\"\"\n",
    "    return logprior(xi) + log_uniform_kernel(xi, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ee0642a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def experiment(x00, T, N, alphas, nlags, rho=0.9):\n",
    "    \"\"\"Runs Hug+Hop and RotatedHUG+HOP using the same velocities and the same random seeds.\n",
    "    We also try to limit the noise in the HOP kernel by sampling the u variables beforehand.\n",
    "    I run RotatedHUG for all values of alpha with the randomness fixed. \n",
    "    This is 1 run, for 1 epsilon. It does 1 HUG+HOP and then THUG+HOP for all alphas.\n",
    "    T1: T for HUG\n",
    "    T2: T for RotatedHUG\n",
    "    \"\"\"\n",
    "    ### COMMON VARIABLES\n",
    "    v = q.rvs(N)\n",
    "    log_uniforms1 = log(rand(N))     # Log uniforms for the HUG kernels\n",
    "    log_uniforms2 = log(rand(N))     # Log uniforms for the HOP kernel\n",
    "    u = MVN(zeros(d), eye(d)).rvs(N) # Original velocities for HOP kernel\n",
    "    ### STORAGE (HUG + HOP)\n",
    "    hh = x00              # Initial sample\n",
    "    ahh1 = 0.0            # Acceptance probability for HUG kernel\n",
    "    ahh2 = 0.0            # Acceptance probability for HOP kernel (when used with HUG)\n",
    "    ehh = 0.0             # EJSD\n",
    "    eghh = 0.0            # EJSD in Gradient direction\n",
    "    ethh = 0.0            # EJSD in Tangent direction\n",
    "    ### STORAGE (RotatedHUG + HOP) I MUST STORE FOR ALL ALPHAS\n",
    "    arh1 = zeros(n_alphas)\n",
    "    arh2 = zeros(n_alphas)\n",
    "    erh  = zeros(n_alphas)\n",
    "    egrh = zeros(n_alphas)\n",
    "    etrh = zeros(n_alphas)\n",
    "    ### ADDITIONAL STORAGE FOR RotatedHUG\n",
    "    rh_esst = zeros(n_alphas)\n",
    "    rh_essu = zeros(n_alphas)\n",
    "    rh_essj = zeros(n_alphas)\n",
    "    rh_uniq = zeros(n_alphas)\n",
    "    rh_act  = zeros((n_alphas, nlags))\n",
    "    rh_acu  = zeros((n_alphas, nlags))\n",
    "    ### HUG + HOP\n",
    "    x = x00\n",
    "    for i in range(N):\n",
    "        y, a1, e, eg, et = HugStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T, B, q, log_abc_posterior, grad_function)\n",
    "        x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, log_abc_posterior, grad_function)\n",
    "        hh = vstack((hh, y, x))\n",
    "        ahh1 += a1 * 100 / N\n",
    "        ahh2 += a2 * 100 / N\n",
    "        ehh += e / N\n",
    "        eghh += eg / N \n",
    "        ethh += et / N \n",
    "    # COMPUTE ESS AND OTHER METRICS FOR HUG\n",
    "    hh = hh[1:]\n",
    "    hh_esst = ESS_univariate(hh[::2, 0])     # ESS for theta\n",
    "    hh_essu = ESS_univariate(hh[::2, 1])     # ESS for u\n",
    "    hh_essj = ESS(hh[::2])                   # ESS joint\n",
    "    hh_uniq = n_unique(hh)                             # Number of unique samples\n",
    "    hh_act  = acf(hh[::2, 0], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for theta (remove the first 1.0)\n",
    "    hh_acu  = acf(hh[::2, 1], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for u\n",
    "    ### RotatedHUG + HOP\n",
    "    for k, alpha in enumerate(alphas):\n",
    "        x = x00\n",
    "        rh = x00      # RESTART THE SAMPLES FROM SCRATCH\n",
    "        velocity = v[0]\n",
    "        rho_value = 1.0    # will be changed to rho after 1st iteration\n",
    "        for i in range(N):\n",
    "            velocity = rho_value*velocity + sqrt(1 - rho_value**2)*v[i]\n",
    "            y, velocity, a1, e, eg, et = HugRotatedStepEJSD_AR_Deterministic(x, velocity, log_uniforms1[i], T, B, alpha, q, log_abc_posterior, grad_function)\n",
    "            x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, log_abc_posterior, grad_function)\n",
    "            rh = vstack((rh, y, x))\n",
    "            arh1[k] += a1 * 100 / N\n",
    "            arh2[k] += a2 * 100 / N\n",
    "            erh[k]  += e / N\n",
    "            egrh[k] += eg / N \n",
    "            etrh[k] += et / N \n",
    "            rho_value = rho\n",
    "        ### COMPUTE ESS AND OTHER METRISC FOR RotatedHUG\n",
    "        rh = rh[1:]\n",
    "        rh_esst[k] = ESS_univariate(rh[::2, 0])     # ESS for theta\n",
    "        rh_essu[k] = ESS_univariate(rh[::2, 1])     # ESS for u\n",
    "        rh_essj[k] = ESS(rh[::2])                   # ESS joint\n",
    "        rh_uniq[k] = n_unique(rh)                             # Number of unique samples\n",
    "        rh_act[k] = acf(rh[::2, 0], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for theta\n",
    "        rh_acu[k] = acf(rh[::2, 1], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for u\n",
    "    # RETURN EVERYTHING\n",
    "    out = {\n",
    "        'HH': {\n",
    "            'A1': ahh1,\n",
    "            'A2': ahh2,\n",
    "            'E': ehh,\n",
    "            'EG': eghh, \n",
    "            'ET': ethh,\n",
    "            'ESS_T': hh_esst,\n",
    "            'ESS_U': hh_essu,\n",
    "            'ESS_J': hh_essj,\n",
    "            'UNIQUE': hh_uniq,\n",
    "            'AC_T': hh_act,\n",
    "            'AC_U': hh_acu,\n",
    "            'SAMPLES': hh\n",
    "        },\n",
    "        'RH': {\n",
    "            'A1': arh1,\n",
    "            'A2': arh2,\n",
    "            'E': erh,\n",
    "            'EG': egrh, \n",
    "            'ET': etrh, \n",
    "            'ESS_T': rh_esst,\n",
    "            'ESS_U': rh_essu,\n",
    "            'ESS_J': rh_essj,\n",
    "            'UNIQUE': rh_uniq,\n",
    "            'AC_T': rh_act,\n",
    "            'AC_U': rh_acu,\n",
    "            'SAMPLES':rh\n",
    "        }\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "95d554aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = MVN(zeros(d), eye(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "12e06f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.999]\n",
    "n_alphas = len(alphas)\n",
    "epsilon = 0.005\n",
    "lam = epsilon / 30\n",
    "kappa = 0.005\n",
    "T1 = T2 = 0.01 #0.3\n",
    "B = 5\n",
    "N = 80000\n",
    "nlags = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "c336ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a guess\n",
    "guess = hstack((np.array([1.0, 1.0, 1.0]), zeros(m)))\n",
    "\n",
    "# Find point on manifold using optimization\n",
    "func = lambda xi: np.r_[f(xi), zeros(d-1)]  # Append 0, 0 to make fsolve work.\n",
    "xi0 = fsolve(func, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f818b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = experiment(xi0, T1, N, alphas, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out['HH']['A1'], out['HH']['A2'], out['HH']['E'], out['HH']['ESS_J'] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4253c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out['RH']['A1'], out['RH']['A2'], out['RH']['E'], out['RH']['ESS_J'] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUG KDES\n",
    "akde_hug = gaussian_kde(out['HH']['SAMPLES'][:, 0])\n",
    "bkde_hug = gaussian_kde(out['HH']['SAMPLES'][:, 1])\n",
    "kkde_hug = gaussian_kde(out['HH']['SAMPLES'][:, 2])\n",
    "# HUG linspaces\n",
    "xa_hug = np.linspace(np.min(out['HH']['SAMPLES'][:, 0]), np.max(out['HH']['SAMPLES'][:, 0]))\n",
    "xb_hug = np.linspace(np.min(out['HH']['SAMPLES'][:, 1]), np.max(out['HH']['SAMPLES'][:, 1]))\n",
    "xk_hug = np.linspace(np.min(out['HH']['SAMPLES'][:, 2]), np.max(out['HH']['SAMPLES'][:, 2]))\n",
    "# THUG KDES\n",
    "akde_thug = gaussian_kde(out['RH']['SAMPLES'][:, 0])\n",
    "bkde_thug = gaussian_kde(out['RH']['SAMPLES'][:, 1])\n",
    "kkde_thug = gaussian_kde(out['RH']['SAMPLES'][:, 2])\n",
    "# THUG linspaces\n",
    "xa_thug = np.linspace(np.min(out['RH']['SAMPLES'][:, 0]), np.max(out['RH']['SAMPLES'][:, 0]))\n",
    "xb_thug = np.linspace(np.min(out['RH']['SAMPLES'][:, 1]), np.max(out['RH']['SAMPLES'][:, 1]))\n",
    "xk_thug = np.linspace(np.min(out['RH']['SAMPLES'][:, 2]), np.max(out['RH']['SAMPLES'][:, 2]))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(20, 5))\n",
    "# First parameter (a)\n",
    "ax[0].plot(xa_hug, akde_hug(xa_hug), label='hug')\n",
    "ax[0].plot(xa_thug, akde_thug(xa_thug), label='rhug')\n",
    "ax[0].vlines(theta0[0], ymin=0, ymax=2, colors='red')\n",
    "ax[0].set_title(\"a\", fontsize=20)\n",
    "# Second parameter (b)\n",
    "ax[1].plot(xb_hug, bkde_hug(xb_hug), label='hug')\n",
    "ax[1].plot(xb_thug, bkde_thug(xb_thug), label='rhug')\n",
    "ax[1].vlines(theta0[1], ymin=0, ymax=2, colors='red')\n",
    "ax[1].set_title(\"b\", fontsize=20)\n",
    "# Third parameter (k)\n",
    "ax[2].plot(xk_hug, kkde_hug(xk_hug), label='hug')\n",
    "ax[2].plot(xk_thug, kkde_thug(xk_thug), label='rhug')\n",
    "ax[2].vlines(theta0[2], ymin=0, ymax=2, colors='red')\n",
    "ax[2].set_title(\"k\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81907d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!say EXPERIMENT FINISHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6a20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023d446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
