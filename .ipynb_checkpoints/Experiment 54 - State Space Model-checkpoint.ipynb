{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32724a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array, sqrt, zeros, exp, log\n",
    "from numpy.random import normal as ndist\n",
    "from numpy.random import randn\n",
    "\n",
    "import autograd.numpy as anp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebf26633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write functions without too much thought\n",
    "def G1(ϕ, ν1):\n",
    "    μ, ρ, γ, σ = ϕ\n",
    "    return μ + (γ/sqrt(1-ρ**2))*ν1\n",
    "\n",
    "def Gt(ϕ, νt, xtm1):\n",
    "    μ, ρ, γ, σ = ϕ\n",
    "    return μ + ρ*(xtm1 - μ) + γ*νt\n",
    "\n",
    "def Ht(ϕ, xt):\n",
    "    return exp(xt)\n",
    "\n",
    "def xbar(t, ϕ, ηt, yt):\n",
    "    return log(yt - σ*ηt)\n",
    "\n",
    "def Cbar1(ϕ, ν, η, y):\n",
    "    return G1(ϕ, ν[1]) - xbar(1, ϕ, η[1], y[1])\n",
    "\n",
    "def Cbar(t, ϕ, ν, η, y):\n",
    "    return Gt(ϕ, ν[t], xbar(t-1, ϕ, η[t-1], y[t-1])) - xbar(t, ϕ, η[t], y[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0fc563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = -0.5\n",
    "γ = 0.4\n",
    "ρ = 0.9\n",
    "T = 1000\n",
    "σ = 0.01\n",
    "θ = array([μ, ρ, γ, σ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57b6de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSM:\n",
    "    def __init__(self, T, σ, autograd=False):\n",
    "        \"\"\"Class for State Space Model in Manifold Lifting paper.\"\"\"\n",
    "        self.T  = T    # Number of time-steps, dictates dimensionality of the model\n",
    "        self.σ  = σ    # Noise scale - dictates tightness around the data manifold.\n",
    "        self.ad = autograd\n",
    "        self.np = anp if autograd else np\n",
    "        \n",
    "    def G1(self, ϕ, ν1):\n",
    "        \"\"\"Generates latent variable x1.\"\"\"\n",
    "        μ, ρ, γ, σ = ϕ\n",
    "        return μ + (γ/sqrt(1 - ρ**2))*ν1\n",
    "    \n",
    "    def Gt(self, t, ϕ, xtm1, νt):\n",
    "        \"\"\"Generates latent variables x2:xT.\"\"\"\n",
    "        μ, ρ, γ, σ = ϕ\n",
    "        return μ + ρ*(xtm1 - μ) + γ*νt\n",
    "        \n",
    "    def x̄(self, t, ϕ, ηt):\n",
    "        \"\"\"Given ϕ and η it generates the latent variables xt that produced yt.\"\"\"\n",
    "        return self.np.log(self.y[t] - self.σ*ηt)\n",
    "    \n",
    "    def C̄1(self, ϕ, ν, η):\n",
    "        \"\"\"Constraint function for the first latent variable/observation.\"\"\"\n",
    "        return self.G1(ϕ, ν[1]) - self.x̄(1, ϕ, η[1])\n",
    "        \n",
    "    def C̄t(self, t, ϕ, ν, η):\n",
    "        \"\"\"Constraint function for t in {2 .. T}.\"\"\"\n",
    "        return self.Gt(t, ϕ, self.x̄(t-1, ϕ, η[t-1]), ν[t]) - self.x̄(t, ϕ, η[t])\n",
    "\n",
    "    def C̄(self, ξ):\n",
    "        \"\"\"Overall constraint function. ξ=(ϕ, ν, η) where ϕ=(μ, ρ, γ, σ).\"\"\"\n",
    "        ϕ, ν, η = ξ[:4], ξ[4:self.T+1], ξ[(self.T+1):(2*self.T + 1)]\n",
    "        return self.np.concatenate(\n",
    "            [self.C̄1(ϕ, ν, η)] + [self.C̄t(t, ϕ, ν, η) for t in range(1, self.T)]\n",
    "        )\n",
    "    \n",
    "    def generate_x_given_param(self, ϕtrue):\n",
    "        \"\"\"Generates x_1:T given the four parameters.\"\"\"\n",
    "        μ, ρ, γ, σ = ϕtrue\n",
    "        x = zeros(self.T)\n",
    "        ν = randn(self.T)\n",
    "        x[0] = ndist(loc=μ, scale=γ/sqrt(1 - ρ**2))\n",
    "        for t in range(1, self.T):\n",
    "            x[t] = μ + ρ*(x[t-1] - μ) + γ*ν[t]\n",
    "        self.true_x = x\n",
    "        self.ϕtrue  = ϕtrue\n",
    "    \n",
    "    def generate_y_given_x(self):\n",
    "        \"\"\"Generates data from true latent variables. \"\"\"\n",
    "        self.y = self.np.exp(self.true_x) + self.σ*randn(self.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94977ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = SSM(100, 0.1, autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3903700",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm.generate_x_given_param(θ)\n",
    "ssm.generate_y_given_x()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee54e90",
   "metadata": {},
   "source": [
    "# Graham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad09a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as onp\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax.scipy.special import ndtr, ndtri, logit, expit\n",
    "import argparse\n",
    "from functools import partial\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1202350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RealInterval = namedtuple(\"RealInterval\", (\"lower\", \"upper\"))\n",
    "reals = RealInterval(-onp.inf, onp.inf)\n",
    "positive_reals = RealInterval(0, onp.inf)\n",
    "negative_reals = RealInterval(-onp.inf, 0)\n",
    "nonnegative_reals = positive_reals\n",
    "nonpositive_reals = negative_reals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3306c",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3d27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElementwiseMonotonicTransform:\n",
    "    def __init__(self, forward, backward, domain, image, val_and_grad_forward=None):\n",
    "        self._forward = forward\n",
    "        self._backward = backward\n",
    "        self.domain = domain\n",
    "        self.image = image\n",
    "        if val_and_grad_forward is None:\n",
    "            val_and_grad_forward = jax.value_and_grad(forward)\n",
    "        self._val_and_grad_forward = val_and_grad_forward\n",
    "\n",
    "    def forward(self, u):\n",
    "        return self._forward(u)\n",
    "\n",
    "    def backward(self, x):\n",
    "        return self._backward(x)\n",
    "\n",
    "    def forward_and_det_jacobian(self, u):\n",
    "        if onp.isscalar(u) or u.shape == ():\n",
    "            return self._val_and_grad_forward(u)\n",
    "        else:\n",
    "            x, dx_du = jax.vmap(self._val_and_grad_forward)(u)\n",
    "            return x, dx_du.sum()\n",
    "\n",
    "    def __call__(self, u):\n",
    "        return self._forward(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d214b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbounded_to_lower_bounded(lower):\n",
    "    \"\"\"Construct transform from reals to lower-bounded interval.\n",
    "    Args:\n",
    "        lower (float): Lower-bound of image of transform.\n",
    "    \"\"\"\n",
    "\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda u: np.exp(u) + lower,\n",
    "        backward=lambda x: np.log(x - lower),\n",
    "        domain=reals,\n",
    "        image=RealInterval(lower, onp.inf),\n",
    "    )\n",
    "\n",
    "def unbounded_to_upper_bounded(upper):\n",
    "    \"\"\"Construct transform from reals to upper-bounded interval.\n",
    "    Args:\n",
    "        upper (float): Upper-bound of image of transform.\n",
    "    \"\"\"\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda u: upper - np.exp(u),\n",
    "        backward=lambda x: np.log(upper - x),\n",
    "        domain=reals,\n",
    "        image=RealInterval(-onp.inf, upper),\n",
    "    )\n",
    "\n",
    "def unbounded_to_lower_and_upper_bounded(lower, upper):\n",
    "    \"\"\"Construct transform from reals to bounded interval.\n",
    "    Args:\n",
    "        lower (float): Lower-bound of image of transform.\n",
    "        upper (float): Upper-bound of image of transform.\n",
    "    \"\"\"\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda u: lower + (upper - lower) * expit(np.asarray(u, np.float64)),\n",
    "        backward=lambda x: logit((np.asarray(x, np.float64) - lower) / (upper - lower)),\n",
    "        domain=reals,\n",
    "        image=RealInterval(lower, upper),\n",
    "    )\n",
    "\n",
    "\n",
    "def diagonal_affine_map(location, scale):\n",
    "\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda x: location + scale * x,\n",
    "        backward=lambda y: (y - location) / scale,\n",
    "        domain=reals,\n",
    "        image=reals,\n",
    "        val_and_grad_forward=lambda x: (location + scale * x, scale),\n",
    "    )\n",
    "\n",
    "def standard_normal_to_uniform(lower, upper):\n",
    "\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda n: lower + ndtr(n) * (upper - lower),\n",
    "        backward=lambda u: ndtri((u - lower) / (upper - lower)),\n",
    "        domain=reals,\n",
    "        image=RealInterval(lower, upper),\n",
    "    )\n",
    "\n",
    "def standard_normal_to_exponential(rate):\n",
    "\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda n: -np.log(ndtr(n)) / rate,\n",
    "        backward=lambda e: ndtri(np.exp(-e * rate)),\n",
    "        domain=reals,\n",
    "        image=nonnegative_reals,\n",
    "    )\n",
    "\n",
    "def standard_normal_to_half_normal(scale):\n",
    "\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda n: ndtri((ndtr(n) + 1) / 2) * scale,\n",
    "        backward=lambda h: ndtri(2 * ndtr(h / scale) - 1),\n",
    "        domain=reals,\n",
    "        image=nonnegative_reals,\n",
    "    )\n",
    "\n",
    "def standard_normal_to_truncated_normal(location, scale, lower, upper):\n",
    "\n",
    "    a = ndtr((lower - location) / scale)\n",
    "    b = ndtr((upper - location) / scale)\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda n: ndtri(a + ndtr(n) * (b - a)) * scale + location,\n",
    "        backward=lambda t: ndtri((ndtr((t - location) / scale) - a) / (b - a)),\n",
    "        domain=reals,\n",
    "        image=RealInterval(lower, upper),\n",
    "    )\n",
    "\n",
    "\n",
    "def standard_normal_to_beta(shape_a, shape_b):\n",
    "\n",
    "    if shape_b == 1:\n",
    "\n",
    "        def icdf(u):\n",
    "            return u ** (1 / shape_a)\n",
    "\n",
    "        def cdf(x):\n",
    "            return x ** shape_a\n",
    "\n",
    "    elif shape_a == 1:\n",
    "\n",
    "        def icdf(u):\n",
    "            return 1 - (1 - u) ** (1 / shape_b)\n",
    "\n",
    "        def cdf(x):\n",
    "            return 1 - (1 - x) ** shape_b\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(\"Transform only defined for shape_a == 1 or shape_b == 1\")\n",
    "\n",
    "    return ElementwiseMonotonicTransform(\n",
    "        forward=lambda n: icdf(ndtr(n)),\n",
    "        backward=lambda x: ndtri(cdf(x)),\n",
    "        domain=reals,\n",
    "        image=RealInterval(0, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bc89b1",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8ed676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution:\n",
    "    \"\"\"Probability distribution with density with respect to Lebesgue measure.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        neg_log_dens,\n",
    "        log_normalizing_constant,\n",
    "        sample,\n",
    "        support,\n",
    "        from_standard_normal_transform=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            neg_log_dens (Callable[[ArrayLike], float]): Function returning the negative\n",
    "                logarithm of a (potentially unnormalised) density function for the\n",
    "                distribution with respect to the Lebesgue measure.\n",
    "            log_normalizing_constant (ArrayLike): Logarithm of the normalising consant\n",
    "                for density function defined by `neg_log_dens` such that\n",
    "                    def dens(x): exp(-neg_log_dens(x) - log_normalizing_constant)\n",
    "                is a normalized probability density function for the distribution.\n",
    "            sample (Callable[[Generator, Tuple[int...]], ArrayLike]):\n",
    "            support (object): Object defining support of distribution.\n",
    "            from_standard_normal_transform (Callable[[ArrayLike], ArrayLike]): Function\n",
    "                which given a random normal variate(s) outputs a variate(s) from the\n",
    "                distribution represented by this object. Optional, may be `None`.\n",
    "        \"\"\"\n",
    "        self._neg_log_dens = neg_log_dens\n",
    "        self.log_normalizing_constant = log_normalizing_constant\n",
    "        self.sample = sample\n",
    "        self.support = support\n",
    "        self.from_standard_normal_transform = from_standard_normal_transform\n",
    "\n",
    "    def neg_log_dens(self, x, include_normalizing_constant=False):\n",
    "        nld = self._neg_log_dens(x)\n",
    "        if include_normalizing_constant:\n",
    "            nld = nld + self.log_normalizing_constant\n",
    "        if not (onp.isscalar(x) or x.shape == ()):\n",
    "            nld = nld.sum()\n",
    "        return nld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c1bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullback_distribution(distribution, transform):\n",
    "    \"\"\"Pullback a distribution through a differentiable transform.\n",
    "    Given a distribution `μ` and (differentiable) transform `F` constructs a\n",
    "    distribution `ν` such that `ν` is the pullback of `μ` under `F` or equivalently `μ`\n",
    "    is the pushforward of `ν` under `F`, i.e. `F#ν = μ`.\n",
    "    Args:\n",
    "        distribution (Distribution): Distribution `μ` to pullback.\n",
    "        transform (Transform): Transform `F` to pullback distribution through.\n",
    "    Returns\n",
    "        Distribution: Pullback distribution `ν`.\n",
    "    \"\"\"\n",
    "\n",
    "    def transformed_neg_log_dens(u):\n",
    "        x, det_dx_du = transform.forward_and_det_jacobian(u)\n",
    "        return distribution.neg_log_dens(x) - np.log(det_dx_du)\n",
    "\n",
    "    def transformed_sample(rng, shape=()):\n",
    "        x_samples = distribution.sample(rng, shape)\n",
    "        return onp.asarray(transform.backward(x_samples))\n",
    "\n",
    "    assert (\n",
    "        distribution.support == transform.image\n",
    "    ), \"Support of distribution does not match transform image\"\n",
    "\n",
    "    transformed_support = transform.domain\n",
    "\n",
    "    if distribution.from_standard_normal_transform is not None:\n",
    "\n",
    "        def transformed_from_standard_normal_transform(n):\n",
    "            return transform.backward(distribution.from_standard_normal_transform(n))\n",
    "\n",
    "    else:\n",
    "        transformed_from_standard_normal_transform = None\n",
    "\n",
    "    return Distribution(\n",
    "        neg_log_dens=transformed_neg_log_dens,\n",
    "        log_normalizing_constant=distribution.log_normalizing_constant,\n",
    "        sample=transformed_sample,\n",
    "        support=transformed_support,\n",
    "        from_standard_normal_transform=transformed_from_standard_normal_transform,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3716ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(lower, upper):\n",
    "    \"\"\"Construct uniform distribution with support on real-interval.\n",
    "    Args:\n",
    "        lower (float): Lower-bound of support.\n",
    "        upper (float): Upper-bound of support.\n",
    "    Returns:\n",
    "        Distribution: Uniform distribution object.\n",
    "    \"\"\"\n",
    "\n",
    "    def neg_log_dens(x):\n",
    "        return 0\n",
    "\n",
    "    log_normalizing_constant = np.log(upper - lower)\n",
    "\n",
    "    def sample(rng, shape=()):\n",
    "        return rng.uniform(low=lower, high=upper, size=shape)\n",
    "\n",
    "    support = RealInterval(lower, upper)\n",
    "\n",
    "    from_standard_normal_transform = standard_normal_to_uniform(lower, upper)\n",
    "\n",
    "    return Distribution(\n",
    "        neg_log_dens=neg_log_dens,\n",
    "        log_normalizing_constant=log_normalizing_constant,\n",
    "        sample=sample,\n",
    "        support=support,\n",
    "        from_standard_normal_transform=from_standard_normal_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c9bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(location, scale):\n",
    "    \"\"\"Construct normal distribution with support on real-line.\n",
    "    Args:\n",
    "        location (float): Location parameter (mean of distribution).\n",
    "        scale (float): Scale parameter (standard deviation of distribution).\n",
    "    Returns:\n",
    "        Distribution: Normal distribution object.\n",
    "    \"\"\"\n",
    "\n",
    "    def neg_log_dens(x):\n",
    "        return ((x - location) / scale) ** 2 / 2\n",
    "\n",
    "    log_normalizing_constant = np.log(2 * np.pi) / 2 + np.log(scale)\n",
    "\n",
    "    def sample(rng, shape=()):\n",
    "        return rng.normal(loc=location, scale=scale, size=shape)\n",
    "\n",
    "    from_standard_normal_transform = diagonal_affine_map(location, scale)\n",
    "\n",
    "    return Distribution(\n",
    "        neg_log_dens=neg_log_dens,\n",
    "        log_normalizing_constant=log_normalizing_constant,\n",
    "        sample=sample,\n",
    "        support=reals,\n",
    "        from_standard_normal_transform=from_standard_normal_transform,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f5608df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal(location, scale):\n",
    "    \"\"\"Construct log-normal distribution with support on positive reals.\n",
    "    Args:\n",
    "        location (float): Location parameter (mean of log of random variable).\n",
    "        scale (float): Scale parameter (standard deviation of log of random variable).\n",
    "    Returns:\n",
    "        Distribution: Log-normal distribution object.\n",
    "    \"\"\"\n",
    "\n",
    "    def neg_log_dens(x):\n",
    "        return ((np.log(x) - location) / scale) ** 2 / 2 + np.log(x)\n",
    "\n",
    "    log_normalizing_constant = np.log(2 * np.pi) / 2 + np.log(scale)\n",
    "\n",
    "    def sample(rng, shape=()):\n",
    "        return onp.exp(rng.normal(loc=location, scale=scale, size=shape))\n",
    "\n",
    "    from_standard_normal_transform = ElementwiseMonotonicTransform(\n",
    "        forward=lambda n: np.exp(location + scale * n),\n",
    "        backward=lambda x: (np.log(x) - location) / scale,\n",
    "        domain=reals,\n",
    "        image=positive_reals\n",
    "    )\n",
    "\n",
    "    return Distribution(\n",
    "        neg_log_dens=neg_log_dens,\n",
    "        log_normalizing_constant=log_normalizing_constant,\n",
    "        sample=sample,\n",
    "        support=positive_reals,\n",
    "        from_standard_normal_transform=from_standard_normal_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9cdf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_normal(scale):\n",
    "    \"\"\"Construct half-normal distribution with support on non-negative reals.\n",
    "    Args:\n",
    "        scale (float): Scale parameter.\n",
    "    Returns:\n",
    "        Distribution: Half-normal distribution object.\n",
    "    \"\"\"\n",
    "\n",
    "    def neg_log_dens(x):\n",
    "        return (x / scale) ** 2 / 2\n",
    "\n",
    "    log_normalizing_constant = np.log(np.pi / 2) / 2 + np.log(scale)\n",
    "\n",
    "    def sample(rng, shape=()):\n",
    "        return abs(rng.normal(loc=0, scale=scale, size=shape))\n",
    "\n",
    "    from_standard_normal_transform = standard_normal_to_half_normal(scale)\n",
    "\n",
    "    return Distribution(\n",
    "        neg_log_dens=neg_log_dens,\n",
    "        log_normalizing_constant=log_normalizing_constant,\n",
    "        sample=sample,\n",
    "        support=nonnegative_reals,\n",
    "        from_standard_normal_transform=from_standard_normal_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4ce9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparametrize_to_unbounded_support(prior_spec):\n",
    "    if (\n",
    "        prior_spec.distribution.support.lower != -np.inf\n",
    "        and prior_spec.distribution.support.upper != np.inf\n",
    "    ):\n",
    "        bounding_transform = unbounded_to_lower_and_upper_bounded(\n",
    "            prior_spec.distribution.support.lower, prior_spec.distribution.support.upper\n",
    "        )\n",
    "    elif prior_spec.distribution.support.lower != -np.inf:\n",
    "        bounding_transform = unbounded_to_lower_bounded(\n",
    "            prior_spec.distribution.support.lower\n",
    "        )\n",
    "    elif prior_spec.distribution.support.upper != np.inf:\n",
    "        bounding_transform = unbounded_to_upper_bounded(\n",
    "            prior_spec.distribution.support.upper\n",
    "        )\n",
    "    else:\n",
    "        return prior_spec\n",
    "    distribution = pullback_distribution(prior_spec.distribution, bounding_transform)\n",
    "    if prior_spec.transform is not None:\n",
    "        transform = lambda u: prior_spec.transform(bounding_transform(u))\n",
    "    else:\n",
    "        transform = bounding_transform\n",
    "    return PriorSpecification(\n",
    "        shape=prior_spec.shape, distribution=distribution, transform=transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fcb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparametrize_to_standard_normal(prior_spec):\n",
    "    from_standard_normal_transform = (\n",
    "        prior_spec.distribution.from_standard_normal_transform\n",
    "    )\n",
    "    if prior_spec.transform is not None:\n",
    "        transform = lambda u: prior_spec.transform(from_standard_normal_transform(u))\n",
    "    else:\n",
    "        transform = from_standard_normal_transform\n",
    "    return PriorSpecification(\n",
    "        shape=prior_spec.shape, distribution=normal(0, 1), transform=transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c21abde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_prior(prior_specs):\n",
    "    def get_shape(spec, data):\n",
    "        return spec.shape(data) if callable(spec.shape) else spec.shape\n",
    "    \n",
    "    def myfunc(shape):\n",
    "        if shape != ():\n",
    "            return int(np.product(shape))\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def reparametrized_prior_specs(data):\n",
    "        for name, spec in prior_specs.items():\n",
    "            if (\n",
    "                data.get(\"parametrization\") == \"normal\"\n",
    "                and spec.distribution.from_standard_normal_transform is not None\n",
    "            ):\n",
    "                yield name, reparametrize_to_standard_normal(spec)\n",
    "            else:\n",
    "                yield name, reparametrize_to_unbounded_support(spec)\n",
    "\n",
    "    def reparametrized_prior_specs_and_u_slices(u, data):\n",
    "        i = 0\n",
    "        for name, spec in reparametrized_prior_specs(data):\n",
    "            shape = get_shape(spec, data)\n",
    "            size = myfunc(shape) #int(np.product(shape))\n",
    "            u_slice = u[i] if shape == () else u[i : i + size].reshape(shape)\n",
    "            i += size\n",
    "            yield name, spec, u_slice\n",
    "\n",
    "    def compute_dim_u(data):\n",
    "        return sum(myfunc(get_shape(spec, data)) for _, spec in reparametrized_prior_specs(data)) \n",
    "#         return sum(\n",
    "#             int(np.product(get_shape(spec, data)))\n",
    "#             for _, spec in reparametrized_prior_specs(data)\n",
    "#         )\n",
    "\n",
    "    def generate_params(u, data):\n",
    "        params = {}\n",
    "        for name, spec, u_slice in reparametrized_prior_specs_and_u_slices(u, data):\n",
    "            if spec.transform is not None:\n",
    "                params[name] = spec.transform(u_slice)\n",
    "            else:\n",
    "                params[name] = u_slice\n",
    "        return params\n",
    "\n",
    "    def prior_neg_log_dens(u, data):\n",
    "        nld = 0\n",
    "        for _, spec, u_slice in reparametrized_prior_specs_and_u_slices(u, data):\n",
    "            nld += spec.distribution.neg_log_dens(u_slice)\n",
    "        return nld\n",
    "\n",
    "    def sample_from_prior(rng, data, num_sample=None):\n",
    "        u_slices = []\n",
    "        for _, spec in reparametrized_prior_specs(data):\n",
    "            shape = get_shape(spec, data)\n",
    "            if num_sample is None:\n",
    "                u_slices.append(\n",
    "                    np.atleast_1d(spec.distribution.sample(rng, shape).flatten())\n",
    "                )\n",
    "            else:\n",
    "                shape = (num_sample,) + shape\n",
    "                u_slices.append(\n",
    "                    np.atleast_2d(spec.distribution.sample(rng, shape).reshape((num_sample, -1)))\n",
    "                )\n",
    "\n",
    "        return np.concatenate(u_slices, -1)\n",
    "\n",
    "    return compute_dim_u, generate_params, prior_neg_log_dens, sample_from_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b925e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PriorSpecification = namedtuple(\n",
    "    \"PriorSpecification\",\n",
    "    (\"shape\", \"distribution\", \"transform\"),\n",
    "    defaults=((), normal(0, 1), None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ed638fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_specifications = {\n",
    "    \"μ\": PriorSpecification(distribution=normal(0, 1)),\n",
    "    \"σ\": PriorSpecification(distribution=half_normal(1)),\n",
    "    \"ϕ\": PriorSpecification(distribution=uniform(-1, 1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4667c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dim_u, generate_params, prior_neg_log_dens, sample_from_prior = set_up_prior(\n",
    "    prior_specifications\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20566401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_x_0(params, v_0, data):\n",
    "    return params[\"μ\"] + (params[\"σ\"] / (1 - params[\"ϕ\"] ** 2) ** 0.5) * v_0\n",
    "\n",
    "\n",
    "def forward_func(params, v, x, data):\n",
    "    return params[\"μ\"] + params[\"ϕ\"] * (x - params[\"μ\"]) + params[\"σ\"] * v\n",
    "\n",
    "\n",
    "def observation_func(params, n, x, data):\n",
    "    return np.exp(x / 2) * n\n",
    "\n",
    "\n",
    "def inverse_observation_func(params, n, y, data):\n",
    "    return 2 * np.log(y / n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "242c8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_state_space_model_generators(\n",
    "    generate_params, generate_x_0, forward_func, observation_func\n",
    "):\n",
    "    \"\"\"Construct functions to generate obs. and state sequences for state space models.\n",
    "    Args:\n",
    "        generate_params (Callable[[ArrayLike, Dict], Dict]): Function which generates a\n",
    "            dictionary of model parameters given a 1D array of unbounded global latent\n",
    "            variables and data dictionary.\n",
    "        generate_x_0 (Callable[[Dict, ArrayLike, Dict], ArrayLike]): Function which\n",
    "            generates the initial latent state given a dictionary of model parameters,\n",
    "            an array of unbounded local latent variables and a data dictionary.\n",
    "        forward_func (Callable[[Dict, ArrayLike, ArrayLike, Dict], ArrayLike]): Function\n",
    "            which generates the next state in the latent state sequence, given a\n",
    "            dictionary of model parameters, an array of unbounded local latent\n",
    "            variables, the current latent state and a data dictionary.\n",
    "        observation_func (Callable[[Dict, ArrayLike, ArrayLike, Dict], ArrayLike]):\n",
    "            Function which generates the observation of a latent state, given a\n",
    "            dictionary of model parameters, an array of unbounded local latent\n",
    "            (observation noise) variables, the current latent state and a data\n",
    "            dictionary.\n",
    "    Returns:\n",
    "        generate_from_model (\n",
    "                Callable[[ArrayLike, ArrayLike, Dict], Tuple[Dict, ArrayLike]]):\n",
    "            Function which given two array arguments and a data dictionary, the first\n",
    "            array corresponding to all unbounded global latent variables and the second\n",
    "            corresponding to all unbounded local latent variables, returns a dictionary\n",
    "            of model parameters and an array corresponding to the generated latent state\n",
    "            sequence.\n",
    "        generate_y (\n",
    "                Callable[[ArrayLike, ArrayLike, ArrayLike, Dict], ArrayLike]):\n",
    "            Function which given three arrays and a data dictionary, the first array\n",
    "            corresponding to all unbounded global latent variables, the second\n",
    "            corresponding to all unbounded local latent variables and the third\n",
    "            corresponding to all unbounded observation noise variables, returns an array\n",
    "            corresponding to all observed variables.\n",
    "    \"\"\"\n",
    "\n",
    "    def generate_from_model(u, v, data):\n",
    "        params = generate_params(u, data)\n",
    "        x_0 = generate_x_0(params, v[0], data)\n",
    "\n",
    "        def step(x, v):\n",
    "            x_ = forward_func(params, v, x, data)\n",
    "            return x_, x_\n",
    "\n",
    "        _, x_ = lax.scan(step, x_0, v[1:])\n",
    "        return params, np.concatenate((x_0[None], x_))\n",
    "\n",
    "    def generate_y(u, v, n, data):\n",
    "        params, x = generate_from_model(u, v, data)\n",
    "        y = jax.vmap(observation_func, (None, 0, 0))(params, n, x, data)\n",
    "        return y\n",
    "\n",
    "    return generate_from_model, generate_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abf61ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_from_model, generate_y = construct_state_space_model_generators(\n",
    "    generate_params=generate_params,\n",
    "    generate_x_0=generate_x_0,\n",
    "    forward_func=forward_func,\n",
    "    observation_func=observation_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e50d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_prior_neg_log_dens(q, data):\n",
    "    dim_u = compute_dim_u(data)\n",
    "    dim_y = data[\"y_obs\"].shape[0]\n",
    "    u, v, n = q[:dim_u], q[dim_u : dim_u + dim_y], q[dim_u + dim_y :]\n",
    "    return prior_neg_log_dens(u, data) + (v ** 2).sum() / 2 + (n ** 2).sum() / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee59afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_neg_log_dens(q, data):\n",
    "    dim_u = compute_dim_u(data)\n",
    "    u, v = q[:dim_u], q[dim_u:]\n",
    "    _, x = generate_from_model(u, v, data)\n",
    "    return (\n",
    "        prior_neg_log_dens(u, data)\n",
    "        + (v ** 2).sum() / 2\n",
    "        + (0.5 * ((data[\"y_obs\"] / np.exp(x / 2)) ** 2).sum() + (x / 2).sum())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4561a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constr_split(u, v, n, y, data):\n",
    "    params = generate_params(u, data)\n",
    "    x = 2 * np.log(y / n)\n",
    "    return (\n",
    "        np.concatenate(\n",
    "            (\n",
    "                (\n",
    "                    params[\"μ\"]\n",
    "                    + (params[\"σ\"] / (1 - params[\"ϕ\"] ** 2) ** 0.5) * v[0]\n",
    "                    - x[0]\n",
    "                )[None],\n",
    "                params[\"μ\"]\n",
    "                + params[\"ϕ\"] * (x[:-1] - params[\"μ\"])\n",
    "                + params[\"σ\"] * v[1:]\n",
    "                - x[1:],\n",
    "            )\n",
    "        ),\n",
    "        x,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "651ee2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacob_constr_split_blocks(u, v, n, y, data):\n",
    "    dim_u = compute_dim_u(data)\n",
    "    dim_y = y.shape[0]\n",
    "    params, dparams_du = jax.jvp(\n",
    "        lambda u_: generate_params(u_, data), (u,), (np.ones(dim_u),)\n",
    "    )\n",
    "    x = 2 * np.log(y / n)\n",
    "    dx_dy = 2 / y\n",
    "    one_minus_ϕ_sq = 1 - params[\"ϕ\"] ** 2\n",
    "    sqrt_one_minus_ϕ_sq = one_minus_ϕ_sq ** 0.5\n",
    "    v_0_over_sqrt_one_minus_ϕ_sq = v[0] / sqrt_one_minus_ϕ_sq\n",
    "    x_minus_μ = x[:-1] - params[\"μ\"]\n",
    "    dc_du = np.stack(\n",
    "        (\n",
    "            np.concatenate(\n",
    "                (\n",
    "                    dparams_du[\"μ\"][None],\n",
    "                    (1 - params[\"ϕ\"]) * dparams_du[\"μ\"] * np.ones(dim_y - 1),\n",
    "                )\n",
    "            ),\n",
    "            np.concatenate(\n",
    "                (\n",
    "                    dparams_du[\"σ\"][None] * v_0_over_sqrt_one_minus_ϕ_sq,\n",
    "                    dparams_du[\"σ\"] * v[1:],\n",
    "                )\n",
    "            ),\n",
    "            np.concatenate(\n",
    "                (\n",
    "                    dparams_du[\"ϕ\"][None]\n",
    "                    * params[\"ϕ\"]\n",
    "                    * params[\"σ\"]\n",
    "                    * v_0_over_sqrt_one_minus_ϕ_sq\n",
    "                    / one_minus_ϕ_sq,\n",
    "                    x_minus_μ * dparams_du[\"ϕ\"],\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "        1,\n",
    "    )\n",
    "    dc_dv = np.concatenate(\n",
    "        [params[\"σ\"][None] / sqrt_one_minus_ϕ_sq, params[\"σ\"] * np.ones(dim_y - 1)]\n",
    "    )\n",
    "    dc_dn = 2 / n, -2 * params[\"ϕ\"] / n[:-1]\n",
    "    c = np.concatenate(\n",
    "        (\n",
    "            (params[\"μ\"] + params[\"σ\"] * v_0_over_sqrt_one_minus_ϕ_sq - x[0])[None],\n",
    "            params[\"μ\"] + params[\"ϕ\"] * x_minus_μ + params[\"σ\"] * v[1:] - x[1:],\n",
    "        )\n",
    "    )\n",
    "    return (dc_du, dc_dv, dc_dn, dx_dy), c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d645e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_initial_states(rng, data, num_chain=4, algorithm=\"chmc\"):\n",
    "    \"\"\"Sample initial states from prior.\"\"\"\n",
    "    init_states = []\n",
    "    dim_y = data[\"y_obs\"].shape[0]\n",
    "    for _ in range(num_chain):\n",
    "        u = sample_from_prior(rng, data)\n",
    "        v = rng.standard_normal(dim_y)\n",
    "        if algorithm == \"chmc\":\n",
    "            _, x = generate_from_model(u, v, data)\n",
    "            n = data[\"y_obs\"] / onp.exp(x / 2)\n",
    "            q = onp.concatenate((u, v, onp.asarray(n)))\n",
    "        else:\n",
    "            q = onp.concatenate((u, v))\n",
    "        init_states.append(q)\n",
    "    return init_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "876d4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_argparser_with_standard_arguments(description):\n",
    "    parser = argparse.ArgumentParser(description=description)\n",
    "    parser.add_argument(\n",
    "        \"--output-root-dir\",\n",
    "        default=\"results\",\n",
    "        help=\"Root directory to make experiment output subdirectory in\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data-dir\", default=\"data\", help=\"Directory containing dataset files\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--algorithm\",\n",
    "        default=\"chmc\",\n",
    "        choices=(\"chmc\", \"hmc\"),\n",
    "        help=\"Which algorithm to perform inference with, from: chmc, hmc\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--prior-parametrization\",\n",
    "        choices=(\"unbounded\", \"normal\"),\n",
    "        default=\"unbounded\",\n",
    "        help=(\n",
    "            \"Parameterization to use for prior distribution. Default is to define all \"\n",
    "            \"parameters as transforms of unbounded variables. Alternatively parameters \"\n",
    "            \"may be expressed as transforms of standard normal variates where possible.\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--seed\", type=int, default=202101, help=\"Seed for random number generator\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-chain\",\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"Number of independent chains to sample\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-warm-up-iter\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        help=\"Number of chain iterations in adaptive warm-up sampling stage\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-main-iter\",\n",
    "        type=int,\n",
    "        default=2500,\n",
    "        help=\"Number of chain iterations in main sampling stage\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-tree-depth\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"Maximum depth of binary trajectory tree in each dynamic HMC iteration\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--step-size-adaptation-target\",\n",
    "        type=float,\n",
    "        default=0.8,\n",
    "        help=\"Target acceptance statistic for step size adaptation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--step-size-reg-coefficient\",\n",
    "        type=float,\n",
    "        default=0.05,\n",
    "        help=\"Regularisation coefficient for step size adaptation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--metric-type\",\n",
    "        choices=(\"diagonal\", \"dense\"),\n",
    "        default=\"diagonal\",\n",
    "        help=(\n",
    "            \"Metric type to adaptively tune during warm-up stage when using HMC \"\n",
    "            \"algorithm. If 'diagonal' a diagonal metric matrix representation is used \"\n",
    "            \"with diagonal entries set to reciprocals of estimates of the marginal \"\n",
    "            \"posterior variances. If 'dense' a dense metric matrix representation is \"\n",
    "            \"used corresponding to the inverse of an estimate of the posterior \"\n",
    "            \"covariance matrix.\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--projection-solver\",\n",
    "        choices=(\"newton\", \"quasi-newton\", \"newton-line-search\"),\n",
    "        default=\"newton\",\n",
    "        help=(\n",
    "            \"Iterative method to solve projection onto manifold when using CHMC \"\n",
    "            \"algorithm.\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--projection-solver-max-iters\",\n",
    "        type=int,\n",
    "        default=50,\n",
    "        help=\"Maximum number of iterations to try in projection solver\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--projection-solver-warm-up-constraint-tol\",\n",
    "        type=float,\n",
    "        default=1e-6,\n",
    "        help=\"Warm-up stage tolerance for constraint function norm in projection solver\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--projection-solver-warm-up-position-tol\",\n",
    "        type=float,\n",
    "        default=1e-5,\n",
    "        help=\"Warm-up stage tolerance for change in position norm in projection solver\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--projection-solver-main-constraint-tol\",\n",
    "        type=float,\n",
    "        default=1e-9,\n",
    "        help=\"Main stage tolerance for constraint function norm in projection solver\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--projection-solver-main-position-tol\",\n",
    "        type=float,\n",
    "        default=1e-8,\n",
    "        help=\"Main stage tolerance for change in position norm in projection solver\",\n",
    "    )\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48d7c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_norm(vct):\n",
    "    \"\"\"Calculate the maximum (L-infinity) norm of a vector.\"\"\"\n",
    "    return abs(vct).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3be8248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ssm_specific_args(parser):\n",
    "    group = parser.add_mutually_exclusive_group(required=False)\n",
    "    group.add_argument(\n",
    "        \"--use-manual-constraint-and-jacobian\",\n",
    "        dest=\"use_manual_constraint_and_jacobian\",\n",
    "        action=\"store_true\",\n",
    "        help=(\n",
    "            \"Use manually specifed split constraint and Jacobian functions rather \"\n",
    "            \"than automatically generated function.\"\n",
    "        ),\n",
    "    )\n",
    "    group.add_argument(\n",
    "        \"--use-auto-constraint-and-jacobian\",\n",
    "        dest=\"use_manual_constraint_and_jacobian\",\n",
    "        action=\"store_false\",\n",
    "        help=(\n",
    "            \"Use automatically generated split constraint and Jacobian functions rather\"\n",
    "            \" than manually defined functions generated functions.\"\n",
    "        ),\n",
    "    )\n",
    "    parser.set_defaults(use_manual_constraint_and_jacobian=True)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f0c0c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_trace_func(generate_params, data, dim_u, dim_v=None):\n",
    "\n",
    "    jitted_generate_params = jax.jit(partial(generate_params, data=data))\n",
    "\n",
    "    if dim_v is None:\n",
    "\n",
    "        def trace_func(state):\n",
    "            u = state.pos[:dim_u]\n",
    "            params = jitted_generate_params(u)\n",
    "            return {**params, \"u\": u}\n",
    "\n",
    "    else:\n",
    "\n",
    "        def trace_func(state):\n",
    "            u, v = state.pos[:dim_u], state.pos[dim_u : dim_u + dim_v]\n",
    "            params = jitted_generate_params(u)\n",
    "            return {**params, \"u\": u, \"v\": v}\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c028dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ssm_constrained_system_class_and_kwargs(\n",
    "    use_manual_constraint_and_jacobian,\n",
    "    generate_params,\n",
    "    generate_x_0,\n",
    "    forward_func,\n",
    "    inverse_observation_func,\n",
    "    constr_split,\n",
    "    jacob_constr_split_blocks,\n",
    "):\n",
    "    if use_manual_constraint_and_jacobian:\n",
    "        constrained_system_class = PartiallyInvertibleStateSpaceModelSystem\n",
    "        constrained_system_kwargs = {\n",
    "            \"constr_split\": constr_split,\n",
    "            \"jacob_constr_split_blocks\": jacob_constr_split_blocks,\n",
    "        }\n",
    "    else:\n",
    "        constrained_system_class = AutoPartiallyInvertibleStateSpaceModelSystem\n",
    "        constrained_system_kwargs = {\n",
    "            \"generate_params\": generate_params,\n",
    "            \"generate_x_0\": generate_x_0,\n",
    "            \"forward_func\": forward_func,\n",
    "            \"inverse_observation_func\": inverse_observation_func,\n",
    "        }\n",
    "    return constrained_system_class, constrained_system_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a3327ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_in_state(*depends_on):\n",
    "    \"\"\"Memoizing decorator for system methods.\n",
    "    Used to decorate `mici.systems.System` methods which compute a function of\n",
    "    one or more chain state variable(s), with the decorated method caching the\n",
    "    value returned by the method being wrapped in the `ChainState` object to\n",
    "    prevent the need for recomputation on future calls if the state variables\n",
    "    the returned value depends on have not been changed in between the calls.\n",
    "    Additionally for `ChainState` instances initialized with a `_call_counts`\n",
    "    argument, the memoized method will update a counter for the method in the\n",
    "    `_call_counts` attribute every time the method being decorated is called\n",
    "    (i.e. when there isn't a valid cached value available).\n",
    "    Args:\n",
    "       *depends_on: One or more strings corresponding to the names of any state\n",
    "           variables the value returned by the method depends on, e.g. 'pos' or\n",
    "           'mom', such that the cache in the state object is correctly cleared\n",
    "           when the value of any of these variables (attributes) of the state\n",
    "           object changes.\n",
    "    \"\"\"\n",
    "\n",
    "    def cache_in_state_decorator(method):\n",
    "        @wraps(method)\n",
    "        def wrapper(self, state):\n",
    "            key = _cache_key_func(self, method)\n",
    "            if key not in state._cache:\n",
    "                for dep in depends_on:\n",
    "                    state._dependencies[dep].add(key)\n",
    "            if key not in state._cache or state._cache[key] is None:\n",
    "                state._cache[key] = method(self, state)\n",
    "                if state._call_counts is not None:\n",
    "                    state._call_counts[key] += 1\n",
    "            return state._cache[key]\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return cache_in_state_decorator\n",
    "\n",
    "def cache_in_state_with_aux(depends_on, auxiliary_outputs):\n",
    "    \"\"\"Memoizing decorator for system methods with possible auxiliary outputs.\n",
    "    Used to decorate `mici.systems.System` methods which compute a function of\n",
    "    one or more chain state variable(s), with the decorated method caching the\n",
    "    value or values returned by the method being wrapped in the `ChainState`\n",
    "    object to prevent the need for recomputation on future calls if the state\n",
    "    variables the returned value(s) depends on have not been changed in between\n",
    "    the calls.\n",
    "    Compared to the `cache_in_state` decorator, this variant allows for methods\n",
    "    which may optionally also return additional auxiliary outputs, such as\n",
    "    intermediate result computed while computing the primary output, which\n",
    "    correspond to the output of another system method decorated with the\n",
    "    `cache_in_state` or `cache_in_state_with_aux` decorators. If such auxiliary\n",
    "    outputs are returned they are also used to update cache entry for the\n",
    "    corresponding decorated method, potentially saving recomputation in\n",
    "    subsequent calls to that method. A common instance of this pattern is in\n",
    "    derivative values computed using automatic differentiation (AD), with the\n",
    "    primal value being differentiated usually either calculated alongside the\n",
    "    derivative (in forward-mode AD) or calculated first in a forward-pass before\n",
    "    the derivatives are calculated in a reverse-pass (in reverse-mode AD). By\n",
    "    caching the value of the primal computed as part of the derivative\n",
    "    calculation, a subsequent call to a method corresponding to calculation of\n",
    "    the primal itself will retrieve the cached value and not recompute the\n",
    "    primal, providing the relevant state variables the primal (and derivative)\n",
    "    depend on have not been changed in between.\n",
    "    Additionally for `ChainState` instances initialized with a `_call_counts`\n",
    "    argument, the memoized method will update a counter for the method in the\n",
    "    `_call_counts` attribute every time the method being decorated is called\n",
    "    (i.e. when there isn't a valid cached value available).\n",
    "    Args:\n",
    "        depends_on (str or Tuple[str]): A string or tuple of strings, with each\n",
    "            string corresponding to the name of a state variables the value(s)\n",
    "            returned by the method depends on, e.g. 'pos' or 'mom', such that\n",
    "            the cache in the state object is correctly cleared when the value of\n",
    "            any of these variables (attributes) of the state object changes.\n",
    "        auxiliary_outputs (str or Tuple[str]): A string or tuple of strings,\n",
    "            with each string defining an auxiliary output the wrapped method may\n",
    "            additionally return in addition to the primary output. If auxiliary\n",
    "            outputs are returned, the returned value should be a tuple with\n",
    "            first entry the 'primary' output corresponding to the value\n",
    "            associated with the name of the method and the subsequent entries in\n",
    "            the tuple corresponding to the auxiliary outputs in the order\n",
    "            specified by the entries in the `auxiliary_outputs` argument. If the\n",
    "            primary output is itself a tuple, it must be wrapped in another\n",
    "            tuple even when no auxiliary outputs are being returned.\n",
    "    \"\"\"\n",
    "    if isinstance(depends_on, str):\n",
    "        depends_on = (depends_on,)\n",
    "    if isinstance(auxiliary_outputs, str):\n",
    "        auxiliary_outputs = (auxiliary_outputs,)\n",
    "\n",
    "    def cache_in_state_with_aux_decorator(method):\n",
    "        @wraps(method)\n",
    "        def wrapper(self, state):\n",
    "            prim_key = _cache_key_func(self, method)\n",
    "            keys = [prim_key] + [_cache_key_func(self, a) for a in auxiliary_outputs]\n",
    "            for i, key in enumerate(keys):\n",
    "                if key not in state._cache:\n",
    "                    for dep in depends_on:\n",
    "                        state._dependencies[dep].add(key)\n",
    "            if prim_key not in state._cache or state._cache[prim_key] is None:\n",
    "                vals = method(self, state)\n",
    "                if isinstance(vals, tuple):\n",
    "                    for k, v in zip(keys, vals):\n",
    "                        state._cache[k] = v\n",
    "                else:\n",
    "                    state._cache[prim_key] = vals\n",
    "                if state._call_counts is not None:\n",
    "                    state._call_counts[prim_key] += 1\n",
    "            return state._cache[prim_key]\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return cache_in_state_with_aux_decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b9e432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class System(ABC):\n",
    "    r\"\"\"Base class for Hamiltonian systems.\n",
    "    The Hamiltonian function \\(h\\) is assumed to have the general form\n",
    "    \\[ h(q, p) = h_1(q) + h_2(q, p) \\]\n",
    "    where \\(q\\) and \\(p\\) are the position and momentum variables respectively,\n",
    "    and \\(h_1\\) and \\(h_2\\) Hamiltonian component functions. The exact\n",
    "    Hamiltonian flow for the \\(h_1\\) component can be always be computed as it\n",
    "    depends only on the position variable however depending on the form of\n",
    "    \\(h_2\\) the corresponding exact Hamiltonian flow may or may not be\n",
    "    simulable.\n",
    "    By default \\(h_1\\) is assumed to correspond to the negative logarithm of an\n",
    "    unnormalized density on the position variables with respect to the Lebesgue\n",
    "    measure, with the corresponding distribution on the position space being\n",
    "    the target distribution it is wished to draw approximate samples from.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, neg_log_dens, grad_neg_log_dens=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            neg_log_dens (Callable[[array], float]): Function which given a\n",
    "                position array returns the negative logarithm of an\n",
    "                unnormalized probability density on the position space with\n",
    "                respect to the Lebesgue measure, with the corresponding\n",
    "                distribution on the position space being the target\n",
    "                distribution it is wished to draw approximate samples from.\n",
    "            grad_neg_log_dens (\n",
    "                    None or Callable[[array], array or Tuple[array, float]]):\n",
    "                Function which given a position array returns the derivative of\n",
    "                `neg_log_dens` with respect to the position array argument.\n",
    "                Optionally the function may instead return a 2-tuple of values\n",
    "                with the first being the array corresponding to the derivative\n",
    "                and the second being the value of the `neg_log_dens` evaluated\n",
    "                at the passed position array. If `None` is passed (the default)\n",
    "                an automatic differentiation fallback will be used to attempt\n",
    "                to construct the derivative of `neg_log_dens` automatically.\n",
    "        \"\"\"\n",
    "        self._neg_log_dens = neg_log_dens\n",
    "        self._grad_neg_log_dens = autodiff_fallback(\n",
    "            grad_neg_log_dens, neg_log_dens, \"grad_and_value\", \"grad_neg_log_dens\"\n",
    "        )\n",
    "\n",
    "    @cache_in_state(\"pos\")\n",
    "    def neg_log_dens(self, state):\n",
    "        \"\"\"Negative logarithm of unnormalized density of target distribution.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            float: Value of computed negative log density.\n",
    "        \"\"\"\n",
    "        return self._neg_log_dens(state.pos)\n",
    "\n",
    "    @cache_in_state_with_aux(\"pos\", \"neg_log_dens\")\n",
    "    def grad_neg_log_dens(self, state):\n",
    "        \"\"\"Derivative of negative log density with respect to position.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            array: Value of `neg_log_dens(state)` derivative with respect to\n",
    "                `state.pos`.\n",
    "        \"\"\"\n",
    "        return self._grad_neg_log_dens(state.pos)\n",
    "\n",
    "    def h1(self, state):\n",
    "        \"\"\"Hamiltonian component depending only on position.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            float: Value of `h1` Hamiltonian component.\n",
    "        \"\"\"\n",
    "        return self.neg_log_dens(state)\n",
    "\n",
    "    def dh1_dpos(self, state):\n",
    "        \"\"\"Derivative of `h1` Hamiltonian component with respect to position.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            array: Value of computed `h1` derivative.\n",
    "        \"\"\"\n",
    "        return self.grad_neg_log_dens(state)\n",
    "\n",
    "    def h1_flow(self, state, dt):\n",
    "        \"\"\"Apply exact flow map corresponding to `h1` Hamiltonian component.\n",
    "        `state` argument is modified in place.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to start flow at.\n",
    "            dt (float): Time interval to simulate flow for.\n",
    "        \"\"\"\n",
    "        state.mom -= dt * self.dh1_dpos(state)\n",
    "\n",
    "    @abstractmethod\n",
    "    def h2(self, state):\n",
    "        \"\"\"Hamiltonian component depending on momentum and optionally position.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            float: Value of `h2` Hamiltonian component.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def dh2_dmom(self, state):\n",
    "        \"\"\"Derivative of `h2` Hamiltonian component with respect to momentum.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            array: Value of `h2(state)` derivative with respect to `state.pos`.\n",
    "        \"\"\"\n",
    "\n",
    "    def h(self, state):\n",
    "        \"\"\"Hamiltonian function for system.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            float: Value of Hamiltonian.\n",
    "        \"\"\"\n",
    "        return self.h1(state) + self.h2(state)\n",
    "\n",
    "    def dh_dpos(self, state):\n",
    "        \"\"\"Derivative of Hamiltonian with respect to position.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            array: Value of `h(state)` derivative with respect to `state.pos`.\n",
    "        \"\"\"\n",
    "        if hasattr(self, \"dh2_dpos\"):\n",
    "            return self.dh1_dpos(state) + self.dh2_dpos(state)\n",
    "        else:\n",
    "            return self.dh1_dpos(state)\n",
    "\n",
    "    def dh_dmom(self, state):\n",
    "        \"\"\"Derivative of Hamiltonian with respect to momentum.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State to compute value at.\n",
    "        Returns:\n",
    "            array: Value of `h(state)` derivative with respect to `state.mom`.\n",
    "        \"\"\"\n",
    "        return self.dh2_dmom(state)\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample_momentum(self, state, rng):\n",
    "        \"\"\"\n",
    "        Sample a momentum from its conditional distribution given a position.\n",
    "        Args:\n",
    "            state (mici.states.ChainState): State defining position to\n",
    "               condition on.\n",
    "        Returns:\n",
    "            mom (array): Sampled momentum.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fcaf298",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AbstractDifferentiableGenerativeModelSystem(System):\n",
    "    \"\"\"Base class for constrained systems for differentiable generative models.\n",
    "    Compare to in-built Mici constrained system classes, uses 'matrix-free'\n",
    "    implementations of operations involving constraint function Jacobian and Gram matrix\n",
    "    to allow exploiting any structure present, and also JIT compiles iterative solvers\n",
    "    for projection steps to improve performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        neg_log_dens,\n",
    "        grad_neg_log_dens,\n",
    "        constr,\n",
    "        jacob_constr_blocks,\n",
    "        decompose_gram,\n",
    "        lmult_by_jacob_constr,\n",
    "        rmult_by_jacob_constr,\n",
    "        lmult_by_inv_gram,\n",
    "        lmult_by_inv_jacob_product,\n",
    "        log_det_sqrt_gram,\n",
    "        lmult_by_pinv_jacob_constr=None,\n",
    "        normal_space_component=None,\n",
    "    ):\n",
    "\n",
    "        if lmult_by_pinv_jacob_constr is None:\n",
    "\n",
    "            def lmult_by_pinv_jacob_constr(jacob_constr_blocks, gram_components, vct):\n",
    "                return rmult_by_jacob_constr(\n",
    "                    *jacob_constr_blocks,\n",
    "                    lmult_by_inv_gram(*jacob_constr_blocks, *gram_components, vct,),\n",
    "                )\n",
    "\n",
    "        if normal_space_component is None:\n",
    "\n",
    "            def normal_space_component(jacob_constr_blocks, gram_components, vct):\n",
    "                return lmult_by_pinv_jacob_constr(\n",
    "                    jacob_constr_blocks,\n",
    "                    gram_components,\n",
    "                    lmult_by_jacob_constr(*jacob_constr_blocks, vct),\n",
    "                )\n",
    "\n",
    "        def quasi_newton_projection(\n",
    "            q,\n",
    "            jacob_constr_blocks_prev,\n",
    "            gram_components_prev,\n",
    "            dt,\n",
    "            constraint_tol,\n",
    "            position_tol,\n",
    "            divergence_tol,\n",
    "            max_iters,\n",
    "            norm,\n",
    "        ):\n",
    "            \"\"\"Quasi-Newton method to solve projection onto manifold.\"\"\"\n",
    "\n",
    "            def body_func(val):\n",
    "                q, mu, i, _, _ = val\n",
    "                c = constr(q)\n",
    "                error = norm(c)\n",
    "                delta_mu = lmult_by_pinv_jacob_constr(\n",
    "                    jacob_constr_blocks_prev, gram_components_prev, c\n",
    "                )\n",
    "                mu += delta_mu\n",
    "                q -= delta_mu\n",
    "                i += 1\n",
    "                return q, mu, i, norm(delta_mu), error\n",
    "\n",
    "            def cond_func(val):\n",
    "                _, _, i, norm_delta_q, error = val\n",
    "                diverged = np.logical_or(error > divergence_tol, np.isnan(error))\n",
    "                converged = np.logical_and(\n",
    "                    error < constraint_tol, norm_delta_q < position_tol\n",
    "                )\n",
    "                return np.logical_not(\n",
    "                    np.logical_or((i >= max_iters), np.logical_or(diverged, converged))\n",
    "                )\n",
    "\n",
    "            q, mu, i, norm_delta_q, error = lax.while_loop(\n",
    "                cond_func, body_func, (q, np.zeros_like(q), 0, np.inf, -1.0)\n",
    "            )\n",
    "            return q, mu / dt, i, norm_delta_q, error\n",
    "\n",
    "        def newton_projection(\n",
    "            q,\n",
    "            jacob_constr_blocks_prev,\n",
    "            dt,\n",
    "            constraint_tol,\n",
    "            position_tol,\n",
    "            divergence_tol,\n",
    "            max_iters,\n",
    "            norm,\n",
    "        ):\n",
    "            \"\"\"Newton method to solve projection onto manifold.\"\"\"\n",
    "\n",
    "            def body_func(val):\n",
    "                q, mu, i, _, _ = val\n",
    "                jac_blocks, c = jacob_constr_blocks(q)\n",
    "                error = norm(c)\n",
    "                delta_mu = rmult_by_jacob_constr(\n",
    "                    *jacob_constr_blocks_prev,\n",
    "                    lmult_by_inv_jacob_product(\n",
    "                        *jac_blocks, *jacob_constr_blocks_prev, c\n",
    "                    ),\n",
    "                )\n",
    "                mu += delta_mu\n",
    "                q -= delta_mu\n",
    "                i += 1\n",
    "                return q, mu, i, norm(delta_mu), error\n",
    "\n",
    "            def cond_func(val):\n",
    "                _, _, i, norm_delta_q, error = val\n",
    "                diverged = np.logical_or(error > divergence_tol, np.isnan(error))\n",
    "                converged = np.logical_and(\n",
    "                    error < constraint_tol, norm_delta_q < position_tol\n",
    "                )\n",
    "                return np.logical_not(\n",
    "                    np.logical_or((i >= max_iters), np.logical_or(diverged, converged))\n",
    "                )\n",
    "\n",
    "            q, mu, i, norm_delta_q, error = lax.while_loop(\n",
    "                cond_func, body_func, (q, np.zeros_like(q), 0, np.inf, -1.0)\n",
    "            )\n",
    "            return q, mu / dt, i, norm_delta_q, error\n",
    "\n",
    "        def newton_projection_with_line_search(\n",
    "            q,\n",
    "            jacob_constr_blocks_prev,\n",
    "            dt,\n",
    "            constraint_tol,\n",
    "            position_tol,\n",
    "            divergence_tol,\n",
    "            max_iters,\n",
    "            max_line_search_iters,\n",
    "            norm,\n",
    "        ):\n",
    "            \"\"\"Newton method with line search to solve projection onto manifold.\"\"\"\n",
    "\n",
    "            def body_func(loop_state):\n",
    "                q, _, _, i, num_constr_calls = loop_state\n",
    "                jac_blocks, c = jacob_constr_blocks(q)\n",
    "                error = norm(c)\n",
    "                search_direction = -rmult_by_jacob_constr(\n",
    "                    *jacob_constr_blocks_prev,\n",
    "                    lmult_by_inv_jacob_product(\n",
    "                        *jac_blocks, *jacob_constr_blocks_prev, c\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                def inner_body_func(inner_loop_state):\n",
    "                    step_size, _, _, j = inner_loop_state\n",
    "                    new_q = q + step_size * search_direction\n",
    "                    new_error = norm(constr(new_q))\n",
    "                    return step_size * 0.5, new_q, new_error, j + 1\n",
    "\n",
    "                def inner_cond_func(inner_loop_state):\n",
    "                    _, _, new_error, j = inner_loop_state\n",
    "                    return np.logical_and(j < max_line_search_iters, new_error > error)\n",
    "\n",
    "\n",
    "                (step_size, new_q, new_error, j) = inner_body_func((1., None, None, 0))\n",
    "                (_, new_q, new_error, j) = lax.while_loop(\n",
    "                    inner_cond_func, inner_body_func, (step_size, new_q, new_error, j)\n",
    "                )\n",
    "                return new_q, norm(new_q - q), new_error, i + 1, num_constr_calls + j\n",
    "\n",
    "            def cond_func(loop_state):\n",
    "                _, norm_delta_q, error, i, _ = loop_state\n",
    "                diverged = np.logical_or(error > divergence_tol, np.isnan(error))\n",
    "                converged = np.logical_and(\n",
    "                    error < constraint_tol, norm_delta_q < position_tol\n",
    "                )\n",
    "                return np.logical_not(\n",
    "                    np.logical_or((i >= max_iters), np.logical_or(diverged, converged))\n",
    "                )\n",
    "\n",
    "            new_q, norm_delta_q, error, i, num_constr_calls = lax.while_loop(\n",
    "                cond_func, body_func, (q, np.inf, -1., 0, 0)\n",
    "            )\n",
    "            return new_q, (q - new_q) / dt, i, norm_delta_q, error, num_constr_calls\n",
    "\n",
    "        self._constr = jax.jit(constr)\n",
    "        self._jacob_constr_blocks = jax.jit(jacob_constr_blocks)\n",
    "        self._decompose_gram = jax.jit(decompose_gram)\n",
    "        self._log_det_sqrt_gram = jax.jit(log_det_sqrt_gram)\n",
    "        self._val_and_grad_log_det_sqrt_gram = jax.jit(\n",
    "            jax.value_and_grad(log_det_sqrt_gram, has_aux=True)\n",
    "        )\n",
    "        self._lmult_by_jacob_constr = jax.jit(lmult_by_jacob_constr)\n",
    "        self._rmult_by_jacob_constr = jax.jit(rmult_by_jacob_constr)\n",
    "        self._lmult_by_pinv_jacob_constr = jax.jit(lmult_by_pinv_jacob_constr)\n",
    "        self._lmult_by_inv_jacob_product = jax.jit(lmult_by_inv_jacob_product)\n",
    "        self._normal_space_component = jax.jit(normal_space_component)\n",
    "        self._quasi_newton_projection = jax.jit(\n",
    "            quasi_newton_projection, static_argnames=\"norm\"\n",
    "        )\n",
    "        self._newton_projection = jax.jit(newton_projection, static_argnames=\"norm\")\n",
    "        self._newton_projection_with_line_search = jax.jit(\n",
    "            newton_projection_with_line_search, static_argnames=\"norm\"\n",
    "        )\n",
    "        super().__init__(neg_log_dens=neg_log_dens, grad_neg_log_dens=grad_neg_log_dens)\n",
    "\n",
    "    def precompile_jax_functions(self, q, solver_norm=maximum_norm):\n",
    "        self._neg_log_dens(q)\n",
    "        self._grad_neg_log_dens(q)\n",
    "        self._constr(q)\n",
    "        jac_blocks, c = self._jacob_constr_blocks(q)\n",
    "        gram_components = self._decompose_gram(*jac_blocks)\n",
    "        self._log_det_sqrt_gram(q)\n",
    "        self._val_and_grad_log_det_sqrt_gram(q)\n",
    "        self._lmult_by_jacob_constr(*jac_blocks, q)\n",
    "        self._rmult_by_jacob_constr(*jac_blocks, c)\n",
    "        self._lmult_by_pinv_jacob_constr(jac_blocks, gram_components, c)\n",
    "        self._lmult_by_inv_jacob_product(*jac_blocks, *jac_blocks, c)\n",
    "        self._normal_space_component(jac_blocks, gram_components, q)\n",
    "        self._quasi_newton_projection(\n",
    "            q, jac_blocks, gram_components, 1., 0.1, 0.1, 1., 10, solver_norm\n",
    "        )\n",
    "        self._newton_projection(q, jac_blocks, 1., 0.1, 0.1, 1., 10, solver_norm)\n",
    "        self._newton_projection_with_line_search(\n",
    "            q, jac_blocks, 1., 0.1, 0.1, 1., 10, 10, solver_norm)\n",
    "\n",
    "    @cache_in_state(\"pos\")\n",
    "    def constr(self, state):\n",
    "        return convert_to_numpy_pytree(self._constr(state.pos))\n",
    "\n",
    "    @cache_in_state_with_aux(\"pos\", \"constr\")\n",
    "    def jacob_constr_blocks(self, state):\n",
    "        return convert_to_numpy_pytree(self._jacob_constr_blocks(state.pos))\n",
    "\n",
    "    @cache_in_state(\"pos\")\n",
    "    def gram_components(self, state):\n",
    "        return convert_to_numpy_pytree(\n",
    "            self._decompose_gram(*self.jacob_constr_blocks(state))\n",
    "        )\n",
    "\n",
    "    @cache_in_state_with_aux(\n",
    "        \"pos\", (\"constr\", \"jacob_constr_blocks\", \"gram_components\"),\n",
    "    )\n",
    "    def log_det_sqrt_gram(self, state):\n",
    "        val, (constr, jacob_constr_blocks, gram_components) = self._log_det_sqrt_gram(\n",
    "            state.pos\n",
    "        )\n",
    "        return convert_to_numpy_pytree(\n",
    "            (val, constr, jacob_constr_blocks, gram_components)\n",
    "        )\n",
    "\n",
    "    @cache_in_state_with_aux(\n",
    "        \"pos\",\n",
    "        (\"log_det_sqrt_gram\", \"constr\", \"jacob_constr_blocks\", \"gram_components\"),\n",
    "    )\n",
    "    def grad_log_det_sqrt_gram(self, state):\n",
    "        (\n",
    "            (val, (constr, jacob_constr_blocks, gram_components)),\n",
    "            grad,\n",
    "        ) = self._val_and_grad_log_det_sqrt_gram(state.pos)\n",
    "        return convert_to_numpy_pytree(\n",
    "            (grad, val, constr, jacob_constr_blocks, gram_components)\n",
    "        )\n",
    "\n",
    "    def h1(self, state):\n",
    "        return self.neg_log_dens(state) + self.log_det_sqrt_gram(state)\n",
    "\n",
    "    def dh1_dpos(self, state):\n",
    "        return self.grad_neg_log_dens(state) + self.grad_log_det_sqrt_gram(state)\n",
    "\n",
    "    def h2(self, state):\n",
    "        return 0.5 * state.mom @ state.mom\n",
    "\n",
    "    def dh2_dmom(self, state):\n",
    "        return state.mom\n",
    "\n",
    "    def dh2_dpos(self, state):\n",
    "        return 0 * state.pos\n",
    "\n",
    "    def dh_dpos(self, state):\n",
    "        return self.dh1_dpos(state)\n",
    "\n",
    "    def h2_flow(self, state, dt):\n",
    "        state.pos += dt * self.dh2_dmom(state)\n",
    "\n",
    "    def dh2_flow_dmom(self, dt):\n",
    "        return (dt * IdentityMatrix(), IdentityMatrix())\n",
    "\n",
    "    def normal_space_component(self, state, vct):\n",
    "        return onp.asarray(\n",
    "            self._normal_space_component(\n",
    "                self.jacob_constr_blocks(state), self.gram_components(state), vct\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def lmult_by_jacob_constr(self, state, vct):\n",
    "        return onp.asarray(\n",
    "            self._lmult_by_jacob_constr(*self.jacob_constr_blocks(state), vct)\n",
    "        )\n",
    "\n",
    "    def rmult_by_jacob_constr(self, state, vct):\n",
    "        return onp.asarray(\n",
    "            self._rmult_by_jacob_constr(*self.jacob_constr_blocks(state), vct)\n",
    "        )\n",
    "\n",
    "    def lmult_by_pinv_jacob_constr(self, state, vct):\n",
    "        return onp.asarray(\n",
    "            self._lmult_by_pinv_jacob_constr(\n",
    "                self.jacob_constr_blocks(state), self.gram_components(state), vct\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def lmult_by_inv_jacob_product(self, state_1, state_2, vct):\n",
    "        return onp.asarray(\n",
    "            self._lmult_by_inv_jacob_product(\n",
    "                *self.jacob_constr_blocks(state_1),\n",
    "                *self.jacob_constr_blocks(state_2),\n",
    "                vct,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def project_onto_cotangent_space(self, mom, state):\n",
    "        mom -= self.normal_space_component(state, mom)\n",
    "        return mom\n",
    "\n",
    "    def sample_momentum(self, state, rng):\n",
    "        mom = rng.standard_normal(state.pos.shape)\n",
    "        mom = self.project_onto_cotangent_space(mom, state)\n",
    "        return mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a334285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_normal_neg_log_dens(q):\n",
    "    \"\"\"Unnormalised negative log density of standard normal vector.\"\"\"\n",
    "    return 0.5 * onp.sum(q ** 2)\n",
    "\n",
    "def standard_normal_grad_neg_log_dens(q):\n",
    "    \"\"\"Gradient and value of negative log density of standard normal vector.\"\"\"\n",
    "    return q, 0.5 * onp.sum(q ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "273d4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartiallyInvertibleStateSpaceModelSystem(\n",
    "    _AbstractDifferentiableGenerativeModelSystem\n",
    "):\n",
    "    \"\"\"System class for scalar state space models with invertible observation functions.\n",
    "    Generative model is assumed to be of the form\n",
    "        params = generate_params(u, data)\n",
    "        x[0] = generate_x_0(params, v[0], data)\n",
    "        for t in range(dim_y):\n",
    "            x[t] = forward_func(params, v[t], x[t - 1], data)\n",
    "            y[t] = observation_func(params, n[t], x[t], data)\n",
    "    If `inverse_observation_func` corresponds to the inverse of `observation_func` in\n",
    "    its third argument,\n",
    "        observation_func(\n",
    "            params, n, inverse_observation_func(params, n, y, data), data) == y\n",
    "    then we can define a 'split' constraint function for the generative model as follows\n",
    "        def constr_split(u, v, n, y, data):\n",
    "            params = generate_params(u, data)\n",
    "            x = [\n",
    "                inverse_observation_func(params, n[t], y[t], data)\n",
    "                for t in range(1, dim_y)\n",
    "            ]\n",
    "            return array(\n",
    "                [generate_x_0(params, v[0], data) - x[0]] +\n",
    "                [\n",
    "                    forward_func(params, v[t], x[t-1], data) - x[t]\n",
    "                    for t in range(1, dim_y)\n",
    "                ]\n",
    "            ), x\n",
    "    where `y` is a `(dim_y,)` shaped 1D array of observed variables, `u` is a `(dim_u,)`\n",
    "    shaped 1D array of global latent variables, `v` is a `(dim_y,)` shaped 1D array of\n",
    "    local latent variables, `n` is a `(dim_y,)` shaped 1D array of observation noise\n",
    "    variables and `data` is a dictionary of fixed values / data used by model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        constr_split,\n",
    "        jacob_constr_split_blocks,\n",
    "        data,\n",
    "        dim_u,\n",
    "        neg_log_dens=standard_normal_neg_log_dens,\n",
    "        grad_neg_log_dens=standard_normal_grad_neg_log_dens,\n",
    "    ):\n",
    "        dim_y = data[\"y_obs\"].shape[0]\n",
    "\n",
    "        if jacob_constr_split_blocks is None:\n",
    "\n",
    "            def jacob_constr_split_blocks(u, v, n, y, data):\n",
    "                dc_du = jax.jacfwd(lambda u_: constr_split(u_, v, n, y, data)[0])(u)\n",
    "                one_vct = np.ones(dim_y)\n",
    "                alt_vct = (-1.0) ** np.arange(dim_y)\n",
    "                _, dx_dy = jax.jvp(\n",
    "                    lambda y_: constr_split(u, v, n, y_, data)[1], (y,), (one_vct,)\n",
    "                )\n",
    "                c, dc_dv = jax.jvp(\n",
    "                    lambda v_: constr_split(u, v_, n, y, data)[0], (v,), (one_vct,)\n",
    "                )\n",
    "                _, dc_dn_1 = jax.jvp(\n",
    "                    lambda n_: constr_split(u, v, n_, y, data)[0], (n,), (one_vct,)\n",
    "                )\n",
    "                _, dc_dn_a = jax.jvp(\n",
    "                    lambda n_: constr_split(u, v, n_, y, data)[0], (n,), (alt_vct,)\n",
    "                )\n",
    "                dc_dn = (\n",
    "                    (dc_dn_1 + dc_dn_a * alt_vct) / 2,\n",
    "                    (dc_dn_1[1:] - dc_dn_a[1:] * alt_vct[1:]) / 2,\n",
    "                )\n",
    "                return (dc_du, dc_dv, dc_dn, dx_dy), c\n",
    "\n",
    "        def constr(q):\n",
    "            u, v, n = np.split(q, (dim_u, dim_u + dim_y))\n",
    "            return constr_split(u, v, n, data[\"y_obs\"], data)[0]\n",
    "\n",
    "        def jacob_constr_blocks(q):\n",
    "            u, v, n = np.split(q, (dim_u, dim_u + dim_y))\n",
    "            return jacob_constr_split_blocks(u, v, n, data[\"y_obs\"], data)\n",
    "\n",
    "        def lmult_by_jacob_constr(dc_du, dc_dv, dc_dn, dx_dy, vct):\n",
    "            vct_u, vct_v, vct_n = (\n",
    "                vct[:dim_u],\n",
    "                vct[dim_u : dim_u + dim_y],\n",
    "                vct[dim_u + dim_y :],\n",
    "            )\n",
    "            return (\n",
    "                dc_du @ vct_u\n",
    "                + dc_dv * vct_v\n",
    "                + dc_dn[0] * vct_n\n",
    "                + np.pad(dc_dn[1] * vct_n[:-1], (1, 0))\n",
    "            )\n",
    "\n",
    "        def rmult_by_jacob_constr(dc_du, dc_dv, dc_dn, dx_dy, vct):\n",
    "            return np.concatenate(\n",
    "                (\n",
    "                    vct @ dc_du,\n",
    "                    vct * dc_dv,\n",
    "                    vct * dc_dn[0] + np.pad(dc_dn[1] * vct[1:], (0, 1)),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        def decompose_gram(dc_du, dc_dv, dc_dn, dx_dy):\n",
    "            a = dc_dn[0][:-1] * dc_dn[1]\n",
    "            b = dc_dv ** 2 + dc_dn[0] ** 2 + np.pad(dc_dn[1] ** 2, (1, 0))\n",
    "            cap_mtx = np.eye(dim_u) + dc_du.T @ jax.vmap(\n",
    "                tridiagonal_solve, (None, None, None, 1), 1\n",
    "            )(a, b, a, dc_du)\n",
    "            chol_cap_mtx = cholesky(cap_mtx)\n",
    "            return (a, b, chol_cap_mtx)\n",
    "\n",
    "        def lmult_by_inv_gram(dc_du, dc_dv, dc_dn, dx_dy, a, b, chol_cap_mtx, vct):\n",
    "            return tridiagonal_solve(\n",
    "                a,\n",
    "                b,\n",
    "                a,\n",
    "                vct\n",
    "                - dc_du\n",
    "                @ sla.cho_solve(\n",
    "                    (chol_cap_mtx, True), dc_du.T @ tridiagonal_solve(a, b, a, vct)\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        def lmult_by_inv_jacob_product(\n",
    "            dc_du_l, dc_dv_l, dc_dn_l, dx_dy_l, dc_du_r, dc_dv_r, dc_dn_r, dx_dy_r, vct\n",
    "        ):\n",
    "            a = dc_dn_l[1] * dc_dn_r[0][:-1]\n",
    "            b = (\n",
    "                dc_dv_l * dc_dv_r\n",
    "                + dc_dn_l[0] * dc_dn_r[0]\n",
    "                + np.pad(dc_dn_l[1] * dc_dn_r[1], (1, 0))\n",
    "            )\n",
    "            c = dc_dn_l[0][:-1] * dc_dn_r[1]\n",
    "            cap_mtx = np.eye(dim_u) + dc_du_r.T @ jax.vmap(\n",
    "                tridiagonal_solve, (None, None, None, 1), 1\n",
    "            )(a, b, c, dc_du_l)\n",
    "            return tridiagonal_solve(\n",
    "                a,\n",
    "                b,\n",
    "                c,\n",
    "                vct\n",
    "                - dc_du_l\n",
    "                @ np.linalg.solve(cap_mtx, dc_du_r.T @ tridiagonal_solve(a, b, c, vct)),\n",
    "            )\n",
    "\n",
    "        def log_det_sqrt_gram(q):\n",
    "            (dc_du, dc_dv, dc_dn, dx_dy), c = jacob_constr_blocks(q)\n",
    "            (a, b, chol_cap_mtx,) = decompose_gram(dc_du, dc_dv, dc_dn, dx_dy)\n",
    "            return (\n",
    "                np.log(chol_cap_mtx.diagonal()).sum()\n",
    "                + tridiagonal_pos_def_log_det(a, b) / 2\n",
    "                - np.log(abs(dx_dy)).sum(),\n",
    "                (c, (dc_du, dc_dv, dc_dn, dx_dy), (a, b, chol_cap_mtx,)),\n",
    "            )\n",
    "\n",
    "        super().__init__(\n",
    "            neg_log_dens=neg_log_dens,\n",
    "            grad_neg_log_dens=grad_neg_log_dens,\n",
    "            constr=constr,\n",
    "            jacob_constr_blocks=jacob_constr_blocks,\n",
    "            decompose_gram=decompose_gram,\n",
    "            lmult_by_jacob_constr=lmult_by_jacob_constr,\n",
    "            rmult_by_jacob_constr=rmult_by_jacob_constr,\n",
    "            lmult_by_inv_gram=lmult_by_inv_gram,\n",
    "            lmult_by_inv_jacob_product=lmult_by_inv_jacob_product,\n",
    "            log_det_sqrt_gram=log_det_sqrt_gram,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fc732c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72d56221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    args,\n",
    "    data,\n",
    "    rng,\n",
    "    experiment_name,\n",
    "    var_names,\n",
    "    var_trace_func,\n",
    "    sample_initial_states,\n",
    "    constrained_system_class,\n",
    "    constrained_system_kwargs,\n",
    "    euclidean_system_class=mici.systems.EuclideanMetricSystem,\n",
    "    euclidean_system_kwargs=None,\n",
    "    posterior_neg_log_dens=None,\n",
    "    extended_prior_neg_log_dens=None,\n",
    "    dir_prefix=None,\n",
    "    precompile_jax_functions=True,\n",
    "):\n",
    "\n",
    "    print(\n",
    "        f\"Running experiment with {experiment_name} model using \"\n",
    "        f\"{args.algorithm.upper()} algorithm for inference\"\n",
    "    )\n",
    "\n",
    "    # Set up output directory and logger\n",
    "\n",
    "    output_dir = set_up_output_directory(args, experiment_name, dir_prefix)\n",
    "    set_up_logger(output_dir)\n",
    "\n",
    "    print(f\"Results will be saved to {output_dir}\")\n",
    "\n",
    "    # Add parametrization flag to data dictionary\n",
    "\n",
    "    data[\"parametrization\"] = args.prior_parametrization\n",
    "\n",
    "    # Set up Mici objects\n",
    "    if posterior_neg_log_dens is not None:\n",
    "        (\n",
    "            neg_log_dens_hmc,\n",
    "            grad_neg_log_dens_hmc,\n",
    "        ) = mlift.construct_mici_system_neg_log_dens_functions(\n",
    "            partial(posterior_neg_log_dens, data=data)\n",
    "        )\n",
    "        euclidean_system_kwargs = {\n",
    "            \"neg_log_dens\": neg_log_dens_hmc,\n",
    "            \"grad_neg_log_dens\": grad_neg_log_dens_hmc,\n",
    "        }\n",
    "    elif euclidean_system_kwargs is None:\n",
    "        raise ValueError(\n",
    "            \"One of either posterior_neg_log_dens or euclidean_system_kwargs must \"\n",
    "            \"not be None \"\n",
    "        )\n",
    "\n",
    "    if extended_prior_neg_log_dens is not None:\n",
    "        (\n",
    "            neg_log_dens_chmc,\n",
    "            grad_neg_log_dens_chmc,\n",
    "        ) = mlift.construct_mici_system_neg_log_dens_functions(\n",
    "            partial(extended_prior_neg_log_dens, data=data)\n",
    "        )\n",
    "        constrained_system_kwargs[\"neg_log_dens\"] = neg_log_dens_chmc\n",
    "        constrained_system_kwargs[\"grad_neg_log_dens\"] = grad_neg_log_dens_chmc\n",
    "\n",
    "    system, integrator, sampler, adapters, monitor_stats = set_up_mici_objects(\n",
    "        args,\n",
    "        rng,\n",
    "        constrained_system_class,\n",
    "        constrained_system_kwargs,\n",
    "        euclidean_system_class,\n",
    "        euclidean_system_kwargs,\n",
    "    )\n",
    "\n",
    "    def hamiltonian_and_call_count_trace_func(state):\n",
    "        call_counts = {\n",
    "            name.split(\".\")[-1] + \"_calls\": val\n",
    "            for (name, _), val in state._call_counts.items()\n",
    "        }\n",
    "        return {\n",
    "            **call_counts,\n",
    "            \"hamiltonian\": system.h(state),\n",
    "            \"neg_log_dens\": system.neg_log_dens(state),\n",
    "        }\n",
    "\n",
    "    trace_funcs = [var_trace_func, hamiltonian_and_call_count_trace_func]\n",
    "\n",
    "    # Initialise chain states\n",
    "\n",
    "    print(\"Sampling initial states ...\")\n",
    "    init_states = sample_initial_states(rng, data, args.num_chain, args.algorithm)\n",
    "    init_states = [\n",
    "        mici.states.ChainState(pos=q, mom=None, dir=1, _call_counts={})\n",
    "        for q in init_states\n",
    "    ]\n",
    "\n",
    "    # Precompile JAX functions to avoid compilation time appearing in chain run times\n",
    "\n",
    "    if precompile_jax_functions:\n",
    "        print(\"Pre-compiling JAX functions ...\")\n",
    "        compile_time = precompile_system_jax_functions(init_states[0].pos, args, system)\n",
    "        print(f\"Total compile time: {compile_time:.0f} seconds\")\n",
    "    else:\n",
    "        compile_time = 0\n",
    "\n",
    "    # Ignore NumPy floating point overflow warnings\n",
    "    # Prevents warning messages being produced while progress bars are being printed\n",
    "\n",
    "    np.seterr(over=\"ignore\")\n",
    "\n",
    "    # Sample chains\n",
    "\n",
    "    final_states, traces, stats, sampling_time = sample_chains(\n",
    "        args, sampler, init_states, trace_funcs, adapters, output_dir, monitor_stats\n",
    "    )\n",
    "\n",
    "    print(f\"Integrator step size: {integrator.step_size:.2g}\")\n",
    "    print(f\"Total sampling time: {sampling_time:.0f} seconds\")\n",
    "\n",
    "    # Compute and display summary of time spent on different operation\n",
    "\n",
    "    print(\"Computing chain operation times ...\")\n",
    "    operation_times = compute_operation_times(system, final_states)\n",
    "    print(\n",
    "        f\"Total operation time: {operation_times['total_operation_time']:.3g} seconds\"\n",
    "    )\n",
    "\n",
    "    # Compute, display and save summary of statistics of traced chain variables\n",
    "\n",
    "    summary_vars = var_names + [\"neg_log_dens\", \"hamiltonian\"]\n",
    "    summary, summary_dict = compute_and_save_summary(\n",
    "        output_dir,\n",
    "        summary_vars,\n",
    "        traces,\n",
    "        total_compile_time=compile_time,\n",
    "        total_sampling_time=sampling_time,\n",
    "        final_integrator_step_size=integrator.step_size,\n",
    "        **operation_times,\n",
    "    )\n",
    "\n",
    "    print(summary)\n",
    "\n",
    "    return final_states, traces, stats, summary_dict, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab4860f7",
   "metadata": {},
   "outputs": [],
   "source": [
    " parser = set_up_argparser_with_standard_arguments(\n",
    "        \"Run stochastic-volatility model simulated data experiment\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdfe68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ssm_specific_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "776e9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(np.load(\"sv-simulated-data.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bff9158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['parametrization'] = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7df46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_u = compute_dim_u(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62040de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_y = data[\"y_obs\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e740ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = onp.random.default_rng(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "575ec51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_func = construct_trace_func(generate_params, data, dim_u, dim_v=dim_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5457927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "        constrained_system_class,\n",
    "        constrained_system_kwargs,\n",
    "    ) = get_ssm_constrained_system_class_and_kwargs(\n",
    "        True,\n",
    "        generate_params,\n",
    "        generate_x_0,\n",
    "        forward_func,\n",
    "        inverse_observation_func,\n",
    "        constr_split,\n",
    "        jacob_constr_split_blocks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7bedc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_system_kwargs.update(data=data, dim_u=dim_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eca17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
