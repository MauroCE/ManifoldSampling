{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea0f4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "## Autograd\n",
    "import autograd.numpy as np\n",
    "from autograd.numpy.random import seed, randn, rand\n",
    "from autograd.numpy import exp, hstack, log\n",
    "from autograd import grad, jacobian\n",
    "from autograd.numpy.linalg import norm\n",
    "from autograd.scipy.stats import norm as ag_norm\n",
    "from autograd.extend import primitive, defvjp\n",
    "from autograd.numpy.numpy_vjps import unbroadcast_f\n",
    "\n",
    "# Standard Python Imports\n",
    "from scipy.stats import norm as ndist\n",
    "from scipy.stats import uniform as udist\n",
    "from numpy import zeros, eye, vstack, sqrt, mean\n",
    "from scipy.stats import multivariate_normal as MVN\n",
    "from numpy.random import uniform\n",
    "from scipy.optimize import fsolve\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from numpy import save\n",
    "\n",
    "# Custom functions\n",
    "from tangential_hug_functions import HugTangentialStepEJSD_Deterministic, Hop_Deterministic, HugStepEJSD_Deterministic, HugRotatedStepEJSD_AR_Deterministic, HugRotatedStepEJSD_Deterministic\n",
    "from utils import ESS_univariate, ESS, n_unique\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "564d4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(thetau):\n",
    "    \"\"\"Deterministic function for distance manifold. f:R^5 -> R \"\"\"\n",
    "    a_param, b_param, k_param, *z = thetau  # Latents are standard normal variables\n",
    "    z = np.array(z)\n",
    "    out = a_param + b_param*(1 + 0.8 * (1 - exp(-g_param * z)) / (1+exp(-g_param * z))) * ((1 + z**2)**k_param) * z\n",
    "    return norm(out - y_star)\n",
    "\n",
    "def data_generator(theta, N):\n",
    "    \"\"\"Generates initial observed data y_star.\"\"\"\n",
    "    z = randn(N)         # Get N samples from N(0, 1) for G&K simulation.\n",
    "    a_param, b_param, k_param = theta   # Grab parameters\n",
    "    return a_param + b_param*(1 + 0.8 * (1 - exp(-g_param * z)) / (1+exp(-g_param * z))) * ((1 + z**2)**k_param) * z\n",
    "\n",
    "def logprior(thetau):\n",
    "    \"\"\"Log prior distribution.\"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return log((abs(thetau[:3]) <= 10).all().astype('float64')) + ndist.logpdf(thetau[3:]).sum()\n",
    "    \n",
    "def log_uniform_kernel(xi, epsilon):\n",
    "    \"\"\"Log density of uniform kernel. \"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return log((f(xi) <= epsilon).astype('float64'))\n",
    "    \n",
    "def log_abc_posterior(xi, epsilon):\n",
    "    \"\"\"Log density of ABC posterior. Product of (param-latent) prior and uniform kernel.\"\"\"\n",
    "    return logprior(xi) + log_uniform_kernel(xi, epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eef20093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### thug\n",
    "def experiment(x00, T, N, epsilon, alphas):\n",
    "    \"\"\"Runs Hug+Hop and THUG+HOP using the same velocities and the same random seeds.\n",
    "    We also try to limit the noise in the HOP kernel by sampling the u variables beforehand.\n",
    "    I run THUG for all values of alpha with the randomness fixed. \n",
    "    This is 1 run, for 1 epsilon. It does 1 HUG+HOP and then THUG+HOP for all alphas.\n",
    "    T1: T for HUG\n",
    "    T2: T for THUG\n",
    "    \"\"\"\n",
    "    ### TARGET\n",
    "    logpi = lambda xi: log_abc_posterior(xi, epsilon)\n",
    "    lam = epsilon / 30\n",
    "    d\n",
    "    ### COMMON VARIABLES\n",
    "    v = q.rvs(N)\n",
    "    log_uniforms1 = log(rand(N))     # Log uniforms for the HUG kernels\n",
    "    log_uniforms2 = log(rand(N))     # Log uniforms for the HOP kernel\n",
    "    u = MVN(zeros(d), eye(d)).rvs(N) # Original velocities for HOP kernel\n",
    "    ### STORAGE (HUG + HOP)\n",
    "    hh = x00              # Initial sample\n",
    "    ahh1 = 0.0       # Acceptance probability for HUG kernel\n",
    "    ahh2 = 0.0       # Acceptance probability for HOP kernel (when used with HUG)\n",
    "    ehh = 0.0             # EJSD\n",
    "    eghh = 0.0            # EJSD in Gradient direction\n",
    "    ethh = 0.0            # EJSD in Tangent direction\n",
    "    ### STORAGE (THUG + HOP) I MUST STORE FOR ALL ALPHAS\n",
    "    ath1 = zeros(n_alphas)\n",
    "    ath2 = zeros(n_alphas)\n",
    "    eth  = zeros(n_alphas)\n",
    "    egth = zeros(n_alphas)\n",
    "    etth = zeros(n_alphas)\n",
    "    ### ADDITIONAL STORAGE FOR THUG\n",
    "    th_ess  = zeros((n_alphas, d))   ##### CHECK D\n",
    "    th_essj = zeros(n_alphas)\n",
    "    th_uniq = zeros(n_alphas)\n",
    "    ### HUG + HOP\n",
    "    x = x00\n",
    "    for i in range(N):\n",
    "        y, a1, e, eg, et = HugStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T, B, q, logpi, grad_function)\n",
    "        x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, logpi, grad_function)\n",
    "        hh = vstack((hh, y, x))\n",
    "        ahh1 += a1 * 100 / N\n",
    "        ahh2 += a2 * 100 / N\n",
    "        ehh += e / N\n",
    "        eghh += eg / N \n",
    "        ethh += et / N \n",
    "    # COMPUTE ESS AND OTHER METRICS FOR HUG\n",
    "    hh = hh[1:]\n",
    "    hh_ess  = ESS_univariate(hh[::2])         # univariate ESS for each dimension\n",
    "    hh_essj = ESS(hh[::2])                   # ESS joint\n",
    "    hh_uniq = n_unique(hh)                             # Number of unique samples\n",
    "    ### THUG + HOP\n",
    "    for k, alpha in enumerate(alphas):\n",
    "        x = x00\n",
    "        th = x00      # RESTART THE SAMPLES FROM SCRATCH\n",
    "        for i in range(N):\n",
    "            y, a1, e, eg, et = HugTangentialStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T, B, alpha, q, logpi, grad_function)\n",
    "            x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, logpi, grad_function)\n",
    "            th = vstack((th, y, x))\n",
    "            ath1[k] += a1 * 100 / N\n",
    "            ath2[k] += a2 * 100 / N\n",
    "            eth[k]  += e / N\n",
    "            egth[k] += eg / N \n",
    "            etth[k] += et / N \n",
    "        ### COMPUTE ESS AND OTHER METRISC FOR THUG\n",
    "        th = th[1:]\n",
    "        th_ess[k]  = ESS_univariate(th[::2])        # univariate ESS for each dimension\n",
    "        th_essj[k] = ESS(th[::2])                   # ESS joint\n",
    "        th_uniq[k] = n_unique(th)                             # Number of unique samples\n",
    "    # RETURN EVERYTHING\n",
    "    out = {\n",
    "        'HH': {\n",
    "            'A1': ahh1,\n",
    "            'A2': ahh2,\n",
    "            'E': ehh,\n",
    "            'EG': eghh, \n",
    "            'ET': ethh,\n",
    "            'ESS': hh_ess,\n",
    "            'ESS_J': hh_essj,\n",
    "            'UNIQUE': hh_uniq,\n",
    "            'SAMPLES': hh\n",
    "        },\n",
    "        'TH': {\n",
    "            'A1': ath1,\n",
    "            'A2': ath2,\n",
    "            'E': eth,\n",
    "            'EG': egth, \n",
    "            'ET': etth, \n",
    "            'ESS': th_ess,\n",
    "            'ESS_J': th_essj,\n",
    "            'UNIQUE': th_uniq,\n",
    "            'SAMPLES': th\n",
    "        },\n",
    "        'N': N,\n",
    "        'T': T,\n",
    "        'ALPHAS': alphas,\n",
    "        'EPSILON': epsilon\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f4cb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "m = 2                                # Number of latents in G and K model\n",
    "d = 3 + m                            # Dimension of ambient space (theta has dim 3)\n",
    "Ts = [0.003]                         # Total integration time\n",
    "B = 5                                # Number of bounces per iteration of HUG/THUG\n",
    "N = 5000                              # Number of samples\n",
    "epsilons = [0.1, 0.01]               # Tolerance for ABC\n",
    "kappa = 0.001                        # HOP scaling in remaining directions relative to lam\n",
    "nlags = 2                            # Number of lags to compute autocorrelation for\n",
    "alphas = [0.5, 0.9]                  # Alphas for THUG\n",
    "n_alphas = len(alphas)\n",
    "n_cores = 8\n",
    "n_epsilons = len(epsilons)\n",
    "n_T = len(Ts)\n",
    "n_runs = 8                           # Number of runs for each setting combination\n",
    "g_param = 2.0                        # Parameter g is not estimated since it is un-informative\n",
    "theta0 = np.array([3.0, 1.0, 0.5])   # True parameter for G and K model\n",
    "y_star = data_generator(theta0, N=m) # Observed data\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "q = MVN(zeros(d), eye(d))                             # Spherically-symmetric proposal for HUG/THUG \n",
    "grad_function = grad(f)                               # Autograd gradient of deterministic simulator\n",
    "func = lambda xi: np.r_[f(xi), zeros(d-1)]            # Function used to find initial point on manifold\n",
    "guess = hstack((np.array([1.0, 1.0, 1.0]), zeros(m))) # Initial guess\n",
    "xi0 = fsolve(func, guess)                             # Fsolve finds initiial point on manifold\n",
    "\n",
    "def find_initial_points(n):\n",
    "    initial_points = []\n",
    "    while len(initial_points) < n:\n",
    "        try:\n",
    "            # Construct a new guess\n",
    "            theta_guess = uniform(0.1, 3.0, size=3)\n",
    "            guess = hstack((theta_guess, zeros(m)))\n",
    "            # Solve to find point on manifold\n",
    "            point = fsolve(func, guess)\n",
    "            initial_points.append(point)\n",
    "        except RuntimeWarning:  \n",
    "            pass\n",
    "    return vstack(initial_points)\n",
    "\n",
    "# Initial points on manifold\n",
    "initial_time = time.time()\n",
    "initial_points = find_initial_points(n_runs)\n",
    "run_indices = np.arange(n_runs).tolist() \n",
    "args = product(initial_points, [Ts], [N], [epsilons], [alphas])\n",
    "args_list = list(product(initial_points, [Ts], [N], [epsilons], [alphas]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e749c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.676727808632433,\n",
       " -2.424727588149733,\n",
       " -1.900350334649393,\n",
       " -2.2456579877328635,\n",
       " -3.5070285260258176,\n",
       " -2.1448629945522883,\n",
       " -4.955041835375766,\n",
       " -1.9949777749566948]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[log_abc_posterior(point, epsilons[0]) for point in initial_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32db4b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.676727808632433,\n",
       " -2.424727588149733,\n",
       " -1.900350334649393,\n",
       " -2.2456579877328635,\n",
       " -3.5070285260258176,\n",
       " -2.1448629945522883,\n",
       " -4.955041835375766,\n",
       " -1.9949777749566948]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[log_abc_posterior(point, epsilons[1]) for point in initial_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da6a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4d6de5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HH': {'A1': 99.93999999999726,\n",
       "  'A2': 95.45999999999815,\n",
       "  'E': 3.532064874118566e-05,\n",
       "  'EG': 0.1537850547986537,\n",
       "  'ET': 0.0016536916454451193,\n",
       "  'ESS': array([ 2.86307861,  3.04040481,  4.60959311, 15.26851866,  2.89406548]),\n",
       "  'ESS_J': 87.456649756502,\n",
       "  'UNIQUE': 9770,\n",
       "  'SAMPLES': array([[ 4.08283736,  1.97092543,  2.80339288, -0.593439  ,  0.29028044],\n",
       "         [ 4.08316492,  1.97100164,  2.80339631, -0.59380945,  0.29130594],\n",
       "         [ 4.08664235,  1.97047123,  2.80525179, -0.59510598,  0.28890871],\n",
       "         ...,\n",
       "         [ 4.43191114,  2.66236038,  2.63614374, -0.57731225,  0.18328086],\n",
       "         [ 4.43246917,  2.66657573,  2.63427883, -0.57663648,  0.18293206],\n",
       "         [ 4.43235882,  2.66640852,  2.63403237, -0.57619989,  0.1833827 ]])},\n",
       " 'TH': {'A1': array([99.46, 98.98]),\n",
       "  'A2': array([94.46, 94.62]),\n",
       "  'E': array([3.52098276e-05, 3.50418422e-05]),\n",
       "  'EG': array([0.09888984, 0.1044332 ]),\n",
       "  'ET': array([0.00120027, 0.00126394]),\n",
       "  'ESS': array([[ 2.87525965,  3.04974157,  4.44180304, 14.42293005,  2.91148121],\n",
       "         [ 2.86939746,  3.05976485,  4.82538801, 14.06704849,  2.93195095]]),\n",
       "  'ESS_J': array([87.10025131, 85.74612102]),\n",
       "  'UNIQUE': array([9696., 9681.]),\n",
       "  'SAMPLES': array([[ 4.08120155,  1.96821   ,  2.80002722, -0.59386624,  0.2908901 ],\n",
       "         [ 4.08150413,  1.96831068,  2.8000445 , -0.59437949,  0.29193246],\n",
       "         [ 4.08498987,  1.96773204,  2.80187799, -0.59547174,  0.28937083],\n",
       "         ...,\n",
       "         [ 4.42028465,  2.63965611,  2.65258827, -0.57309021,  0.18529882],\n",
       "         [ 4.42078906,  2.64389804,  2.65074537, -0.57265273,  0.18489945],\n",
       "         [ 4.42071621,  2.6437298 ,  2.65049973, -0.57214137,  0.18540979]])},\n",
       " 'N': 5000,\n",
       " 'T': 0.003,\n",
       " 'ALPHAS': [0.5, 0.9],\n",
       " 'EPSILON': 0.1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(x00, Ts[0], N, epsilons[0], alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3fb99261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-inf,   1.,   2.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([-np.inf, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e0d307b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c3d4d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning has been -excepted-\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    warnings.warn(Warning())\n",
    "except Warning:\n",
    "    print('Warning has been -excepted-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c613801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    try:\n",
    "        warnings.warn(Warning())\n",
    "    except Warning:\n",
    "        print(\"Here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a92a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
