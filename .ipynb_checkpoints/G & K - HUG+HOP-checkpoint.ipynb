{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd0e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autograd\n",
    "import autograd.numpy as np\n",
    "from autograd.numpy.random import seed, randn, rand\n",
    "from autograd.numpy import exp, hstack, log\n",
    "from autograd import grad, jacobian\n",
    "from autograd.numpy.linalg import norm\n",
    "from autograd.scipy.stats import norm as ag_norm\n",
    "from autograd.extend import primitive, defvjp\n",
    "from autograd.numpy.numpy_vjps import unbroadcast_f\n",
    "\n",
    "# Standard Python Imports\n",
    "from scipy.stats import norm as ndist\n",
    "from scipy.stats import uniform as udist\n",
    "from numpy import zeros, eye, vstack\n",
    "from scipy.stats import multivariate_normal as MVN\n",
    "from numpy.random import uniform\n",
    "from scipy.optimize import fsolve\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Custom functions\n",
    "from tangential_hug_functions import HugTangentialStepEJSD_Deterministic, Hop_Deterministic, HugStepEJSD_Deterministic\n",
    "from utils import ESS_univariate, ESS, n_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01367d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(thetau):\n",
    "    \"\"\"Deterministic function for distance manifold. f:R^5 -> R \"\"\"\n",
    "    a_param, b_param, k_param, *z = thetau  # Latents are standard normal variables\n",
    "    z = np.array(z)\n",
    "    out = a_param + b_param*(1 + 0.8 * (1 - exp(-g_param * z)) / (1+exp(-g_param * z))) * ((1 + z**2)**k_param) * z\n",
    "    return norm(out - y_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948ff35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(theta, N=2):\n",
    "    \"\"\"Generates initial observed data y_star.\"\"\"\n",
    "    z = randn(N)         # Get N samples from N(0, 1) for G&K simulation.\n",
    "    a_param, b_param, k_param = theta   # Grab parameters\n",
    "    return a_param + b_param*(1 + 0.8 * (1 - exp(-g_param * z)) / (1+exp(-g_param * z))) * ((1 + z**2)**k_param) * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1698a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = np.array([3.0, 1.0, 0.5])\n",
    "g_param = 2.0\n",
    "y_star = data_generator(theta0, N=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a225c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_function = grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88664da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprior(thetau):\n",
    "    \"\"\"Log prior distribution.\"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return log((abs(thetau[:3]) <= 10).all().astype('float64')) + ndist.logpdf(thetau[-2:]).sum()\n",
    "    \n",
    "def log_uniform_kernel(xi, epsilon):\n",
    "    \"\"\"Log density of uniform kernel. \"\"\"\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return log((f(xi) <= epsilon).astype('float64'))\n",
    "    \n",
    "def log_abc_posterior(xi):\n",
    "    \"\"\"Log density of ABC posterior. Product of (param-latent) prior and uniform kernel.\"\"\"\n",
    "    return logprior(xi) + log_uniform_kernel(xi, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9d218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(x00, T1, T2, N, alphas, nlags):\n",
    "    \"\"\"Runs Hug+Hop and THUG+HOP using the same velocities and the same random seeds.\"\"\"\n",
    "    ### COMMON VARIABLES\n",
    "    v = q.rvs(N)\n",
    "    log_uniforms1 = log(rand(N))     # Log uniforms for the HUG kernels\n",
    "    log_uniforms2 = log(rand(N))     # Log uniforms for the HOP kernel\n",
    "    u = MVN(zeros(5), eye(5)).rvs(N) # Original velocities for HOP kernel\n",
    "    ### STORAGE (HUG + HOP)\n",
    "    hh = x00              # Initial sample\n",
    "    ahh1 = 0.0            # Acceptance probability for HUG kernel\n",
    "    ahh2 = 0.0            # Acceptance probability for HOP kernel (when used with HUG)\n",
    "    ehh = 0.0             # EJSD\n",
    "    eghh = 0.0            # EJSD in Gradient direction\n",
    "    ethh = 0.0            # EJSD in Tangent direction\n",
    "    ### STORAGE (THUG + HOP) I MUST STORE FOR ALL ALPHAS\n",
    "    ath1 = zeros(n_alphas)\n",
    "    ath2 = zeros(n_alphas)\n",
    "    eth  = zeros(n_alphas)\n",
    "    egth = zeros(n_alphas)\n",
    "    etth = zeros(n_alphas)\n",
    "    ### ADDITIONAL STORAGE FOR THUG\n",
    "    th_esst = zeros(n_alphas)\n",
    "    th_essu = zeros(n_alphas)\n",
    "    th_essj = zeros(n_alphas)\n",
    "    th_uniq = zeros(n_alphas)\n",
    "    th_act  = zeros((n_alphas, nlags))\n",
    "    th_acu  = zeros((n_alphas, nlags))\n",
    "    ### HUG + HOP\n",
    "    x = x00\n",
    "    for i in range(N):\n",
    "        y, a1, e, eg, et = HugStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T1, B, q, log_abc_posterior, grad_function)\n",
    "        x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, log_abc_posterior, grad_function)\n",
    "        hh = vstack((hh, y, x))\n",
    "        ahh1 += a1 * 100 / N\n",
    "        ahh2 += a2 * 100 / N\n",
    "        ehh += e / N\n",
    "        eghh += eg / N \n",
    "        ethh += et / N \n",
    "    # COMPUTE ESS AND OTHER METRICS FOR HUG\n",
    "    hh = hh[1:]\n",
    "    hh_esst = ESS_univariate(hh[::2, 0])     # ESS for theta\n",
    "    hh_essu = ESS_univariate(hh[::2, 1])     # ESS for u\n",
    "    hh_essj = ESS(hh[::2])                   # ESS joint\n",
    "    hh_uniq = n_unique(hh)                             # Number of unique samples\n",
    "    hh_act  = acf(hh[::2, 0], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for theta (remove the first 1.0)\n",
    "    hh_acu  = acf(hh[::2, 1], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for u\n",
    "    ### THUG + HOP\n",
    "    for k, alpha in enumerate(alphas):\n",
    "        x = x00\n",
    "        th = x00      # RESTART THE SAMPLES FROM SCRATCH\n",
    "        for i in range(N):\n",
    "            y, a1, e, eg, et = HugTangentialStepEJSD_Deterministic(x, v[i], log_uniforms1[i], T2, B, alpha, q, log_abc_posterior, grad_function)\n",
    "            x, a2 = Hop_Deterministic(y, u[i], log_uniforms2[i], lam, kappa, log_abc_posterior, grad_function)\n",
    "            th = vstack((th, y, x))\n",
    "            ath1[k] += a1 * 100 / N\n",
    "            ath2[k] += a2 * 100 / N\n",
    "            eth[k]  += e / N\n",
    "            egth[k] += eg / N \n",
    "            etth[k] += et / N \n",
    "        ### COMPUTE ESS AND OTHER METRISC FOR THUG\n",
    "        th = th[1:]\n",
    "        th_esst[k] = ESS_univariate(th[::2, 0])     # ESS for theta\n",
    "        th_essu[k] = ESS_univariate(th[::2, 1])     # ESS for u\n",
    "        th_essj[k] = ESS(th[::2])                   # ESS joint\n",
    "        th_uniq[k] = n_unique(th)                             # Number of unique samples\n",
    "        th_act[k] = acf(th[::2, 0], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for theta\n",
    "        th_acu[k] = acf(th[::2, 1], adjusted=True, nlags=nlags, fft=True)[1:]  # Autocorrelation for u\n",
    "    # RETURN EVERYTHING\n",
    "    out = {\n",
    "        'HH': {\n",
    "            'A1': ahh1,\n",
    "            'A2': ahh2,\n",
    "            'E': ehh,\n",
    "            'EG': eghh, \n",
    "            'ET': ethh,\n",
    "            'ESS_T': hh_esst,\n",
    "            'ESS_U': hh_essu,\n",
    "            'ESS_J': hh_essj,\n",
    "            'UNIQUE': hh_uniq,\n",
    "            'AC_T': hh_act,\n",
    "            'AC_U': hh_acu,\n",
    "            'T': T1,\n",
    "            'SAMPLES': hh\n",
    "        },\n",
    "        'TH': {\n",
    "            'A1': ath1,\n",
    "            'A2': ath2,\n",
    "            'E': eth,\n",
    "            'EG': egth, \n",
    "            'ET': etth, \n",
    "            'ESS_T': th_esst,\n",
    "            'ESS_U': th_essu,\n",
    "            'ESS_J': th_essj,\n",
    "            'UNIQUE': th_uniq,\n",
    "            'AC_T': th_act,\n",
    "            'AC_U': th_acu,\n",
    "            'T': T2,\n",
    "            'SAMPLES': th\n",
    "        }\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f517582",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = MVN(zeros(5), eye(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6889208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.99]\n",
    "n_alphas = len(alphas)\n",
    "epsilon = 0.00001\n",
    "lam = epsilon / 30\n",
    "kappa = 0.001\n",
    "T1 = T2 = 0.01\n",
    "B = 5\n",
    "N = 5000\n",
    "nlags = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4f774456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a guess\n",
    "guess = np.array([1.0, 1.0, 1.0, 0.0, 0.0]) \n",
    "\n",
    "# Find point on manifold using optimization\n",
    "func = lambda xi: np.r_[f(xi), 0.0, 0.0, 0.0, 0.0]  # Append 0, 0 to make fsolve work.\n",
    "xi0 = fsolve(func, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff28000",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = experiment(xi0, T1, T2, N, alphas, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out['HH']['A1'], out['HH']['A2'], out['HH']['E'], out['HH']['ESS_J'] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb58a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out['TH']['A1'], out['TH']['A2'], out['TH']['E'], out['TH']['ESS_J'] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf1f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
